1:"$Sreact.fragment"
2:I[11363,["/_next/static/chunks/0dc5382467fc7d73.js"],""]
49:I[36222,["/_next/static/chunks/b296557f5fbf63fb.js","/_next/static/chunks/29b10150c0f3771e.js"],"OutletBoundary"]
4a:"$Sreact.suspense"
0:{"buildId":"d61kz0L6dQlOCk8Q0BItM","rsc":["$","$1","c",{"children":[["$","div",null,{"className":"mx-auto max-w-4xl px-6 py-12","children":[["$","div",null,{"className":"text-sm text-zinc-500 mb-4","children":[["$","$L2",null,{"href":"/data","className":"hover:text-white","children":"Data"}]," ‚Üí ArXiv Papers"]}],["$","h1",null,{"className":"text-2xl font-semibold tracking-tight mb-2","children":"ArXiv AI Papers"}],["$","p",null,{"className":"text-zinc-400 mb-1","children":"Latest research in AI agents, code generation, and LLMs"}],["$","p",null,{"className":"text-xs text-zinc-600 mb-6","children":[70," papers ¬∑ Categories: ","cs.AI, cs.CL, cs.LG"," ¬∑ Updated: ","Feb 11, 23:51"," UTC"]}],["$","div",null,{"className":"grid grid-cols-2 md:grid-cols-4 gap-4 mb-8","children":[["$","div",null,{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg text-center","children":[["$","div",null,{"className":"text-2xl font-semibold text-white","children":"200"}],["$","div",null,{"className":"text-xs text-zinc-500 mt-1","children":"Papers Scanned"}]]}],["$","div",null,{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg text-center","children":[["$","div",null,{"className":"text-2xl font-semibold text-white","children":"50"}],["$","div",null,{"className":"text-xs text-zinc-500 mt-1","children":"AI-Relevant"}]]}],["$","div",null,{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg text-center","children":[["$","div",null,{"className":"text-2xl font-semibold text-white","children":"20"}],["$","div",null,{"className":"text-xs text-zinc-500 mt-1","children":"Last 48h"}]]}],["$","div",null,{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg text-center","children":[["$","div",null,{"className":"text-2xl font-semibold text-white","children":"5"}],["$","div",null,{"className":"text-xs text-zinc-500 mt-1","children":"Categories"}]]}]]}],["$","section",null,{"className":"mb-8","children":[["$","div",null,{"className":"mb-4 pb-2 border-b border-white/[0.08]","children":["$","h2",null,{"className":"text-xs uppercase tracking-wide text-zinc-500","children":"Research Topics"}]}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","span","agents",{"className":"px-3 py-1 rounded-full text-sm border text-amber-400 bg-amber-400/10 border-amber-400/20","children":["ü§ñ Agents",": ",17]}],["$","span","benchmarks",{"className":"px-3 py-1 rounded-full text-sm border text-green-400 bg-green-400/10 border-green-400/20","children":["üìä Benchmarks",": ",16]}],["$","span","code-generation",{"className":"px-3 py-1 rounded-full text-sm border text-blue-400 bg-blue-400/10 border-blue-400/20","children":["üíª Code Gen",": ",11]}],["$","span","reasoning",{"className":"px-3 py-1 rounded-full text-sm border text-purple-400 bg-purple-400/10 border-purple-400/20","children":["üß† Reasoning",": ",4]}],["$","span","safety",{"className":"px-3 py-1 rounded-full text-sm border text-red-400 bg-red-400/10 border-red-400/20","children":["üõ°Ô∏è Safety",": ",2]}]]}]]}],["$","section",null,{"className":"mb-10","children":[["$","div",null,{"className":"mb-4 pb-2 border-b border-white/[0.08]","children":["$","h2",null,{"className":"text-xs uppercase tracking-wide text-zinc-500","children":"Top Relevant Papers"}]}],["$","div",null,{"className":"space-y-4","children":[["$","div","2602.09447v1",{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg hover:border-white/20 transition-colors","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"text-center min-w-[50px] hidden sm:block","children":[["$","div",null,{"className":"text-lg font-semibold text-green-400","children":22}],["$","div",null,{"className":"text-xs text-zinc-600","children":"score"}]]}],["$","div",null,{"className":"flex-1 min-w-0","children":[["$","a",null,{"href":"https://arxiv.org/abs/2602.09447v1","target":"_blank","rel":"noopener noreferrer","className":"text-white hover:text-blue-400 font-medium block mb-2 leading-snug","children":"SWE-AGI: Benchmarking Specification-Driven Software Construction with MoonBit in the Era of Autonomous Agents"}],"$L3","$L4"]}]]}]}],"$L5","$L6","$L7","$L8","$L9","$La","$Lb","$Lc","$Ld","$Le","$Lf","$L10","$L11","$L12"]}]]}],"$L13","$L14"]}],null,"$L15"]}],"loading":null,"isPartial":false}
3:["$","p",null,{"className":"text-sm text-zinc-400 mb-3 leading-relaxed","children":"Although large language models (LLMs) have demonstrated impressive coding capabilities, their ability to autonomously build production-scale software from explicit specifications remains an open question. We introduce SWE-AGI, an open-source benchmar..."}]
4:["$","div",null,{"className":"flex flex-wrap items-center gap-x-3 gap-y-2 text-xs text-zinc-500","children":[["$","span",null,{"className":"line-clamp-1","children":["Zhirui Zhang, Hongbo Zhang, Haoxiang Fei"," +11"]}],["$","span",null,{"children":"¬∑"}],["$","span",null,{"children":"3d ago"}],"$undefined",["$","span",null,{"children":"¬∑"}],["$","a",null,{"href":"https://arxiv.org/pdf/2602.09447v1","target":"_blank","rel":"noopener noreferrer","className":"text-blue-400 hover:text-blue-300","children":"PDF ‚Üó"}]]}]
5:["$","div","2602.10092v1",{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg hover:border-white/20 transition-colors","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"text-center min-w-[50px] hidden sm:block","children":[["$","div",null,{"className":"text-lg font-semibold text-green-400","children":16}],["$","div",null,{"className":"text-xs text-zinc-600","children":"score"}]]}],["$","div",null,{"className":"flex-1 min-w-0","children":[["$","a",null,{"href":"https://arxiv.org/abs/2602.10092v1","target":"_blank","rel":"noopener noreferrer","className":"text-white hover:text-blue-400 font-medium block mb-2 leading-snug","children":"Quantum-Audit: Evaluating the Reasoning Limits of LLMs on Quantum Computing"}],["$","p",null,{"className":"text-sm text-zinc-400 mb-3 leading-relaxed","children":"Language models have become practical tools for quantum computing education and research, from summarizing technical papers to explaining theoretical concepts and answering questions about recent developments in the field. While existing benchmarks e..."}],["$","div",null,{"className":"flex flex-wrap items-center gap-x-3 gap-y-2 text-xs text-zinc-500","children":[["$","span",null,{"className":"line-clamp-1","children":["Mohamed Afane, Kayla Laufer, Wenqi Wei"," +4"]}],["$","span",null,{"children":"¬∑"}],["$","span",null,{"children":"2d ago"}],"$undefined",["$","span",null,{"children":"¬∑"}],["$","a",null,{"href":"https://arxiv.org/pdf/2602.10092v1","target":"_blank","rel":"noopener noreferrer","className":"text-blue-400 hover:text-blue-300","children":"PDF ‚Üó"}]]}]]}]]}]}]
6:["$","div","2602.10063v1",{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg hover:border-white/20 transition-colors","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"text-center min-w-[50px] hidden sm:block","children":[["$","div",null,{"className":"text-lg font-semibold text-green-400","children":16}],["$","div",null,{"className":"text-xs text-zinc-600","children":"score"}]]}],["$","div",null,{"className":"flex-1 min-w-0","children":[["$","a",null,{"href":"https://arxiv.org/abs/2602.10063v1","target":"_blank","rel":"noopener noreferrer","className":"text-white hover:text-blue-400 font-medium block mb-2 leading-snug","children":"Chain of Mindset: Reasoning with Adaptive Cognitive Modes"}],["$","p",null,{"className":"text-sm text-zinc-400 mb-3 leading-relaxed","children":"Human problem-solving is never the repetition of a single mindset, by which we mean a distinct mode of cognitive processing. When tackling a specific task, we do not rely on a single mindset; instead, we integrate multiple mindsets within the single..."}],["$","div",null,{"className":"flex flex-wrap items-center gap-x-3 gap-y-2 text-xs text-zinc-500","children":[["$","span",null,{"className":"line-clamp-1","children":["Tianyi Jiang, Arctanx An, Hengyi Feng"," +12"]}],["$","span",null,{"children":"¬∑"}],["$","span",null,{"children":"2d ago"}],"$undefined",["$","span",null,{"children":"¬∑"}],["$","a",null,{"href":"https://arxiv.org/pdf/2602.10063v1","target":"_blank","rel":"noopener noreferrer","className":"text-blue-400 hover:text-blue-300","children":"PDF ‚Üó"}]]}]]}]]}]}]
7:["$","div","2602.09937v1",{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg hover:border-white/20 transition-colors","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"text-center min-w-[50px] hidden sm:block","children":[["$","div",null,{"className":"text-lg font-semibold text-green-400","children":16}],["$","div",null,{"className":"text-xs text-zinc-600","children":"score"}]]}],["$","div",null,{"className":"flex-1 min-w-0","children":[["$","a",null,{"href":"https://arxiv.org/abs/2602.09937v1","target":"_blank","rel":"noopener noreferrer","className":"text-white hover:text-blue-400 font-medium block mb-2 leading-snug","children":"Why Do AI Agents Systematically Fail at Cloud Root Cause Analysis?"}],["$","p",null,{"className":"text-sm text-zinc-400 mb-3 leading-relaxed","children":"Failures in large-scale cloud systems incur substantial financial losses, making automated Root Cause Analysis (RCA) essential for operational stability. Recent efforts leverage Large Language Model (LLM) agents to automate this task, yet existing sy..."}],["$","div",null,{"className":"flex flex-wrap items-center gap-x-3 gap-y-2 text-xs text-zinc-500","children":[["$","span",null,{"className":"line-clamp-1","children":["Taeyoon Kim, Woohyeok Park, Hoyeong Yun"," +1"]}],["$","span",null,{"children":"¬∑"}],["$","span",null,{"children":"2d ago"}],"$undefined",["$","span",null,{"children":"¬∑"}],["$","a",null,{"href":"https://arxiv.org/pdf/2602.09937v1","target":"_blank","rel":"noopener noreferrer","className":"text-blue-400 hover:text-blue-300","children":"PDF ‚Üó"}]]}]]}]]}]}]
8:["$","div","2602.09598v1",{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg hover:border-white/20 transition-colors","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"text-center min-w-[50px] hidden sm:block","children":[["$","div",null,{"className":"text-lg font-semibold text-green-400","children":16}],["$","div",null,{"className":"text-xs text-zinc-600","children":"score"}]]}],["$","div",null,{"className":"flex-1 min-w-0","children":[["$","a",null,{"href":"https://arxiv.org/abs/2602.09598v1","target":"_blank","rel":"noopener noreferrer","className":"text-white hover:text-blue-400 font-medium block mb-2 leading-snug","children":"Learning from the Irrecoverable: Error-Localized Policy Optimization for Tool-Integrated LLM Reasoning"}],["$","p",null,{"className":"text-sm text-zinc-400 mb-3 leading-relaxed","children":"Tool-integrated reasoning (TIR) enables LLM agents to solve tasks through planning, tool use, and iterative revision, but outcome-only reinforcement learning in this setting suffers from sparse, delayed rewards and weak step-level credit assignment...."}],["$","div",null,{"className":"flex flex-wrap items-center gap-x-3 gap-y-2 text-xs text-zinc-500","children":[["$","span",null,{"className":"line-clamp-1","children":["Qiao Liang, Yuke Zhu, Chao Ge"," +4"]}],["$","span",null,{"children":"¬∑"}],["$","span",null,{"children":"3d ago"}],"$undefined",["$","span",null,{"children":"¬∑"}],["$","a",null,{"href":"https://arxiv.org/pdf/2602.09598v1","target":"_blank","rel":"noopener noreferrer","className":"text-blue-400 hover:text-blue-300","children":"PDF ‚Üó"}]]}]]}]]}]}]
9:["$","div","2602.09517v1",{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg hover:border-white/20 transition-colors","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"text-center min-w-[50px] hidden sm:block","children":[["$","div",null,{"className":"text-lg font-semibold text-green-400","children":16}],["$","div",null,{"className":"text-xs text-zinc-600","children":"score"}]]}],["$","div",null,{"className":"flex-1 min-w-0","children":[["$","a",null,{"href":"https://arxiv.org/abs/2602.09517v1","target":"_blank","rel":"noopener noreferrer","className":"text-white hover:text-blue-400 font-medium block mb-2 leading-snug","children":"Knowledge Integration Decay in Search-Augmented Reasoning of Large Language Models"}],["$","p",null,{"className":"text-sm text-zinc-400 mb-3 leading-relaxed","children":"Modern Large Language Models (LLMs) have demonstrated remarkable capabilities in complex tasks by employing search-augmented reasoning to incorporate external knowledge into long chains of thought. However, we identify a critical yet underexplored bo..."}],["$","div",null,{"className":"flex flex-wrap items-center gap-x-3 gap-y-2 text-xs text-zinc-500","children":[["$","span",null,{"className":"line-clamp-1","children":["Sangwon Yu, Ik-hwan Kim, Donghun Kang"," +6"]}],["$","span",null,{"children":"¬∑"}],["$","span",null,{"children":"3d ago"}],"$undefined",["$","span",null,{"children":"¬∑"}],["$","a",null,{"href":"https://arxiv.org/pdf/2602.09517v1","target":"_blank","rel":"noopener noreferrer","className":"text-blue-400 hover:text-blue-300","children":"PDF ‚Üó"}]]}]]}]]}]}]
a:["$","div","2602.09463v1",{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg hover:border-white/20 transition-colors","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"text-center min-w-[50px] hidden sm:block","children":[["$","div",null,{"className":"text-lg font-semibold text-green-400","children":16}],["$","div",null,{"className":"text-xs text-zinc-600","children":"score"}]]}],["$","div",null,{"className":"flex-1 min-w-0","children":[["$","a",null,{"href":"https://arxiv.org/abs/2602.09463v1","target":"_blank","rel":"noopener noreferrer","className":"text-white hover:text-blue-400 font-medium block mb-2 leading-snug","children":"SpotAgent: Grounding Visual Geo-localization in Large Vision-Language Models through Agentic Reasoning"}],["$","p",null,{"className":"text-sm text-zinc-400 mb-3 leading-relaxed","children":"Large Vision-Language Models (LVLMs) have demonstrated strong reasoning capabilities in geo-localization, yet they often struggle in real-world scenarios where visual cues are sparse, long-tailed, and highly ambiguous. Previous approaches, bound by i..."}],["$","div",null,{"className":"flex flex-wrap items-center gap-x-3 gap-y-2 text-xs text-zinc-500","children":[["$","span",null,{"className":"line-clamp-1","children":["Furong Jia, Ling Dai, Wenjin Deng"," +4"]}],["$","span",null,{"children":"¬∑"}],["$","span",null,{"children":"3d ago"}],"$undefined",["$","span",null,{"children":"¬∑"}],["$","a",null,{"href":"https://arxiv.org/pdf/2602.09463v1","target":"_blank","rel":"noopener noreferrer","className":"text-blue-400 hover:text-blue-300","children":"PDF ‚Üó"}]]}]]}]]}]}]
b:["$","div","2602.09443v1",{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg hover:border-white/20 transition-colors","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"text-center min-w-[50px] hidden sm:block","children":[["$","div",null,{"className":"text-lg font-semibold text-green-400","children":16}],["$","div",null,{"className":"text-xs text-zinc-600","children":"score"}]]}],["$","div",null,{"className":"flex-1 min-w-0","children":[["$","a",null,{"href":"https://arxiv.org/abs/2602.09443v1","target":"_blank","rel":"noopener noreferrer","className":"text-white hover:text-blue-400 font-medium block mb-2 leading-snug","children":"P1-VL: Bridging Visual Perception and Scientific Reasoning in Physics Olympiads"}],["$","p",null,{"className":"text-sm text-zinc-400 mb-3 leading-relaxed","children":"The transition from symbolic manipulation to science-grade reasoning represents a pivotal frontier for Large Language Models (LLMs), with physics serving as the critical test anchor for binding abstract logic to physical reality. Physics demands that..."}],["$","div",null,{"className":"flex flex-wrap items-center gap-x-3 gap-y-2 text-xs text-zinc-500","children":[["$","span",null,{"className":"line-clamp-1","children":["Yun Luo, Futing Wang, Qianjia Cheng"," +28"]}],["$","span",null,{"children":"¬∑"}],["$","span",null,{"children":"3d ago"}],"$undefined",["$","span",null,{"children":"¬∑"}],["$","a",null,{"href":"https://arxiv.org/pdf/2602.09443v1","target":"_blank","rel":"noopener noreferrer","className":"text-blue-400 hover:text-blue-300","children":"PDF ‚Üó"}]]}]]}]]}]}]
c:["$","div","2602.09945v1",{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg hover:border-white/20 transition-colors","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"text-center min-w-[50px] hidden sm:block","children":[["$","div",null,{"className":"text-lg font-semibold text-green-400","children":15}],["$","div",null,{"className":"text-xs text-zinc-600","children":"score"}]]}],["$","div",null,{"className":"flex-1 min-w-0","children":[["$","a",null,{"href":"https://arxiv.org/abs/2602.09945v1","target":"_blank","rel":"noopener noreferrer","className":"text-white hover:text-blue-400 font-medium block mb-2 leading-snug","children":"Closing Reasoning Gaps in Clinical Agents with Differential Reasoning Learning"}],["$","p",null,{"className":"text-sm text-zinc-400 mb-3 leading-relaxed","children":"Clinical decision support requires not only correct answers but also clinically valid reasoning. We propose Differential Reasoning Learning (DRL), a framework that improves clinical agents by learning from reasoning discrepancies. From reference reas..."}],["$","div",null,{"className":"flex flex-wrap items-center gap-x-3 gap-y-2 text-xs text-zinc-500","children":[["$","span",null,{"className":"line-clamp-1","children":["Jinsong Liu, Yuhang Jiang, Ramayya Krishnan"," +3"]}],["$","span",null,{"children":"¬∑"}],["$","span",null,{"children":"2d ago"}],"$undefined",["$","span",null,{"children":"¬∑"}],["$","a",null,{"href":"https://arxiv.org/pdf/2602.09945v1","target":"_blank","rel":"noopener noreferrer","className":"text-blue-400 hover:text-blue-300","children":"PDF ‚Üó"}]]}]]}]]}]}]
d:["$","div","2602.09817v1",{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg hover:border-white/20 transition-colors","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"text-center min-w-[50px] hidden sm:block","children":[["$","div",null,{"className":"text-lg font-semibold text-green-400","children":15}],["$","div",null,{"className":"text-xs text-zinc-600","children":"score"}]]}],["$","div",null,{"className":"flex-1 min-w-0","children":[["$","a",null,{"href":"https://arxiv.org/abs/2602.09817v1","target":"_blank","rel":"noopener noreferrer","className":"text-white hover:text-blue-400 font-medium block mb-2 leading-snug","children":"AnalyticsGPT: An LLM Workflow for Scientometric Question Answering"}],["$","p",null,{"className":"text-sm text-zinc-400 mb-3 leading-relaxed","children":"This paper introduces AnalyticsGPT, an intuitive and efficient large language model (LLM)-powered workflow for scientometric question answering. This underrepresented downstream task addresses the subcategory of meta-scientific questions concerning t..."}],["$","div",null,{"className":"flex flex-wrap items-center gap-x-3 gap-y-2 text-xs text-zinc-500","children":[["$","span",null,{"className":"line-clamp-1","children":["Khang Ly, Georgios Cheirmpos, Adrian Raudaschl"," +2"]}],["$","span",null,{"children":"¬∑"}],["$","span",null,{"children":"2d ago"}],"$undefined",["$","span",null,{"children":"¬∑"}],["$","a",null,{"href":"https://arxiv.org/pdf/2602.09817v1","target":"_blank","rel":"noopener noreferrer","className":"text-blue-400 hover:text-blue-300","children":"PDF ‚Üó"}]]}]]}]]}]}]
e:["$","div","2602.09712v1",{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg hover:border-white/20 transition-colors","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"text-center min-w-[50px] hidden sm:block","children":[["$","div",null,{"className":"text-lg font-semibold text-green-400","children":15}],["$","div",null,{"className":"text-xs text-zinc-600","children":"score"}]]}],["$","div",null,{"className":"flex-1 min-w-0","children":[["$","a",null,{"href":"https://arxiv.org/abs/2602.09712v1","target":"_blank","rel":"noopener noreferrer","className":"text-white hover:text-blue-400 font-medium block mb-2 leading-snug","children":"TraceMem: Weaving Narrative Memory Schemata from User Conversational Traces"}],["$","p",null,{"className":"text-sm text-zinc-400 mb-3 leading-relaxed","children":"Sustaining long-term interactions remains a bottleneck for Large Language Models (LLMs), as their limited context windows struggle to manage dialogue histories that extend over time. Existing memory systems often treat interactions as disjointed snip..."}],["$","div",null,{"className":"flex flex-wrap items-center gap-x-3 gap-y-2 text-xs text-zinc-500","children":[["$","span",null,{"className":"line-clamp-1","children":["Yiming Shu, Pei Liu, Tiange Zhang"," +3"]}],["$","span",null,{"children":"¬∑"}],["$","span",null,{"children":"3d ago"}],"$undefined",["$","span",null,{"children":"¬∑"}],["$","a",null,{"href":"https://arxiv.org/pdf/2602.09712v1","target":"_blank","rel":"noopener noreferrer","className":"text-blue-400 hover:text-blue-300","children":"PDF ‚Üó"}]]}]]}]]}]}]
f:["$","div","2602.09642v1",{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg hover:border-white/20 transition-colors","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"text-center min-w-[50px] hidden sm:block","children":[["$","div",null,{"className":"text-lg font-semibold text-green-400","children":14}],["$","div",null,{"className":"text-xs text-zinc-600","children":"score"}]]}],["$","div",null,{"className":"flex-1 min-w-0","children":[["$","a",null,{"href":"https://arxiv.org/abs/2602.09642v1","target":"_blank","rel":"noopener noreferrer","className":"text-white hover:text-blue-400 font-medium block mb-2 leading-snug","children":"MATA: Multi-Agent Framework for Reliable and Flexible Table Question Answering"}],["$","p",null,{"className":"text-sm text-zinc-400 mb-3 leading-relaxed","children":"Recent advances in Large Language Models (LLMs) have significantly improved table understanding tasks such as Table Question Answering (TableQA), yet challenges remain in ensuring reliability, scalability, and efficiency, especially in resource-const..."}],["$","div",null,{"className":"flex flex-wrap items-center gap-x-3 gap-y-2 text-xs text-zinc-500","children":[["$","span",null,{"className":"line-clamp-1","children":["Sieun Hyeon, Jusang Oh, Sunghwan Steve Cho"," +1"]}],["$","span",null,{"children":"¬∑"}],["$","span",null,{"children":"3d ago"}],"$undefined",["$","span",null,{"children":"¬∑"}],["$","a",null,{"href":"https://arxiv.org/pdf/2602.09642v1","target":"_blank","rel":"noopener noreferrer","className":"text-blue-400 hover:text-blue-300","children":"PDF ‚Üó"}]]}]]}]]}]}]
10:["$","div","2602.10081v1",{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg hover:border-white/20 transition-colors","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"text-center min-w-[50px] hidden sm:block","children":[["$","div",null,{"className":"text-lg font-semibold text-green-400","children":13}],["$","div",null,{"className":"text-xs text-zinc-600","children":"score"}]]}],["$","div",null,{"className":"flex-1 min-w-0","children":[["$","a",null,{"href":"https://arxiv.org/abs/2602.10081v1","target":"_blank","rel":"noopener noreferrer","className":"text-white hover:text-blue-400 font-medium block mb-2 leading-snug","children":"Anagent For Enhancing Scientific Table &amp; Figure Analysis"}],["$","p",null,{"className":"text-sm text-zinc-400 mb-3 leading-relaxed","children":"In scientific research, analysis requires accurately interpreting complex multimodal knowledge, integrating evidence from different sources, and drawing inferences grounded in domain-specific knowledge. However, current artificial intelligence (AI) s..."}],["$","div",null,{"className":"flex flex-wrap items-center gap-x-3 gap-y-2 text-xs text-zinc-500","children":[["$","span",null,{"className":"line-clamp-1","children":["Xuehang Guo, Zhiyong Lu, Tom Hope"," +1"]}],["$","span",null,{"children":"¬∑"}],["$","span",null,{"children":"2d ago"}],"$undefined",["$","span",null,{"children":"¬∑"}],["$","a",null,{"href":"https://arxiv.org/pdf/2602.10081v1","target":"_blank","rel":"noopener noreferrer","className":"text-blue-400 hover:text-blue-300","children":"PDF ‚Üó"}]]}]]}]]}]}]
11:["$","div","2602.09629v1",{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg hover:border-white/20 transition-colors","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"text-center min-w-[50px] hidden sm:block","children":[["$","div",null,{"className":"text-lg font-semibold text-green-400","children":13}],["$","div",null,{"className":"text-xs text-zinc-600","children":"score"}]]}],["$","div",null,{"className":"flex-1 min-w-0","children":[["$","a",null,{"href":"https://arxiv.org/abs/2602.09629v1","target":"_blank","rel":"noopener noreferrer","className":"text-white hover:text-blue-400 font-medium block mb-2 leading-snug","children":"Stop Testing Attacks, Start Diagnosing Defenses: The Four-Checkpoint Framework Reveals Where LLM Safety Breaks"}],["$","p",null,{"className":"text-sm text-zinc-400 mb-3 leading-relaxed","children":"Large Language Models (LLMs) deploy safety mechanisms to prevent harmful outputs, yet these defenses remain vulnerable to adversarial prompts. While existing research demonstrates that jailbreak attacks succeed, it does not explain \\textit{where} def..."}],["$","div",null,{"className":"flex flex-wrap items-center gap-x-3 gap-y-2 text-xs text-zinc-500","children":[["$","span",null,{"className":"line-clamp-1","children":["Hayfa Dhabhi, Kashyap Thimmaraju",false]}],["$","span",null,{"children":"¬∑"}],["$","span",null,{"children":"3d ago"}],"$undefined",["$","span",null,{"children":"¬∑"}],["$","a",null,{"href":"https://arxiv.org/pdf/2602.09629v1","target":"_blank","rel":"noopener noreferrer","className":"text-blue-400 hover:text-blue-300","children":"PDF ‚Üó"}]]}]]}]]}]}]
12:["$","div","2602.09438v1",{"className":"p-4 bg-white/[0.02] border border-white/[0.08] rounded-lg hover:border-white/20 transition-colors","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"text-center min-w-[50px] hidden sm:block","children":[["$","div",null,{"className":"text-lg font-semibold text-green-400","children":13}],["$","div",null,{"className":"text-xs text-zinc-600","children":"score"}]]}],["$","div",null,{"className":"flex-1 min-w-0","children":[["$","a",null,{"href":"https://arxiv.org/abs/2602.09438v1","target":"_blank","rel":"noopener noreferrer","className":"text-white hover:text-blue-400 font-medium block mb-2 leading-snug","children":"Breaking the Pre-Sampling Barrier: Activation-Informed Difficulty-Aware Self-Consistency"}],["$","p",null,{"className":"text-sm text-zinc-400 mb-3 leading-relaxed","children":"Self-Consistency (SC) is an effective decoding strategy that improves the reasoning performance of Large Language Models (LLMs) by generating multiple chain-of-thought reasoning paths and selecting the final answer via majority voting. However, it su..."}],["$","div",null,{"className":"flex flex-wrap items-center gap-x-3 gap-y-2 text-xs text-zinc-500","children":[["$","span",null,{"className":"line-clamp-1","children":["Taewoong Yoon, Geunyeong Jeong, Geon Park"," +2"]}],["$","span",null,{"children":"¬∑"}],["$","span",null,{"children":"3d ago"}],"$undefined",["$","span",null,{"children":"¬∑"}],["$","a",null,{"href":"https://arxiv.org/pdf/2602.09438v1","target":"_blank","rel":"noopener noreferrer","className":"text-blue-400 hover:text-blue-300","children":"PDF ‚Üó"}]]}]]}]]}]}]
13:["$","section",null,{"children":[["$","div",null,{"className":"mb-4 pb-2 border-b border-white/[0.08]","children":["$","h2",null,{"className":"text-xs uppercase tracking-wide text-zinc-500","children":"All Papers"}]}],["$","div",null,{"className":"overflow-x-auto","children":["$","table",null,{"className":"w-full text-sm","children":[["$","thead",null,{"children":["$","tr",null,{"className":"text-left text-xs text-zinc-500 uppercase","children":[["$","th",null,{"className":"pb-2 pr-4","children":"Score"}],["$","th",null,{"className":"pb-2 pr-4","children":"Title"}],["$","th",null,{"className":"pb-2 pr-4 hidden md:table-cell","children":"Category"}],["$","th",null,{"className":"pb-2","children":"Published"}]]}]}],["$","tbody",null,{"className":"text-zinc-300","children":[["$","tr","2602.09805v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":12}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09805v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Decomposing Reasoning Efficiency in Large Language Models"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}],["$","tr","2602.09794v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":12}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09794v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"GHS-TDA: A Synergistic Reasoning Framework Integrating Global Hypothesis Space with Topological Data Analysis"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}],["$","tr","2602.09634v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":12}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09634v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"LLM-FS: Zero-Shot Feature Selection for Effective and Interpretable Malware Detection"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}],["$","tr","2602.09486v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":12}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09486v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Listen to the Layers: Mitigating Hallucinations with Inter-Layer Disagreement"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}],["$","tr","2602.10090v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":11}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.10090v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}],["$","tr","2602.10048v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":11}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.10048v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Long Chain-of-Thought Compression via Fine-Grained Group Policy Optimization"}]}],"$L16","$L17"]}],"$L18","$L19","$L1a","$L1b","$L1c","$L1d","$L1e","$L1f","$L20","$L21","$L22","$L23","$L24","$L25","$L26","$L27","$L28","$L29","$L2a","$L2b","$L2c","$L2d","$L2e","$L2f","$L30","$L31","$L32","$L33","$L34","$L35","$L36","$L37","$L38","$L39","$L3a","$L3b","$L3c","$L3d","$L3e","$L3f","$L40","$L41","$L42","$L43","$L44","$L45","$L46","$L47","$L48"]}]]}]}]]}]
14:["$","p",null,{"className":"text-xs text-zinc-600 mt-8","children":["Source: ",["$","a",null,{"href":"https://arxiv.org","className":"text-blue-400 hover:text-blue-300","target":"_blank","rel":"noopener noreferrer","children":"ArXiv"}]," ¬∑ Categories: cs.AI, cs.CL, cs.LG"]}]
15:["$","$L49",null,{"children":["$","$4a",null,{"name":"Next.MetadataOutlet","children":"$@4b"}]}]
16:["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}]
17:["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]
18:["$","tr","2602.10009v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":11}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.10009v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Discovering High Level Patterns from Simulation Traces"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
19:["$","tr","2602.09782v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":11}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09782v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Flexible Entropy Control in RLVR with Gradient-Preserving Perspective"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
1a:["$","tr","2602.09621v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":11}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09621v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"AlignTune: Modular Toolkit for Post-Training Alignment of Large Language Models"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
1b:["$","tr","2602.09464v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":11}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09464v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"AlgoVeri: An Aligned Benchmark for Verified Code Generation on Classical Algorithms"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
1c:["$","tr","2602.09442v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":11}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09442v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Evaluating Social Bias in RAG Systems: When External Context Helps and Reasoning Hurts"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
1d:["$","tr","2602.09870v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":10}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09870v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Steer2Edit: From Activation Steering to Component-Level Editing"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
1e:["$","tr","2602.09856v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":10}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09856v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Code2World: A GUI World Model via Renderable Code Generation"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
1f:["$","tr","2602.09689v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":10}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09689v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Model soups need only one ingredient"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
20:["$","tr","2602.09485v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":10}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09485v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Bridging Efficiency and Transparency: Explainable CoT Compression in Multimodal Large Reasoning Models"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
21:["$","tr","2602.10117v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":9}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.10117v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Biases in the Blind Spot: Detecting What LLMs Fail to Mention"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
22:["$","tr","2602.10042v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":9}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.10042v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Fake-HR1: Rethinking reasoning of vision language model for synthetic image detection"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
23:["$","tr","2602.10021v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":9}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.10021v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Decoupled Reasoning with Implicit Fact Tokens (DRIFT): A Dual-Model Framework for Efficient Long-Context Inference"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
24:["$","tr","2602.09832v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":9}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09832v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"LLM Reasoning Predicts When Models Are Right: Evidence from Coding Classroom Discourse"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
25:["$","tr","2602.09501v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":9}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09501v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Where-to-Unmask: Ground-Truth-Guided Unmasking Order Learning for Masked Diffusion Language Models"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
26:["$","tr","2602.09416v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":9}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09416v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Are Language Models Sensitive to Morally Irrelevant Distractors?"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
27:["$","tr","2602.10095v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":8}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.10095v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Causality in Video Diffusers is Separable from Denoising"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
28:["$","tr","2602.10014v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":8}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.10014v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"A Task-Centric Theory for Iterative Self-Improvement with Easy-to-Hard Curricula"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
29:["$","tr","2602.10006v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":8}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.10006v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Answer First, Reason Later: Aligning Search Relevance via Mode-Balanced Reinforcement Learning"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
2a:["$","tr","2602.09953v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":8}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09953v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"ATTNPO: Attention-Guided Process Supervision for Efficient Reasoning"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
2b:["$","tr","2602.09924v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":8}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09924v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"LLMs Encode Their Failures: Predicting Success from Pre-Generation Activations"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
2c:["$","tr","2602.09877v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":8}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09877v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
2d:["$","tr","2602.09851v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":8}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09851v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"CoFEH: LLM-driven Feature Engineering Empowered by Collaborative Bayesian Hyperparameter Optimization"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
2e:["$","tr","2602.09823v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":8}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09823v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Covo-Audio Technical Report"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
2f:["$","tr","2602.09514v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":8}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09514v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"EcoGym: Evaluating LLMs for Long-Horizon Plan-and-Execute in Interactive Economies"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
30:["$","tr","2602.09961v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":7}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09961v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"ViMultiChoice: Toward a Method That Gives Explanation for Multiple-Choice Reading Comprehension in Vietnamese"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
31:["$","tr","2602.09914v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":7}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09914v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"AmharicIR+Instr: A Two-Dataset Resource for Neural Retrieval and Instruction Tuning"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
32:["$","tr","2602.09907v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":7}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09907v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Self-Regulated Reading with AI Support: An Eight-Week Study with Students"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
33:["$","tr","2602.09902v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":7}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09902v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Routing, Cascades, and User Choice for LLMs"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
34:["$","tr","2602.09821v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":7}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09821v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Text summarization via global structure awareness"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
35:["$","tr","2602.10100v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.10100v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Towards Explainable Federated Learning: Understanding the Impact of Differential Privacy"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
36:["$","tr","2602.10044v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.10044v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Optimistic World Models: Efficient Exploration in Model-Based Deep Reinforcement Learning"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
37:["$","tr","2602.10031v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.10031v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Position: Message-passing and spectral GNNs are two sides of the same coin"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
38:["$","tr","2602.10003v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.10003v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"ViSpeechFormer: A Phonemic Approach for Vietnamese Automatic Speech Recognition"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
39:["$","tr","2602.09987v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09987v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Infusion: Shaping Model Behavior by Editing Training Data via Influence Functions"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
3a:["$","tr","2602.09985v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09985v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Online Monitoring Framework for Automotive Time Series Data using JEPA Embeddings"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
3b:["$","tr","2602.09936v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09936v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"The Catastrophic Failure of The k-Means Algorithm in High Dimensions, and How Hartigan's Algorithm Avoids It"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
3c:["$","tr","2602.09933v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09933v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Unbalanced optimal transport for robust longitudinal lesion evolution with registration-aware and appearance-guided priors"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
3d:["$","tr","2602.09918v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09918v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"SARS: A Novel Face and Body Shape and Appearance Aware 3D Reconstruction System extends Morphable Models"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
3e:["$","tr","2602.09864v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09864v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Differentiable Tripartite Modularity for Clustering Heterogeneous Graphs"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
3f:["$","tr","2602.09848v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09848v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Robust Processing and Learning: Principles, Methods, and Wireless Applications"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
40:["$","tr","2602.09838v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09838v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"How Do People Quantify Naturally: Evidence from Mandarin Picture Description"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"2d ago"}]]}]
41:["$","tr","2602.09748v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09748v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Linear Model Extraction via Factual and Counterfactual Queries"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
42:["$","tr","2602.09730v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09730v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Allure of Craquelure: A Variational-Generative Approach to Crack Detection in Paintings"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
43:["$","tr","2602.09718v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09718v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"SAQNN: Spectral Adaptive Quantum Neural Network as a Universal Approximator"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
44:["$","tr","2602.09708v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09708v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Physics-informed diffusion models in spectral space"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
45:["$","tr","2602.09651v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09651v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"The Entropic Signature of Class Speciation in Diffusion Models"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
46:["$","tr","2602.09639v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09639v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Blind denoising diffusion models and the blessings of dimensionality"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
47:["$","tr","2602.09620v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09620v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"FLINGO -- Instilling ASP Expressiveness into Linear Integer Constraints"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
48:["$","tr","2602.09613v1",{"className":"border-b border-white/[0.04] hover:bg-white/[0.02]","children":[["$","td",null,{"className":"py-2 pr-4 text-green-400 font-mono","children":0}],["$","td",null,{"className":"py-2 pr-4","children":["$","a",null,{"href":"https://arxiv.org/abs/2602.09613v1","target":"_blank","rel":"noopener noreferrer","className":"hover:text-white line-clamp-1","children":"Tracking Finite-Time Lyapunov Exponents to Robustify Neural ODEs"}]}],["$","td",null,{"className":"py-2 pr-4 hidden md:table-cell"}],["$","td",null,{"className":"py-2 text-zinc-500 whitespace-nowrap","children":"3d ago"}]]}]
4b:null
