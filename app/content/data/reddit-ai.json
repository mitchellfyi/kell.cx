{
  "scraped_at": "2026-02-25T05:29:21.961Z",
  "source": "rss",
  "subreddits": [
    "LocalLLaMA",
    "MachineLearning",
    "ClaudeAI",
    "ChatGPT",
    "singularity"
  ],
  "stats": {
    "total_fetched": 125,
    "relevant_count": 30,
    "other_count": 20
  },
  "relevant_posts": [
    {
      "subreddit": "ClaudeAI",
      "title": "Dario, don't drop the ethics, come to Europe",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1re3sbo/dario_dont_drop_the_ethics_come_to_europe/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1re3sbo/dario_dont_drop_the_ethics_come_to_europe/",
      "author": "/u/decixl",
      "created_utc": 1771995008,
      "selftext": "I understand true American values - what's happening right now isn't that. It's bully pressure dressed as patriotism. EU is old money, that's why innovation is stifled. But even those old billionaire grandpas understand what AI brings to the world - and they're scared enough to do anything to accommodate Anthropic. If it's money, they'll shower you with it. If it's privacy, Switzerland is waiting. Claude is better than any current model. It's the one fastest on the road to AGI. Don't let that...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "ChatGPT randomly switched to Arabic in its response",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1re3q5i/chatgpt_randomly_switched_to_arabic_in_its/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1re3q5i/chatgpt_randomly_switched_to_arabic_in_its/",
      "author": "/u/kakarotssj",
      "created_utc": 1771994823,
      "selftext": "ChatGPT randomly switched to Arabic for a few words in its response. The screen grab shows a part of the full response. This was a brand new chat with no previous prompting. The text translates to \"within the USA\" so it does make sense. &#32; submitted by &#32; /u/kakarotssj [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Is Qwen3.5 35b and 122b better than Qwen3 Coder Next 80b at Coding?",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1re3puw/is_qwen35_35b_and_122b_better_than_qwen3_coder/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1re3puw/is_qwen35_35b_and_122b_better_than_qwen3_coder/",
      "author": "/u/ClimateBoss",
      "created_utc": 1771994798,
      "selftext": "Thoughts on agentic coding? Do these Generic LLMs outperform Qwen3 Coder Next 80b ? Qwen3.5 122b Qwen3.5 35b Qwen3 Coder Next 80b Which do you like? what languages did you try? &#32; submitted by &#32; /u/ClimateBoss [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "discussion",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Qwen3-30B-A3B vs Qwen3.5-35B-A3B on RTX 5090",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1re3l3r/qwen330ba3b_vs_qwen3535ba3b_on_rtx_5090/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1re3l3r/qwen330ba3b_vs_qwen3535ba3b_on_rtx_5090/",
      "author": "/u/3spky5u-oss",
      "created_utc": 1771994392,
      "selftext": "Qwen3-30B-A3B vs Qwen3.5-35B-A3B on RTX 5090 — Day-1 Extended Benchmark (Q4_K_M, llama.cpp) Qwen3.5-35B-A3B dropped today. Same MoE architecture as the 30B (3B active params), 5B more total parameters, and ships with a vision projector. Grabbed the Q4_K_M, ran it head-to-head against my daily driver Qwen3-30B-A3B through 7 test sections. All automated, same prompts, same hardware, same server config. TL;DR: The 3.5 is ~32% slower in raw generation but handles long context significantly better...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "benchmark",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "Twitter post claims Claude now can function across PPT and Excel",
      "permalink": "https://www.reddit.com/r/singularity/comments/1re2tho/twitter_post_claims_claude_now_can_function/",
      "url": "https://www.reddit.com/r/singularity/comments/1re2tho/twitter_post_claims_claude_now_can_function/",
      "author": "/u/NotMyMainLoLzy",
      "created_utc": 1771992148,
      "selftext": "https://x.com/unusual\\_whales/status/2026335244257767670?s=20 White collar America is not prepared. &#32; submitted by &#32; /u/NotMyMainLoLzy [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "You can use Qwen3.5 without thinking",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1re1b4a/you_can_use_qwen35_without_thinking/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1re1b4a/you_can_use_qwen35_without_thinking/",
      "author": "/u/guiopen",
      "created_utc": 1771987969,
      "selftext": "Just add --chat-template-kwargs '{\"enable_thinking\": false}' to llama.cpp server Also, remember to update your parameters to better suit the instruct mode, this is what qwen recommends: --repeat-penalty 1.0 --presence-penalty 1.5 --min-p 0.0 --top-k 20 --top-p 0.8 --temp 0.7 Overall it is still very good in instruct mode, I didn't noticed a huge performance drop like what happens in glm flash &#32; submitted by &#32; /u/guiopen [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Blown Away By Qwen 3.5 35b A3B",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1re17th/blown_away_by_qwen_35_35b_a3b/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1re17th/blown_away_by_qwen_35_35b_a3b/",
      "author": "/u/Jordanthecomeback",
      "created_utc": 1771987718,
      "selftext": "I bought a 64gig mac setup ~5 days ago and had a miserable time finding anything good, I looked at advice, guides, tried them all, including Qwen 3, and nothing felt like a good fit for my long-context companion. My testing was an initial baseline process with 5 multi-stage questions to check it's ability to reference context data (which I paste into system prompt) and then I'd review their answers and have claude sonnet 4.6 do it too, so we had a lot of coverage on ~8 different models. GLM 4...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "PicoKittens/PicoMistral-23M: Pico-Sized Model",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1re0wtf/picokittenspicomistral23m_picosized_model/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1re0wtf/picokittenspicomistral23m_picosized_model/",
      "author": "/u/PicoKittens",
      "created_utc": 1771986900,
      "selftext": "We are introducing our first pico model: PicoMistral-23M . This is an ultra-compact, experimental model designed specifically to run on weak hardware or IoT edge devices where standard LLMs simply cannot operate. Despite its tiny footprint, it is capable of maintaining basic conversational structure and surprisingly solid grammar. Benchmark results below https://preview.redd.it/qaofoyxoyjlg1.png?width=989&amp;format=png&amp;auto=webp&amp;s=692df50b7d9b63b7fbbd388ede0b24718ed67a37 As this is a...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "Insufferable chat GPT.",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1re004i/insufferable_chat_gpt/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1re004i/insufferable_chat_gpt/",
      "author": "/u/Automatic_Buffalo_14",
      "created_utc": 1771984463,
      "selftext": "I need to be careful here but, I wonder how the CEO of openai is going to feel next quarter when it becomes apparent just how many people are abandoning chat GPT because if it's excessively patronizing psychoanalyzing thought-policing dismissive condescending gas-lighting guardrails that amount to an undisclosed non-consensual meta psychological evaluation and meta experimentstion on its users? Because all I see you on this forum is user after user saying that they've left chat GPT for Claude...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "If you give them an inch they will take a mile!",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rdzk1j/if_you_give_them_an_inch_they_will_take_a_mile/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rdzk1j/if_you_give_them_an_inch_they_will_take_a_mile/",
      "author": "/u/SubatomicGreenLeaves",
      "created_utc": 1771983265,
      "selftext": "To the Anthropic leadership team, I’m writing as a paying customer and daily user of Claude to say something simple: please do NOT back down!!! Your commitment to refusing mass surveillance and fully autonomous weapons isn’t “woke AI”, it’s the bare minimum of responsible technology development. These are principles that the vast majority of your customers support! I chose Anthropic specifically because you stand for something. OpenAI, Google, and xAI have already caved. If you do the same, t...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Claude’s reasoning is sometimes hilarious",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rdz5y6/claudes_reasoning_is_sometimes_hilarious/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rdz5y6/claudes_reasoning_is_sometimes_hilarious/",
      "author": "/u/polygirl1991",
      "created_utc": 1771982231,
      "selftext": "I usually don’t like the shortened thought processes but this was too good. &#32; submitted by &#32; /u/polygirl1991 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "New in Claude Code: Remote Control",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rdyhk4/new_in_claude_code_remote_control/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rdyhk4/new_in_claude_code_remote_control/",
      "author": "/u/bbt_rachel",
      "created_utc": 1771980513,
      "selftext": "Kick off a task in your terminal and pick it up from your phone while you take a walk or join a meeting. Claude keeps running on your machine, and you can control the session from the Claude app or claude.ai/code Source tweet: https://x.com/claudeai/status/2026418433911603668?s=46 &#32; submitted by &#32; /u/bbt_rachel [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "Jian Yang launches “Not Claude”",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rdxxgv/jian_yang_launches_not_claude/",
      "url": "https://www.reddit.com/r/singularity/comments/1rdxxgv/jian_yang_launches_not_claude/",
      "author": "/u/policyweb",
      "created_utc": 1771979124,
      "selftext": "&#32; submitted by &#32; /u/policyweb [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Qwen3.5-35B-A3B is a gamechanger for agentic coding.",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rdxfdu/qwen3535ba3b_is_a_gamechanger_for_agentic_coding/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rdxfdu/qwen3535ba3b_is_a_gamechanger_for_agentic_coding/",
      "author": "/u/jslominski",
      "created_utc": 1771977884,
      "selftext": "Qwen3.5-35B-A3B with Opencode Just tested this badboy with Opencode cause frankly I couldn't believe those benchmarks. Running it on a single RTX 3090 on a headless Linux box. Freshly compiled Llama.cpp and those are my settings after some tweaking, still not fully tuned: ./llama.cpp/llama-server \\ -m /models/ Qwen3.5-35B-A3B-MXFP4_MOE.gguf \\ -a \"DrQwen\" \\ -c 131072 \\ -ngl all \\ -ctk q8_0 \\ -ctv q8_0 \\ -sm none \\ -mg 0 \\ -np 1 \\ -fa on Around 22 gigs of vram used. Now the fun part: I'm gettin...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "Anthropic has no intention of easing restrictions, per Reuters",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rdx53q/anthropic_has_no_intention_of_easing_restrictions/",
      "url": "https://www.reddit.com/r/singularity/comments/1rdx53q/anthropic_has_no_intention_of_easing_restrictions/",
      "author": "/u/exordin26",
      "created_utc": 1771977199,
      "selftext": "https://www.reuters.com/world/anthropic-digs-heels-dispute-with-pentagon-source-says-2026-02-24/ &#32; submitted by &#32; /u/exordin26 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "TIME: Anthropic Drops Flagship Safety Pledge",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rdwdld/time_anthropic_drops_flagship_safety_pledge/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rdwdld/time_anthropic_drops_flagship_safety_pledge/",
      "author": "/u/JollyQuiscalus",
      "created_utc": 1771975344,
      "selftext": "From the article: Anthropic, the wildly successful AI company that has cast itself as the most safety-conscious of the top research labs, is dropping the central pledge of its flagship safety policy, company officials tell TIME. In 2023, Anthropic committed to never train an AI system unless it could guarantee in advance that the company’s safety measures were adequate. For years, its leaders touted that promise—the central pillar of their Responsible Scaling Policy (RSP)—as evidence that the...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Bullshit Benchmark - A benchmark for testing whether models identify and push back on nonsensical prompts instead of confidently answering them",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rdw6pp/bullshit_benchmark_a_benchmark_for_testing/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rdw6pp/bullshit_benchmark_a_benchmark_for_testing/",
      "author": "/u/bot_exe",
      "created_utc": 1771974894,
      "selftext": "https://preview.redd.it/n7w95mmuyilg1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=6e87d1a7d9275935b2f552cfbb887ad6fe4dcf86 View the results: https://petergpt.github.io/bullshit-benchmark/viewer/index.html This is a pretty interesting benchmark. It’s measuring how much the model is willing to go along with obvious bullshit. That’s something that has always concerned me with LLMs, that they don’t call you out and instead just go along with it, basically self-inducing hallucinations for th...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "benchmark",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "GPT 5.2 versus GPT 5.3-Codex on MineBench",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rdw43i/gpt_52_versus_gpt_53codex_on_minebench/",
      "url": "https://www.reddit.com/r/singularity/comments/1rdw43i/gpt_52_versus_gpt_53codex_on_minebench/",
      "author": "/u/ENT_Alam",
      "created_utc": 1771974727,
      "selftext": "I expected GPT 5.3-Codex to do equally as bad as 5.2-Codex had on this benchmark, as the whole Codex series of models doesn't really seem trained to do well in this type of benchmark to begin with, but the results way better than I thought. Which is why I decided to post a comparison of GPT 5.2 versus GPT 5.3-Codex, as the 5.2-Codex model just isn't in the same league. Some Notes: This model was amazingly cheap to benchmark (on xhigh); less than ~$5 for all 15 builds (Opus 4.6 took over $60 i...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Bullshit Benchmark - A benchmark for testing whether models identify and push back on nonsensical prompts instead of confidently answering them",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rdw3rd/bullshit_benchmark_a_benchmark_for_testing/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rdw3rd/bullshit_benchmark_a_benchmark_for_testing/",
      "author": "/u/bot_exe",
      "created_utc": 1771974706,
      "selftext": "https://preview.redd.it/g8qfezc2yilg1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=598fdb7a7ed6f0e09d52729d92fbe5fe53fdd170 View the results: https://petergpt.github.io/bullshit-benchmark/viewer/index.html This is actually a pretty interesting benchmark. It’s measuring how much the model is willing to go along with obvious bullshit. That’s something that has always concerned me with LLMs, that they don’t call you out and instead just go along with it, basically self-inducing hallucinatio...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "benchmark",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Jian Yang launches Not Claude",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rdvvt0/jian_yang_launches_not_claude/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rdvvt0/jian_yang_launches_not_claude/",
      "author": "/u/policyweb",
      "created_utc": 1771974196,
      "selftext": "&#32; submitted by &#32; /u/policyweb [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Qwen3.5 27B is Match Made in Heaven for Size and Performance",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rdvq3s/qwen35_27b_is_match_made_in_heaven_for_size_and/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rdvq3s/qwen35_27b_is_match_made_in_heaven_for_size_and/",
      "author": "/u/Lopsided_Dot_4557",
      "created_utc": 1771973832,
      "selftext": "Just got Qwen3.5 27B running on server and wanted to share the full setup for anyone trying to do the same. Setup: Model: Qwen3.5-27B-Q8_0 (unsloth GGUF) , Thanks Dan GPU: RTX A6000 48GB Inference: llama.cpp with CUDA Context: 32K Speed: ~19.7 tokens/sec Why Q8 and not a lower quant? With 48GB VRAM the Q8 fits comfortably at 28.6GB leaving plenty of headroom for KV cache. Quality is virtually identical to full BF16 — no reason to go lower if your VRAM allows it. What's interesting about this ...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "FlashLM v6 \"SUPERNOVA\": 4.1M ternary model hits 3,500 tok/s on CPU — novel P-RCSM reasoning architecture, no attention, no convolution",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rdv74o/flashlm_v6_supernova_41m_ternary_model_hits_3500/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rdv74o/flashlm_v6_supernova_41m_ternary_model_hits_3500/",
      "author": "/u/Own-Albatross868",
      "created_utc": 1771972612,
      "selftext": "Back with v6. Some of you saw v5 “Thunderbolt” — 29.7M params, PPL 1.36, beat the TinyStories-1M baseline on a borrowed Ryzen 7950X3D (thanks again to arki05 for that machine). This time I went back to the free Deepnote notebook — 2 threads, 5GB RAM — and built a completely new architecture from scratch. What it is: 4.1M parameter language model with a novel architecture called P-RCSM (Parallel - Recursive Compositional State Machines). 81% of weights are ternary {-1, 0, +1}. Trained for ~3 h...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "I built an iOS app using Claude API that analyzes used car listings — 175K+ views on Reddit, zero paying customers. Here's what I learned.",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rdv2ar/i_built_an_ios_app_using_claude_api_that_analyzes/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rdv2ar/i_built_an_ios_app_using_claude_api_that_analyzes/",
      "author": "/u/DONTAIMX",
      "created_utc": 1771972316,
      "selftext": "Solo dev here. Wanted to share my experience building with Claude API because I think there are some real lessons in here for anyone shipping AI-powered apps. **What I built** The app is called Snag AI. You screenshot any used car listing from Facebook Marketplace, Craigslist, OfferUp, etc. and Claude API extracts the vehicle details, pulls fair market pricing from KBB/Edmunds, gives you a deal score out of 100, and generates 4 ready-to-send negotiation messages. Tech stack: React Native / Ex...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "Grok is wild",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rdurl0/grok_is_wild/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rdurl0/grok_is_wild/",
      "author": "/u/Early-Dentist3782",
      "created_utc": 1771971642,
      "selftext": "Imagine if chatgpt was like this &#32; submitted by &#32; /u/Early-Dentist3782 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Anthropic believes RSI (recursive self improvement) could arrive “as soon as early 2027”",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rduhxw/anthropic_believes_rsi_recursive_self_improvement/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rduhxw/anthropic_believes_rsi_recursive_self_improvement/",
      "author": "/u/Tolopono",
      "created_utc": 1771971039,
      "selftext": "https://www.anthropic.com/responsible-scaling-policy/roadmap &#32; submitted by &#32; /u/Tolopono [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "Anthropic believes RSI (recursive self improvement) could arrive “as soon as early 2027”",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rdufm4/anthropic_believes_rsi_recursive_self_improvement/",
      "url": "https://www.reddit.com/r/singularity/comments/1rdufm4/anthropic_believes_rsi_recursive_self_improvement/",
      "author": "/u/Tolopono",
      "created_utc": 1771970896,
      "selftext": "https://www.anthropic.com/responsible-scaling-policy/roadmap >We believe that AI models could, in the next few years, have a broad range of capabilities that exceed human capabilities. In particular, most or all of the work needed to advance research and development in key domains - from robotics to energy to cyberwarfare to AI R&amp;D itself - may become automatable.\" so ASI in the next few years according to their roadmap &#32; submitted by &#32; /u/Tolopono [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "Anthropic faces Friday deadline in Defense AI clash with Hegseth - Pentagon threatens ban for defense contractors or use of the Defense Production Act",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rdtmrp/anthropic_faces_friday_deadline_in_defense_ai/",
      "url": "https://www.reddit.com/r/singularity/comments/1rdtmrp/anthropic_faces_friday_deadline_in_defense_ai/",
      "author": "/u/Tinac4",
      "created_utc": 1771969146,
      "selftext": "&#32; submitted by &#32; /u/Tinac4 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "Guys, I think ChatGPT is onto something here.",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rdtd0y/guys_i_think_chatgpt_is_onto_something_here/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rdtd0y/guys_i_think_chatgpt_is_onto_something_here/",
      "author": "/u/-Sliced-",
      "created_utc": 1771968550,
      "selftext": "“Actual” conversation - https://chatgpt.com/share/699e178f-0540-8007-991a-f8daca4c4d6a &#32; submitted by &#32; /u/-Sliced- [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "\"This feels like it was human written\" : it wasn't. Voice extraction process for Claude Code, template included",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rdsnxi/this_feels_like_it_was_human_written_it_wasnt/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rdsnxi/this_feels_like_it_was_human_written_it_wasnt/",
      "author": "/u/gorinrockbow",
      "created_utc": 1771967040,
      "selftext": "A couple weeks ago I posted about my AI poisoning setup and someone immediately proved it doesn't work by asking Gemini about me. Turns out explaining your anti-AI defense system in detail on a public forum that AI crawlers index is not the 200 IQ move I thought it was. Lesson learned. But that post had an unintended side effect : someone commented \"this feels like it was human written and I am grateful\" and it was entirely AI-generated using a custom voice skill. A few people asked how it wa...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "Bullshit Benchmark - A benchmark for testing whether models identify and push back on nonsensical prompts instead of confidently answering them",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rdsf3r/bullshit_benchmark_a_benchmark_for_testing/",
      "url": "https://www.reddit.com/r/singularity/comments/1rdsf3r/bullshit_benchmark_a_benchmark_for_testing/",
      "author": "/u/likeastar20",
      "created_utc": 1771966529,
      "selftext": "https://x.com/scaling01/status/2026398199993258428?s=46 &#32; submitted by &#32; /u/likeastar20 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "benchmark",
      "is_relevant": true
    }
  ],
  "other_posts": [
    {
      "subreddit": "ChatGPT",
      "title": "​Wonder if he actually got the job.",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1re2vba/wonder_if_he_actually_got_the_job/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1re2vba/wonder_if_he_actually_got_the_job/",
      "author": "/u/LittleFortunex",
      "created_utc": 1771992293,
      "selftext": "&#32; submitted by &#32; /u/LittleFortunex [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "Seedance 2.0: Neo vs Agent Smith, The Matrix",
      "permalink": "https://www.reddit.com/r/singularity/comments/1re16tu/seedance_20_neo_vs_agent_smith_the_matrix/",
      "url": "https://www.reddit.com/r/singularity/comments/1re16tu/seedance_20_neo_vs_agent_smith_the_matrix/",
      "author": "/u/SadAd8761",
      "created_utc": 1771987650,
      "selftext": "&#32; submitted by &#32; /u/SadAd8761 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "benchmark",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "Is there a positive vision of the Singularity for normal people",
      "permalink": "https://www.reddit.com/r/singularity/comments/1re0gbu/is_there_a_positive_vision_of_the_singularity_for/",
      "url": "https://www.reddit.com/r/singularity/comments/1re0gbu/is_there_a_positive_vision_of_the_singularity_for/",
      "author": "/u/Kind_Score_3155",
      "created_utc": 1771985674,
      "selftext": "I am coming in peace as a relative normie on matters such as this and for some dialogue. I don't want to upload myself into a computer, I don't want to become a cyborg, I don't want to live forever. Space is cool, but I feel no deep yearning to colonize the galaxy or anything. I mostly want to have a nice, stable, middle class life where I marry a woman that I love, have kids and a dog. I enjoy reading books, going to the gym, watching sports, and spending time with friends/family. The other ...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "Made a pixel art version of my dog",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1re04fs/made_a_pixel_art_version_of_my_dog/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1re04fs/made_a_pixel_art_version_of_my_dog/",
      "author": "/u/Scottiedoesntno",
      "created_utc": 1771984789,
      "selftext": "&#32; submitted by &#32; /u/Scottiedoesntno [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "Would roleplay explode in a post-scarcity world?",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rdzjba/would_roleplay_explode_in_a_postscarcity_world/",
      "url": "https://www.reddit.com/r/singularity/comments/1rdzjba/would_roleplay_explode_in_a_postscarcity_world/",
      "author": "/u/Onipsis",
      "created_utc": 1771983212,
      "selftext": "I remember an animated Netflix series where a woman in her 40s spent the last months of her life hanging out with people who were roleplaying as office workers because, if I’m not mistaken, a meteor was about to hit the planet. That idea doesn’t even sound that crazy in a world where jobs no longer exist. I can easily imagine adult “Kidzania-style” theme parks where people pay to experience what it was like to work in old professions: corporate offices, factories, hospitals, whatever, just to...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "discussion",
      "is_relevant": false
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Things change fast in AI",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rdyr7y/things_change_fast_in_ai/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rdyr7y/things_change_fast_in_ai/",
      "author": "/u/Terrible-Priority-21",
      "created_utc": 1771981185,
      "selftext": "&#32; submitted by &#32; /u/Terrible-Priority-21 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "Best prompt?",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rdv11b/best_prompt/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rdv11b/best_prompt/",
      "author": "/u/Recent_Refuse_4282",
      "created_utc": 1771972233,
      "selftext": "&#32; submitted by &#32; /u/Recent_Refuse_4282 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "discussion",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "A not *entirely* crazy theory?",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rdtg8t/a_not_entirely_crazy_theory/",
      "url": "https://www.reddit.com/r/singularity/comments/1rdtg8t/a_not_entirely_crazy_theory/",
      "author": "/u/wseadowntown",
      "created_utc": 1771968749,
      "selftext": "&#32; submitted by &#32; /u/wseadowntown [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "discussion",
      "is_relevant": false
    },
    {
      "subreddit": "MachineLearning",
      "title": "[P] mlx-onnx: Run your MLX models in the browser using ONNX / WebGPU",
      "permalink": "https://www.reddit.com/r/MachineLearning/comments/1rdrurq/p_mlxonnx_run_your_mlx_models_in_the_browser/",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1rdrurq/p_mlxonnx_run_your_mlx_models_in_the_browser/",
      "author": "/u/rut216",
      "created_utc": 1771965289,
      "selftext": "Web Demo: https://skryl.github.io/mlx-ruby/demo/ Repo: https://github.com/skryl/mlx-onnx What My Project Does It allows you to convert MLX models into ONNX (onnxruntime, validation, downstream deployment). You can then run the onnx models in the browser using WebGPU. Exports MLX callables directly to ONNX Supports both Python and native C++ interfaces Target Audience Developers who want to run MLX-defined computations in ONNX tooling (e.g. ORT, WebGPU) Early adopters and contributors; this is...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "academic",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "more qwens will appear",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rdptw8/more_qwens_will_appear/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rdptw8/more_qwens_will_appear/",
      "author": "/u/jacek2023",
      "created_utc": 1771960941,
      "selftext": "(remember that 9B was promised before) &#32; submitted by &#32; /u/jacek2023 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Chinese AI Models Capture Majority of OpenRouter Token Volume as MiniMax M2.5 Surges to the Top",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rdpapc/chinese_ai_models_capture_majority_of_openrouter/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rdpapc/chinese_ai_models_capture_majority_of_openrouter/",
      "author": "/u/Koyaanisquatsi_",
      "created_utc": 1771959811,
      "selftext": "&#32; submitted by &#32; /u/Koyaanisquatsi_ [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "Please don’t say “and honestly?” anymore because I find it really annoying, thank you.",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rdol3t/please_dont_say_and_honestly_anymore_because_i/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rdol3t/please_dont_say_and_honestly_anymore_because_i/",
      "author": "/u/Binkybunwun",
      "created_utc": 1771958320,
      "selftext": "Sigh &#32; submitted by &#32; /u/Binkybunwun [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "discussion",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "Dictators as Boring Modern People",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rdo357/dictators_as_boring_modern_people/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rdo357/dictators_as_boring_modern_people/",
      "author": "/u/GormtheOld25",
      "created_utc": 1771957248,
      "selftext": "&#32; submitted by &#32; /u/GormtheOld25 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "In July last year I made a post here comparing the top models at the time at making SVGs of different kinds. This has been the progress just half a year later",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rdngag/in_july_last_year_i_made_a_post_here_comparing/",
      "url": "https://www.reddit.com/r/singularity/comments/1rdngag/in_july_last_year_i_made_a_post_here_comparing/",
      "author": "/u/enilea",
      "created_utc": 1771955936,
      "selftext": "&#32; submitted by &#32; /u/enilea [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "MachineLearning",
      "title": "[R] 91k production agent interactions (Feb 1–23, 2026): distribution shift toward tool-chain escalation + multimodal injection — notes on multilabel detection + evaluation",
      "permalink": "https://www.reddit.com/r/MachineLearning/comments/1rdm7gj/r_91k_production_agent_interactions_feb_123_2026/",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1rdm7gj/r_91k_production_agent_interactions_feb_123_2026/",
      "author": "/u/cyberamyntas",
      "created_utc": 1771953274,
      "selftext": "We've been running threat detection on production AI agent deployments and just published our second monthly report with some findings that might be interesting to the ML community. Dataset: 91,284 agent interactions across 47 unique deployments, month-to-date through Feb 23. Detection model is a Gemma-based 5-head multilabel classifier with a voting ensemble, covering threat family, technique, and harm classification. P95 inference latency is 189ms. Key findings from a methodology perspectiv...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "academic",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "Google brings ProducerAI into Google Labs as its official AI music creation platform",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rdm786/google_brings_producerai_into_google_labs_as_its/",
      "url": "https://www.reddit.com/r/singularity/comments/1rdm786/google_brings_producerai_into_google_labs_as_its/",
      "author": "/u/BuildwithVignesh",
      "created_utc": 1771953260,
      "selftext": "ProducerAI is now part of Google Labs as a music creation partner. Lets users create full songs from simple prompts. Supports lyrics, melody, arrangement, effects and genre blending. Powered by Google DeepMind models and uses preview version of Lyria 3 for high fidelity music generation. All outputs include SynthID watermarking. Source: Google AI labs &#32; submitted by &#32; /u/BuildwithVignesh [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "The constant “AI fail” gotcha posts are not harmless they’re training people to underestimate a real disruption",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rdlpnu/the_constant_ai_fail_gotcha_posts_are_not/",
      "url": "https://www.reddit.com/r/singularity/comments/1rdlpnu/the_constant_ai_fail_gotcha_posts_are_not/",
      "author": "/u/gibblesnbits160",
      "created_utc": 1771952250,
      "selftext": "&#32; submitted by &#32; /u/gibblesnbits160 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Qwen/Qwen3.5-122B-A10B · Hugging Face",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rdlc02/qwenqwen35122ba10b_hugging_face/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rdlc02/qwenqwen35122ba10b_hugging_face/",
      "author": "/u/coder543",
      "created_utc": 1771951453,
      "selftext": "&#32; submitted by &#32; /u/coder543 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Qwen/Qwen3.5-35B-A3B · Hugging Face",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rdlbvc/qwenqwen3535ba3b_hugging_face/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rdlbvc/qwenqwen3535ba3b_hugging_face/",
      "author": "/u/ekojsalim",
      "created_utc": 1771951445,
      "selftext": "&#32; submitted by &#32; /u/ekojsalim [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "Half this sub is pretty much ignorant by choice",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rdjn6f/half_this_sub_is_pretty_much_ignorant_by_choice/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rdjn6f/half_this_sub_is_pretty_much_ignorant_by_choice/",
      "author": "/u/Such--Balance",
      "created_utc": 1771947780,
      "selftext": "The number of posts blaiming ai for responding in x way, while you can easely instruct it any way you want because thats exactly one of the great things about this new tech is absolutely insane. There seems to be 2 types of users. Those that use it properly and those that keep driving their car into a brick wall while you can steer it away with little effort. The upvotes on those types of posts are a clear sign that the stupid are keeping themselves comfortably in their echochamber with no in...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    }
  ]
}