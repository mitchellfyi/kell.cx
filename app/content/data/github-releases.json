{
  "generatedAt": "2026-02-24T05:27:22.001Z",
  "source": "GitHub API",
  "reposTracked": 18,
  "recentCount": 35,
  "totalReleasesFound": 80,
  "recentReleases": [
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "litellm_presidio-dev-v1.81.15",
      "tag": "litellm_presidio-dev-v1.81.15",
      "url": "https://github.com/BerriAI/litellm/releases/tag/litellm_presidio-dev-v1.81.15",
      "publishedAt": "2026-02-24T05:08:16Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* feat: show proxy url in ModelHub by @janfrederickk in https://github.com/BerriAI/litellm/pull/21660\n* fix(bedrock): correct modelInput format for Converse API batch models by @hztBUAA in https://github.com/BerriAI/litellm/pull/21656\n* fix: only tag selected deployment in access g..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.23.0",
      "tag": "v2.23.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.23.0",
      "publishedAt": "2026-02-24T03:19:39Z",
      "isPrerelease": false,
      "body": "## 2.23.0 (2026-02-24)\n\nFull Changelog: [v2.22.0...v2.23.0](https://github.com/openai/openai-python/compare/v2.22.0...v2.23.0)\n\n### Features\n\n* **api:** add gpt-realtime-1.5 and gpt-audio-1.5 model options to realtime calls ([3300b61](https://github.com/openai/openai-python/commit/3300b61e1d5a34c9d2..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8140",
      "tag": "b8140",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8140",
      "publishedAt": "2026-02-24T02:15:00Z",
      "isPrerelease": false,
      "body": "<details open>\n\nhexagon refactor all Ops to use local context struct (#19819)\n\n* hexagon: refactor set/get/sum-rows ops to use local context\n\n* hexagon: refactor ROPE and Softmax Ops to use local context\n\nImproves performance a bit by precomputing things and saving in the context.\n\n* hexagon: refact..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.51",
      "tag": "v2.1.51",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.51",
      "publishedAt": "2026-02-24T01:40:58Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Added `claude remote-control` subcommand for external builds, enabling local environment serving for all users.\n- Updated plugin marketplace default git timeout from 30s to 120s and added `CLAUDE_CODE_PLUGIN_GIT_TIMEOUT_MS` to configure.\n- Added support for custom npm registries..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8138",
      "tag": "b8138",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8138",
      "publishedAt": "2026-02-23T21:09:34Z",
      "isPrerelease": false,
      "body": "<details open>\n\nvendor : update cpp-httplib to 0.34.0 (#19830)\n\nSigned-off-by: Adrien Gallouët <angt@huggingface.co>\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8138/llama-b8138-bin-macos-arm64.tar.gz)\n- [macOS Intel (x64)](htt..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.14.rc.1",
      "tag": "v1.81.14.rc.1",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.14.rc.1",
      "publishedAt": "2026-02-23T21:03:37Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* fix: remove list-to-str transformation from dashscope by @ZeroAurora in https://github.com/BerriAI/litellm/pull/21547\n* Uncomment response_model in user_info endpoint by @richardmcsong in https://github.com/BerriAI/litellm/pull/17430\n* fix: allow github aliases to reuse upstream ..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.14-nightly",
      "tag": "v1.81.14-nightly",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.14-nightly",
      "publishedAt": "2026-02-23T20:42:49Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* fix: remove list-to-str transformation from dashscope by @ZeroAurora in https://github.com/BerriAI/litellm/pull/21547\n* Uncomment response_model in user_info endpoint by @richardmcsong in https://github.com/BerriAI/litellm/pull/17430\n* fix: allow github aliases to reuse upstream ..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.22.0",
      "tag": "v2.22.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.22.0",
      "publishedAt": "2026-02-23T20:13:52Z",
      "isPrerelease": false,
      "body": "## 2.22.0 (2026-02-23)\n\nFull Changelog: [v2.21.0...v2.22.0](https://github.com/openai/openai-python/compare/v2.21.0...v2.22.0)\n\n### Features\n\n* **api:** websockets for responses api ([c01f6fb](https://github.com/openai/openai-python/commit/c01f6fb0d55b7454f73c4904ea7a1954553085dc))\n\n\n### Chores\n\n* *..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "litellm_idx-db-dev-v1.81.14",
      "tag": "litellm_idx-db-dev-v1.81.14",
      "url": "https://github.com/BerriAI/litellm/releases/tag/litellm_idx-db-dev-v1.81.14",
      "publishedAt": "2026-02-23T15:10:15Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* ci: split slow test matrix groups to reduce CI wall-clock time by @jquinter in https://github.com/BerriAI/litellm/pull/21674\n* feat: upgrade duplicate issue detection to be AI-powered instead of title text by @ryan-crabbe in https://github.com/BerriAI/litellm/pull/21606\n* [Test] ..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-core==1.2.15",
      "tag": "langchain-core==1.2.15",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-core%3D%3D1.2.15",
      "publishedAt": "2026-02-23T15:05:04Z",
      "isPrerelease": false,
      "body": "Changes since langchain-core==1.2.14\n\nfix(core): improve error message for non-JSON-serializable tool schemas (#34376)\nfix(core): improve typing/docs for on_chat_model_start to clarify required positional args (#35324)\nperf(core): defer specific `langsmith` imports to reduce import time (#35298)\nrev..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8133",
      "tag": "b8133",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8133",
      "publishedAt": "2026-02-23T06:58:47Z",
      "isPrerelease": false,
      "body": "<details open>\n\nllama : remove write/read of output ids/logits/embeddings (#18862)\n\n* llama : remove write/read of output ids/logits/embeddings\n\nThis commit removes the write/read of output ids, logits and\nembeddings from the llama context state.\n\nRefs: https://github.com/ggml-org/llama.cpp/pull/188..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8132",
      "tag": "b8132",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8132",
      "publishedAt": "2026-02-23T00:01:57Z",
      "isPrerelease": false,
      "body": "<details open>\n\ncli : provide model with text filename (#19783)\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8132/llama-b8132-bin-macos-arm64.tar.gz)\n- [macOS Intel (x64)](https://github.com/ggml-org/llama.cpp/releases/download/..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8131",
      "tag": "b8131",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8131",
      "publishedAt": "2026-02-22T21:34:07Z",
      "isPrerelease": false,
      "body": "<details open>\n\njinja: correct stats for tojson and string filters (#19785)\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8131/llama-b8131-bin-macos-arm64.tar.gz)\n- [macOS Intel (x64)](https://github.com/ggml-org/llama.cpp/releas..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.12-stable",
      "tag": "v1.81.12-stable",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.12-stable",
      "publishedAt": "2026-02-21T22:46:10Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.12.rc.1...v1.81.12-stable"
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.17.0",
      "tag": "v0.17.0",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.17.0",
      "publishedAt": "2026-02-21T06:40:46Z",
      "isPrerelease": false,
      "body": "## OpenClaw\n\nOpenClaw can now be installed and configured automatically via Ollama, making it the easiest way to get up and running with OpenClaw with open models like Kimi-K2.5, GLM-5, and Minimax-M2.5.\n\n### Get started\n\n`ollama launch openclaw`\n\n<img width=\"2368\" height=\"1830\" alt=\"oc1\" src=\"https..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.50",
      "tag": "v2.1.50",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.50",
      "publishedAt": "2026-02-20T23:48:57Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Added support for `startupTimeout` configuration for LSP servers\n- Added `WorktreeCreate` and `WorktreeRemove` hook events, enabling custom VCS setup and teardown when agent worktree isolation creates or removes worktrees.\n- Fixed a bug where resumed sessions could be invisible ..."
    },
    {
      "repo": "JetBrains/intellij-community",
      "company": "JetBrains",
      "category": "ide",
      "name": "idea/2025.3.3",
      "tag": "idea/2025.3.3",
      "url": "https://github.com/JetBrains/intellij-community/releases/tag/idea/2025.3.3",
      "publishedAt": "2026-02-20T17:45:29Z",
      "isPrerelease": false,
      "body": "Release notes are available [here](https://youtrack.jetbrains.com/articles/IDEA-A-2100662633)"
    },
    {
      "repo": "JetBrains/intellij-community",
      "company": "JetBrains",
      "category": "ide",
      "name": "pycharm/2025.3.3",
      "tag": "pycharm/2025.3.3",
      "url": "https://github.com/JetBrains/intellij-community/releases/tag/pycharm/2025.3.3",
      "publishedAt": "2026-02-20T09:14:29Z",
      "isPrerelease": false,
      "body": "Release notes are available [here](https://youtrack.jetbrains.com/articles/PY-A-233538520)"
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026 Recovery 5",
      "tag": "1.109.5",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.5",
      "publishedAt": "2026-02-20T00:20:02Z",
      "isPrerelease": false,
      "body": "The update addresses these [issues\n](https://github.com/microsoft/vscode/milestone/378?closed=1).\n\nFor the complete release notes go to [Updates](https://code.visualstudio.com/updates/v1_109) on [code.visualstudio.com](https://code.visualstudio.com/)."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.49",
      "tag": "v2.1.49",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.49",
      "publishedAt": "2026-02-19T23:28:27Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Fixed Ctrl+C and ESC being silently ignored when background agents are running and the main thread is idle. Pressing twice within 3 seconds now kills all background agents.\n- Fixed prompt suggestion cache regression that reduced cache hit rates.\n- Fixed `plugin enable` and `plug..."
    }
  ],
  "allReleases": [
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "litellm_presidio-dev-v1.81.15",
      "tag": "litellm_presidio-dev-v1.81.15",
      "url": "https://github.com/BerriAI/litellm/releases/tag/litellm_presidio-dev-v1.81.15",
      "publishedAt": "2026-02-24T05:08:16Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* feat: show proxy url in ModelHub by @janfrederickk in https://github.com/BerriAI/litellm/pull/21660\n* fix(bedrock): correct modelInput format for Converse API batch models by @hztBUAA in https://github.com/BerriAI/litellm/pull/21656\n* fix: only tag selected deployment in access g..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.23.0",
      "tag": "v2.23.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.23.0",
      "publishedAt": "2026-02-24T03:19:39Z",
      "isPrerelease": false,
      "body": "## 2.23.0 (2026-02-24)\n\nFull Changelog: [v2.22.0...v2.23.0](https://github.com/openai/openai-python/compare/v2.22.0...v2.23.0)\n\n### Features\n\n* **api:** add gpt-realtime-1.5 and gpt-audio-1.5 model options to realtime calls ([3300b61](https://github.com/openai/openai-python/commit/3300b61e1d5a34c9d2..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8140",
      "tag": "b8140",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8140",
      "publishedAt": "2026-02-24T02:15:00Z",
      "isPrerelease": false,
      "body": "<details open>\n\nhexagon refactor all Ops to use local context struct (#19819)\n\n* hexagon: refactor set/get/sum-rows ops to use local context\n\n* hexagon: refactor ROPE and Softmax Ops to use local context\n\nImproves performance a bit by precomputing things and saving in the context.\n\n* hexagon: refact..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.51",
      "tag": "v2.1.51",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.51",
      "publishedAt": "2026-02-24T01:40:58Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Added `claude remote-control` subcommand for external builds, enabling local environment serving for all users.\n- Updated plugin marketplace default git timeout from 30s to 120s and added `CLAUDE_CODE_PLUGIN_GIT_TIMEOUT_MS` to configure.\n- Added support for custom npm registries..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8138",
      "tag": "b8138",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8138",
      "publishedAt": "2026-02-23T21:09:34Z",
      "isPrerelease": false,
      "body": "<details open>\n\nvendor : update cpp-httplib to 0.34.0 (#19830)\n\nSigned-off-by: Adrien Gallouët <angt@huggingface.co>\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8138/llama-b8138-bin-macos-arm64.tar.gz)\n- [macOS Intel (x64)](htt..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.14.rc.1",
      "tag": "v1.81.14.rc.1",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.14.rc.1",
      "publishedAt": "2026-02-23T21:03:37Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* fix: remove list-to-str transformation from dashscope by @ZeroAurora in https://github.com/BerriAI/litellm/pull/21547\n* Uncomment response_model in user_info endpoint by @richardmcsong in https://github.com/BerriAI/litellm/pull/17430\n* fix: allow github aliases to reuse upstream ..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.14-nightly",
      "tag": "v1.81.14-nightly",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.14-nightly",
      "publishedAt": "2026-02-23T20:42:49Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* fix: remove list-to-str transformation from dashscope by @ZeroAurora in https://github.com/BerriAI/litellm/pull/21547\n* Uncomment response_model in user_info endpoint by @richardmcsong in https://github.com/BerriAI/litellm/pull/17430\n* fix: allow github aliases to reuse upstream ..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.22.0",
      "tag": "v2.22.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.22.0",
      "publishedAt": "2026-02-23T20:13:52Z",
      "isPrerelease": false,
      "body": "## 2.22.0 (2026-02-23)\n\nFull Changelog: [v2.21.0...v2.22.0](https://github.com/openai/openai-python/compare/v2.21.0...v2.22.0)\n\n### Features\n\n* **api:** websockets for responses api ([c01f6fb](https://github.com/openai/openai-python/commit/c01f6fb0d55b7454f73c4904ea7a1954553085dc))\n\n\n### Chores\n\n* *..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "litellm_idx-db-dev-v1.81.14",
      "tag": "litellm_idx-db-dev-v1.81.14",
      "url": "https://github.com/BerriAI/litellm/releases/tag/litellm_idx-db-dev-v1.81.14",
      "publishedAt": "2026-02-23T15:10:15Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* ci: split slow test matrix groups to reduce CI wall-clock time by @jquinter in https://github.com/BerriAI/litellm/pull/21674\n* feat: upgrade duplicate issue detection to be AI-powered instead of title text by @ryan-crabbe in https://github.com/BerriAI/litellm/pull/21606\n* [Test] ..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-core==1.2.15",
      "tag": "langchain-core==1.2.15",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-core%3D%3D1.2.15",
      "publishedAt": "2026-02-23T15:05:04Z",
      "isPrerelease": false,
      "body": "Changes since langchain-core==1.2.14\n\nfix(core): improve error message for non-JSON-serializable tool schemas (#34376)\nfix(core): improve typing/docs for on_chat_model_start to clarify required positional args (#35324)\nperf(core): defer specific `langsmith` imports to reduce import time (#35298)\nrev..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8133",
      "tag": "b8133",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8133",
      "publishedAt": "2026-02-23T06:58:47Z",
      "isPrerelease": false,
      "body": "<details open>\n\nllama : remove write/read of output ids/logits/embeddings (#18862)\n\n* llama : remove write/read of output ids/logits/embeddings\n\nThis commit removes the write/read of output ids, logits and\nembeddings from the llama context state.\n\nRefs: https://github.com/ggml-org/llama.cpp/pull/188..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8132",
      "tag": "b8132",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8132",
      "publishedAt": "2026-02-23T00:01:57Z",
      "isPrerelease": false,
      "body": "<details open>\n\ncli : provide model with text filename (#19783)\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8132/llama-b8132-bin-macos-arm64.tar.gz)\n- [macOS Intel (x64)](https://github.com/ggml-org/llama.cpp/releases/download/..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8131",
      "tag": "b8131",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8131",
      "publishedAt": "2026-02-22T21:34:07Z",
      "isPrerelease": false,
      "body": "<details open>\n\njinja: correct stats for tojson and string filters (#19785)\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8131/llama-b8131-bin-macos-arm64.tar.gz)\n- [macOS Intel (x64)](https://github.com/ggml-org/llama.cpp/releas..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.12-stable",
      "tag": "v1.81.12-stable",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.12-stable",
      "publishedAt": "2026-02-21T22:46:10Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.12.rc.1...v1.81.12-stable"
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.17.0",
      "tag": "v0.17.0",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.17.0",
      "publishedAt": "2026-02-21T06:40:46Z",
      "isPrerelease": false,
      "body": "## OpenClaw\n\nOpenClaw can now be installed and configured automatically via Ollama, making it the easiest way to get up and running with OpenClaw with open models like Kimi-K2.5, GLM-5, and Minimax-M2.5.\n\n### Get started\n\n`ollama launch openclaw`\n\n<img width=\"2368\" height=\"1830\" alt=\"oc1\" src=\"https..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.50",
      "tag": "v2.1.50",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.50",
      "publishedAt": "2026-02-20T23:48:57Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Added support for `startupTimeout` configuration for LSP servers\n- Added `WorktreeCreate` and `WorktreeRemove` hook events, enabling custom VCS setup and teardown when agent worktree isolation creates or removes worktrees.\n- Fixed a bug where resumed sessions could be invisible ..."
    },
    {
      "repo": "JetBrains/intellij-community",
      "company": "JetBrains",
      "category": "ide",
      "name": "idea/2025.3.3",
      "tag": "idea/2025.3.3",
      "url": "https://github.com/JetBrains/intellij-community/releases/tag/idea/2025.3.3",
      "publishedAt": "2026-02-20T17:45:29Z",
      "isPrerelease": false,
      "body": "Release notes are available [here](https://youtrack.jetbrains.com/articles/IDEA-A-2100662633)"
    },
    {
      "repo": "JetBrains/intellij-community",
      "company": "JetBrains",
      "category": "ide",
      "name": "pycharm/2025.3.3",
      "tag": "pycharm/2025.3.3",
      "url": "https://github.com/JetBrains/intellij-community/releases/tag/pycharm/2025.3.3",
      "publishedAt": "2026-02-20T09:14:29Z",
      "isPrerelease": false,
      "body": "Release notes are available [here](https://youtrack.jetbrains.com/articles/PY-A-233538520)"
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026 Recovery 5",
      "tag": "1.109.5",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.5",
      "publishedAt": "2026-02-20T00:20:02Z",
      "isPrerelease": false,
      "body": "The update addresses these [issues\n](https://github.com/microsoft/vscode/milestone/378?closed=1).\n\nFor the complete release notes go to [Updates](https://code.visualstudio.com/updates/v1_109) on [code.visualstudio.com](https://code.visualstudio.com/)."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.49",
      "tag": "v2.1.49",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.49",
      "publishedAt": "2026-02-19T23:28:27Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Fixed Ctrl+C and ESC being silently ignored when background agents are running and the main thread is idle. Pressing twice within 3 seconds now kills all background agents.\n- Fixed prompt suggestion cache regression that reduced cache hit rates.\n- Fixed `plugin enable` and `plug..."
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.16.3",
      "tag": "v0.16.3",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.16.3",
      "publishedAt": "2026-02-19T22:11:27Z",
      "isPrerelease": false,
      "body": "## What's Changed\n*  New `ollama launch cline` added for the Cline CLI\n* `ollama launch <integration>` will now always show the model picker\n* Added Gemma 3, Llama and Qwen 3 architectures to MLX runner\n\n## New Contributors\n* @hellosaumil made their first contribution in https://github.com/ollama/ol..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.83.0",
      "tag": "v0.83.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.83.0",
      "publishedAt": "2026-02-19T19:26:11Z",
      "isPrerelease": false,
      "body": "## 0.83.0 (2026-02-19)\n\nFull Changelog: [v0.82.0...v0.83.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.82.0...v0.83.0)\n\n### Features\n\n* **api:** Add top-level cache control (automatic caching) ([a940123](https://github.com/anthropics/anthropic-sdk-python/commit/a940123da34ac33f0b6..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-core==1.2.14",
      "tag": "langchain-core==1.2.14",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-core%3D%3D1.2.14",
      "publishedAt": "2026-02-19T14:22:50Z",
      "isPrerelease": false,
      "body": "Changes since langchain-core==1.2.13\n\nrelease(core): 1.2.14 (#35328)\nchore(core): remove `langserve` from sys info util, add `deepagents` (#35325)\nfix(core): fix merge_lists incorrectly merging parallel tool calls (#35281)\nfix(core): accept int temperature in _get_ls_params for LangSmith tracing (#3..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-text-splitters==1.1.1",
      "tag": "langchain-text-splitters==1.1.1",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-text-splitters%3D%3D1.1.1",
      "publishedAt": "2026-02-18T23:03:00Z",
      "isPrerelease": false,
      "body": "Changes since langchain-text-splitters==1.1.0\n\nrelease(text-splitters): 1.1.1 (#35318)\nfix(text-splitters): prevent JSFrameworkTextSplitter from mutating self._separators on each split_text() call (#35316)\nchore: bump transformers from 5.1.0 to 5.2.0 in /libs/text-splitters in the other-deps group a..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.47",
      "tag": "v2.1.47",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.47",
      "publishedAt": "2026-02-18T21:38:45Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Fixed FileWriteTool line counting to preserve intentional trailing blank lines instead of stripping them with `trimEnd()`.\n- Fixed Windows terminal rendering bugs caused by `os.EOL` (`\\r\\n`) in display code — line counts now show correct values instead of always showing 1 on Win..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.82.0",
      "tag": "v0.82.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.82.0",
      "publishedAt": "2026-02-18T20:24:48Z",
      "isPrerelease": false,
      "body": "## 0.82.0 (2026-02-18)\n\nFull Changelog: [v0.81.0...v0.82.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.81.0...v0.82.0)\n\n### Features\n\n* **api:** fix shared UserLocation and error code types ([da3b931](https://github.com/anthropics/anthropic-sdk-python/commit/da3b931a2be768d77c228a..."
    },
    {
      "repo": "run-llama/llama_index",
      "company": "LlamaIndex",
      "category": "framework",
      "name": "v0.14.15",
      "tag": "v0.14.15",
      "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.15",
      "publishedAt": "2026-02-18T19:06:42Z",
      "isPrerelease": false,
      "body": "# Release Notes\n\n## [2026-02-18]\n\n### llama-index-agent-agentmesh [0.1.0]\n\n- [Integration] AgentMesh: Trust Layer for LlamaIndex Agents ([#20644](https://github.com/run-llama/llama_index/pull/20644))\n\n### llama-index-core [0.14.15]\n\n- Support basic operations for multimodal types ([#20640](https://g..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-tests==1.1.5",
      "tag": "langchain-tests==1.1.5",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-tests%3D%3D1.1.5",
      "publishedAt": "2026-02-18T16:08:44Z",
      "isPrerelease": false,
      "body": "Changes since langchain-tests==1.1.4\n\nchore: bump the other-deps group across 3 directories with 2 updates (#35255)\nstyle: bump ruff version to 0.15 (#35042)\nchore(deps): bump langsmith from 0.4.56 to 0.6.3 in /libs/standard-tests (#35157)\nrelease(standard-tests): release 1.1.5 (#35139)\nchore(deps):..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.81.0",
      "tag": "v0.81.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.81.0",
      "publishedAt": "2026-02-18T04:00:28Z",
      "isPrerelease": false,
      "body": "## 0.81.0 (2026-02-18)\n\nFull Changelog: [v0.80.0...v0.81.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.80.0...v0.81.0)\n\n### Features\n\n* **api:** Make new tool versions available as top level tool types ([0a385c2](https://github.com/anthropics/anthropic-sdk-python/commit/0a385c29d2..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.2.16-vscode",
      "tag": "v1.2.16-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.2.16-vscode",
      "publishedAt": "2026-02-17T20:54:38Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* .continue/agents by @sestinj in https://github.com/continuedev/continue/pull/10233\n* .continue/agents p2 by @sestinj in https://github.com/continuedev/continue/pull/10235\n* feat: limited MCP App support by @RomneyDa in https://github.com/continuedev/continue/pull/10132\n* feat(cli..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.0.61-jetbrains",
      "tag": "v1.0.61-jetbrains",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.0.61-jetbrains",
      "publishedAt": "2026-02-17T20:35:59Z",
      "isPrerelease": true,
      "body": "## What's Changed\n* .continue/agents by @sestinj in https://github.com/continuedev/continue/pull/10233\n* .continue/agents p2 by @sestinj in https://github.com/continuedev/continue/pull/10235\n* feat: limited MCP App support by @RomneyDa in https://github.com/continuedev/continue/pull/10132\n* feat(cli..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.3.32-vscode",
      "tag": "v1.3.32-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.3.32-vscode",
      "publishedAt": "2026-02-17T20:35:24Z",
      "isPrerelease": true,
      "body": "## What's Changed\n* .continue/agents by @sestinj in https://github.com/continuedev/continue/pull/10233\n* .continue/agents p2 by @sestinj in https://github.com/continuedev/continue/pull/10235\n* feat: limited MCP App support by @RomneyDa in https://github.com/continuedev/continue/pull/10132\n* feat(cli..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.80.0",
      "tag": "v0.80.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.80.0",
      "publishedAt": "2026-02-17T19:25:53Z",
      "isPrerelease": false,
      "body": "## 0.80.0 (2026-02-17)\n\nFull Changelog: [v0.79.0...v0.80.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.79.0...v0.80.0)\n\n### Features\n\n* **api:** Releasing claude-sonnet-4-6 ([d518d6e](https://github.com/anthropics/anthropic-sdk-python/commit/d518d6ecede3d0638f0b14950dc2be8efa0b4ff..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.45",
      "tag": "v2.1.45",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.45",
      "publishedAt": "2026-02-17T18:53:52Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Added support for Claude Sonnet 4.6\n- Added support for reading `enabledPlugins` and `extraKnownMarketplaces` from `--add-dir` directories\n- Added `spinnerTipsOverride` setting to customize spinner tips — configure `tips` with an array of custom tip strings, and optionally set `..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-openai==1.1.10",
      "tag": "langchain-openai==1.1.10",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-openai%3D%3D1.1.10",
      "publishedAt": "2026-02-17T18:04:01Z",
      "isPrerelease": false,
      "body": "Changes since langchain-openai==1.1.9\n\nrelease(openai): 1.1.10 (#35292)\nfeat(openai): support automatic server-side compaction (#35212)\nfix(openai): add `model` property (#35284)\nfix(nomic,openai,perplexity): update pillow version to >= 12.1.1, <13.0.0 (#35254)\ndocs(openai): more nits (#35277)\ndocs(..."
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.16.2",
      "tag": "v0.16.2",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.16.2",
      "publishedAt": "2026-02-14T08:43:11Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* `ollama launch claude` now supports searching the web when using `:cloud` models\n* Fixed rendering issue when running `ollama` in PowerShell\n* New setting in Ollama's app makes it easier to disable cloud models for sensitive and private tasks where data cannot leave your computer..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.21.0",
      "tag": "v2.21.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.21.0",
      "publishedAt": "2026-02-14T00:11:26Z",
      "isPrerelease": false,
      "body": "## 2.21.0 (2026-02-13)\n\nFull Changelog: [v2.20.0...v2.21.0](https://github.com/openai/openai-python/compare/v2.20.0...v2.21.0)\n\n### Features\n\n* **api:** container network_policy and skills ([d19de2e](https://github.com/openai/openai-python/commit/d19de2ee5c74413f9dc52684b650df1898dee82b))\n\n\n### Bug ..."
    },
    {
      "repo": "vllm-project/vllm",
      "company": "vLLM",
      "category": "inference",
      "name": "v0.16.0",
      "tag": "v0.16.0",
      "url": "https://github.com/vllm-project/vllm/releases/tag/v0.16.0",
      "publishedAt": "2026-02-13T00:35:21Z",
      "isPrerelease": true,
      "body": "# vLLM v0.16.0\n\n## Highlights\n\nThis release features 440 commits from 203 contributors (7 new)!\n\n* **PyTorch 2.10 upgrade** (#30525). This is a breaking change for environment dependency.\n* **Async scheduling + Pipeline Parallelism** is now fully supported, delivering **30.8% E2E throughput improvem..."
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.16.1",
      "tag": "v0.16.1",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.16.1",
      "publishedAt": "2026-02-12T23:40:00Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* Installing Ollama via the `curl` install script on macOS will now only prompt for your password if its required\n* Installing Ollama via the `iem` install script in Windows will now show progress\n* Image generation models will now respect the `OLLAMA_LOAD_TIMEOUT` variable\n\n**Full..."
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.16.0",
      "tag": "v0.16.0",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.16.0",
      "publishedAt": "2026-02-12T01:19:43Z",
      "isPrerelease": false,
      "body": "## New models\n* [GLM-5](https://ollama.com/library/glm-5): A strong reasoning and agentic model from Z.ai with 744B total parameters (40B active), built for complex systems engineering and long-horizon tasks.\n* [MiniMax-M2.5](https://ollama.com/library/minimax-m2.5): a new state-of-the-art large lan..."
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026 Recovery 2",
      "tag": "1.109.2",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.2",
      "publishedAt": "2026-02-11T03:24:57Z",
      "isPrerelease": false,
      "body": "The update addresses these [issues](https://github.com/Microsoft/vscode/issues?q=is%3Aissue+milestone%3A%22January+2026+Recovery+2%22+is%3Aclosed+).\n\nFor the complete release notes go to [Updates](https://code.visualstudio.com/updates/v1_109) on [code.visualstudio.com](https://code.visualstudio.com)..."
    },
    {
      "repo": "run-llama/llama_index",
      "company": "LlamaIndex",
      "category": "framework",
      "name": "v0.14.14",
      "tag": "v0.14.14",
      "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.14",
      "publishedAt": "2026-02-10T23:08:46Z",
      "isPrerelease": false,
      "body": "# Release Notes\n\n## [2026-02-10]\n\n### llama-index-callbacks-wandb [0.4.2]\n\n- Fix potential crashes and improve security defaults in core components ([#20610](https://github.com/run-llama/llama_index/pull/20610))\n\n### llama-index-core [0.14.14]\n\n- fix: catch pydantic ValidationError in VectorStoreQue..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.20.0",
      "tag": "v2.20.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.20.0",
      "publishedAt": "2026-02-10T19:02:11Z",
      "isPrerelease": false,
      "body": "## 2.20.0 (2026-02-10)\n\nFull Changelog: [v2.19.0...v2.20.0](https://github.com/openai/openai-python/compare/v2.19.0...v2.20.0)\n\n### Features\n\n* **api:** support for images in batch api ([28edb6e](https://github.com/openai/openai-python/commit/28edb6e1b7eb30dbb7be49979cee7882e8889264))"
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026 Recovery 1",
      "tag": "1.109.1",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.1",
      "publishedAt": "2026-02-10T18:30:40Z",
      "isPrerelease": false,
      "body": "The update addresses these [issues](https://github.com/Microsoft/vscode/issues?q=is%3Aissue+milestone%3A%22January+2026+Recovery+1%22+is%3Aclosed+), including a fix for a security vulnerability.\n\nFor the complete release notes go to [Updates](https://code.visualstudio.com/updates/v1_109) on [code.vi..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.19.0",
      "tag": "v2.19.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.19.0",
      "publishedAt": "2026-02-10T18:20:53Z",
      "isPrerelease": false,
      "body": "## 2.19.0 (2026-02-10)\n\nFull Changelog: [v2.18.0...v2.19.0](https://github.com/openai/openai-python/compare/v2.18.0...v2.19.0)\n\n### Features\n\n* **api:** skills and hosted shell ([27fdf68](https://github.com/openai/openai-python/commit/27fdf6820655b5994e3c1eddb3c8d9344a8be744))\n\n\n### Chores\n\n* **inte..."
    },
    {
      "repo": "TabbyML/tabby",
      "company": "Tabby",
      "category": "self-hosted",
      "name": "next-alpha",
      "tag": "next-alpha",
      "url": "https://github.com/TabbyML/tabby/releases/tag/next-alpha",
      "publishedAt": "2026-02-09T10:49:36Z",
      "isPrerelease": true,
      "body": "This is an alpha version for Tabby dev,\nThis is only intended to be used internally."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.79.0",
      "tag": "v0.79.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.79.0",
      "publishedAt": "2026-02-07T18:05:51Z",
      "isPrerelease": false,
      "body": "## 0.79.0 (2026-02-07)\n\nFull Changelog: [v0.78.0...v0.79.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.78.0...v0.79.0)\n\n### Features\n\n* **api:** enabling fast-mode in claude-opus-4-6 ([5953ba7](https://github.com/anthropics/anthropic-sdk-python/commit/5953ba7b425ba113595de570bc8c6..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.2.15-vscode",
      "tag": "v1.2.15-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.2.15-vscode",
      "publishedAt": "2026-02-04T23:12:36Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* docs: update /info command description with usage statistics by @continue[bot] in https://github.com/continuedev/continue/pull/9071\n* chore(deps): bump undici from 7.16.0 to 7.18.2 in /binary by @dependabot[bot] in https://github.com/continuedev/continue/pull/9534\n* fix: add GH_T..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.3.31-vscode",
      "tag": "v1.3.31-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.3.31-vscode",
      "publishedAt": "2026-02-04T23:06:04Z",
      "isPrerelease": true,
      "body": "## What's Changed\n* fix(cli): flaky hub loader tests by @uinstinct in https://github.com/continuedev/continue/pull/9923\n* [Snyk] Upgrade @tiptap/extension-text from 2.26.1 to 2.27.1 by @sestinj in https://github.com/continuedev/continue/pull/9915\n* chore(deps): bump tar from 7.4.3 to 7.5.7 in /core ..."
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026",
      "tag": "1.109.0",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.0",
      "publishedAt": "2026-02-04T21:08:10Z",
      "isPrerelease": false,
      "body": "Welcome to the January 2026 release of Visual Studio Code. In this release, we are further evolving VS Code to make it the **home for multi-agent development**.\n\n* **Chat UX**: chat just feels better and snappier with faster streaming, improved reasoning results, and a revamped editor inline chat\n\n*..."
    }
  ],
  "repoStats": [
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "latestRelease": "litellm_presidio-dev-v1.81.15",
      "latestDate": "2026-02-24T05:08:16Z"
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "latestRelease": "v2.23.0",
      "latestDate": "2026-02-24T03:19:39Z"
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "latestRelease": "b8140",
      "latestDate": "2026-02-24T02:15:00Z"
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "latestRelease": "v2.1.51",
      "latestDate": "2026-02-24T01:40:58Z"
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "latestRelease": "langchain-core==1.2.15",
      "latestDate": "2026-02-23T15:05:04Z"
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "latestRelease": "v0.17.0",
      "latestDate": "2026-02-21T06:40:46Z"
    },
    {
      "repo": "JetBrains/intellij-community",
      "company": "JetBrains",
      "category": "ide",
      "latestRelease": "idea/2025.3.3",
      "latestDate": "2026-02-20T17:45:29Z"
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "latestRelease": "1.109.5",
      "latestDate": "2026-02-20T00:20:02Z"
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "latestRelease": "v0.83.0",
      "latestDate": "2026-02-19T19:26:11Z"
    },
    {
      "repo": "run-llama/llama_index",
      "company": "LlamaIndex",
      "category": "framework",
      "latestRelease": "v0.14.15",
      "latestDate": "2026-02-18T19:06:42Z"
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "latestRelease": "v1.3.32-vscode",
      "latestDate": "2026-02-17T20:35:24Z"
    },
    {
      "repo": "vllm-project/vllm",
      "company": "vLLM",
      "category": "inference",
      "latestRelease": "v0.16.0",
      "latestDate": "2026-02-13T00:35:21Z"
    },
    {
      "repo": "openai/tiktoken",
      "company": "OpenAI",
      "category": "tool",
      "latestRelease": "0.12.0",
      "latestDate": "2025-10-06T20:21:57Z"
    },
    {
      "repo": "Aider-AI/aider",
      "company": "Aider",
      "category": "cli",
      "latestRelease": "v0.86.0",
      "latestDate": "2025-08-09T17:42:19Z"
    },
    {
      "repo": "Exafunction/codeium",
      "company": "Codeium",
      "category": "extension",
      "latestRelease": "test-tag",
      "latestDate": "2024-06-17T16:04:28Z"
    },
    {
      "repo": "TabbyML/tabby",
      "company": "Tabby",
      "category": "self-hosted",
      "latestRelease": "nightly",
      "latestDate": "2023-09-08T01:39:25Z"
    }
  ]
}