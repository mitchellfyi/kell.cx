{
  "generatedAt": "2026-02-26T05:26:30.176Z",
  "source": "GitHub API",
  "reposTracked": 18,
  "recentCount": 31,
  "totalReleasesFound": 80,
  "recentReleases": [
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8157",
      "tag": "b8157",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8157",
      "publishedAt": "2026-02-26T03:08:19Z",
      "isPrerelease": false,
      "body": "<details open>\n\nsupport permuted, remove check s0/s10 (#19889)\n\nCo-authored-by: Neo Zhang Jianyu <jianyu.zhang@intel.com>\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8157/llama-b8157-bin-macos-arm64.tar.gz)\n- [macOS Intel (x64)..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.59",
      "tag": "v2.1.59",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.59",
      "publishedAt": "2026-02-26T00:59:24Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Claude automatically saves useful context to auto-memory. Manage with /memory\n- Added `/copy` command to show an interactive picker when code blocks are present, allowing selection of individual code blocks or the full response.\n- Improved \"always allow\" prefix suggestions for c..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8156",
      "tag": "b8156",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8156",
      "publishedAt": "2026-02-26T00:10:53Z",
      "isPrerelease": false,
      "body": "<details open>\n\nvulkan: check for memory overlap before doing fusion (#19768)\n\n* vulkan: check for memory overlap before doing fusion\n\n* Update ggml/src/ggml-vulkan/ggml-vulkan.cpp\n\n* address feedback\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/r..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8155",
      "tag": "b8155",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8155",
      "publishedAt": "2026-02-25T23:40:34Z",
      "isPrerelease": false,
      "body": "<details open>\n\ncommon : add more aliases for sampler CLI params (#19797)\n\n* common : add more aliases for sampler CLI params\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8155/llama-b8155-bin-macos-arm64.tar.gz)\n- [macOS Intel (..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8153",
      "tag": "b8153",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8153",
      "publishedAt": "2026-02-25T22:50:38Z",
      "isPrerelease": false,
      "body": "<details open>\n\nserver : enable multi-modal prompt caching (#19877)\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8153/llama-b8153-bin-macos-arm64.tar.gz)\n- [macOS Intel (x64)](https://github.com/ggml-org/llama.cpp/releases/downl..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8152",
      "tag": "b8152",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8152",
      "publishedAt": "2026-02-25T20:56:11Z",
      "isPrerelease": false,
      "body": "<details open>\n\nserver : support multi-modal context checkpoints (#19849)\n\n* Modify llama-memory-hybrid-iswa.cpp\n\n* Modify llama-memory-recurrent.cpp\n\n* Modify server-common.cpp\n\n* Modify server-common.h\n\n* Modify server-context.cpp\n\n* Modify server-task.h\n\n* Added comment to llama-memory-hybrid-isw..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.58",
      "tag": "v2.1.58",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.58",
      "publishedAt": "2026-02-25T20:00:11Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Expand Remote Control to more users"
    },
    {
      "repo": "vllm-project/vllm",
      "company": "vLLM",
      "category": "inference",
      "name": "v0.16.0",
      "tag": "v0.16.0",
      "url": "https://github.com/vllm-project/vllm/releases/tag/v0.16.0",
      "publishedAt": "2026-02-25T19:58:49Z",
      "isPrerelease": false,
      "body": "# vLLM v0.16.0\nPlease note that this release was branch cut on Feb 8, so any features added to vLLM after that date is not included.\n\n## Highlights\n\nThis release features 440 commits from 203 contributors (7 new)!\n\n* **Async scheduling + Pipeline Parallelism** is now fully supported, delivering **30..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-core==1.2.16",
      "tag": "langchain-core==1.2.16",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-core%3D%3D1.2.16",
      "publishedAt": "2026-02-25T16:27:43Z",
      "isPrerelease": false,
      "body": "Changes since langchain-core==1.2.15\n\nrelease(core): 1.2.16 (#35439)\nfix(core): treat empty tool chunk ids as missing in merge (#35414)"
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.56",
      "tag": "v2.1.56",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.56",
      "publishedAt": "2026-02-25T06:27:48Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- VS Code: Fixed another cause of \"command 'claude-vscode.editor.openLast' not found\" crashes"
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.84.0",
      "tag": "v0.84.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.84.0",
      "publishedAt": "2026-02-25T05:22:10Z",
      "isPrerelease": false,
      "body": "## 0.84.0 (2026-02-25)\n\nFull Changelog: [v0.83.0...v0.84.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.83.0...v0.84.0)\n\n### Features\n\n* **api:** change array_format to brackets ([925d2ad](https://github.com/anthropics/anthropic-sdk-python/commit/925d2ad6b76ad7c15de07b9b2768738775f..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.55",
      "tag": "v2.1.55",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.55",
      "publishedAt": "2026-02-25T03:15:51Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Fixed BashTool failing on Windows with EINVAL error"
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.53",
      "tag": "v2.1.53",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.53",
      "publishedAt": "2026-02-25T00:13:48Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Fixed a UI flicker where user input would briefly disappear after submission before the message rendered\n- Fixed bulk agent kill (ctrl+f) to send a single aggregate notification instead of one per agent, and to properly clear the command queue\n- Fixed graceful shutdown sometimes..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.6.rc.5",
      "tag": "v1.81.6.rc.5",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.6.rc.5",
      "publishedAt": "2026-02-24T21:30:01Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* fix(schema): remove duplicate LiteLLM_DeletedTeamTable definition by @ryan-crabbe in https://github.com/BerriAI/litellm/pull/22037\n* [Patch] Spend Logging in RC by @yuneng-jiang in https://github.com/BerriAI/litellm/pull/22038\n\n\n**Full Changelog**: https://github.com/BerriAI/lite..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.6.rc.4",
      "tag": "v1.81.6.rc.4",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.6.rc.4",
      "publishedAt": "2026-02-24T20:44:13Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.6.rc.1...v1.81.6.rc.4"
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.12-stable.1",
      "tag": "v1.81.12-stable.1",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.12-stable.1",
      "publishedAt": "2026-02-24T20:44:12Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* fix(mcp): backport StreamableHTTPSessionManager stateless fix to v1.81.12-stable by @michelligabriele in https://github.com/BerriAI/litellm/pull/22030\n\n\n**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.12-stable...v1.81.12-stable.1"
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.12-stable_gpt-5.3",
      "tag": "v1.81.12-stable_gpt-5.3",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.12-stable_gpt-5.3",
      "publishedAt": "2026-02-24T20:36:24Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.12-stable...v1.81.12-stable_gpt-5.3"
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.24.0",
      "tag": "v2.24.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.24.0",
      "publishedAt": "2026-02-24T20:01:29Z",
      "isPrerelease": false,
      "body": "## 2.24.0 (2026-02-24)\n\nFull Changelog: [v2.23.0...v2.24.0](https://github.com/openai/openai-python/compare/v2.23.0...v2.24.0)\n\n### Features\n\n* **api:** add phase ([391deb9](https://github.com/openai/openai-python/commit/391deb99f6a92e51bffb25efd8dfe367d144bb9d))\n\n\n### Bug Fixes\n\n* **api:** fix phas..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.15-nightly",
      "tag": "v1.81.15-nightly",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.15-nightly",
      "publishedAt": "2026-02-24T17:29:27Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/litellmv1.81.15.presidio.dev...v1.81.15-nightly"
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.17.1",
      "tag": "v0.17.1",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.17.1",
      "publishedAt": "2026-02-24T15:00:28Z",
      "isPrerelease": true,
      "body": "## What's Changed\n* models: add nemotron architecture support by @jmorganca in https://github.com/ollama/ollama/pull/14356\n* Avoid Excessive MLX Memory Usage by @jessegross in https://github.com/ollama/ollama/pull/14341\n* ui: use capability-based detection for web search by @hoyyeva in https://githu..."
    }
  ],
  "allReleases": [
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8157",
      "tag": "b8157",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8157",
      "publishedAt": "2026-02-26T03:08:19Z",
      "isPrerelease": false,
      "body": "<details open>\n\nsupport permuted, remove check s0/s10 (#19889)\n\nCo-authored-by: Neo Zhang Jianyu <jianyu.zhang@intel.com>\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8157/llama-b8157-bin-macos-arm64.tar.gz)\n- [macOS Intel (x64)..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.59",
      "tag": "v2.1.59",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.59",
      "publishedAt": "2026-02-26T00:59:24Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Claude automatically saves useful context to auto-memory. Manage with /memory\n- Added `/copy` command to show an interactive picker when code blocks are present, allowing selection of individual code blocks or the full response.\n- Improved \"always allow\" prefix suggestions for c..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8156",
      "tag": "b8156",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8156",
      "publishedAt": "2026-02-26T00:10:53Z",
      "isPrerelease": false,
      "body": "<details open>\n\nvulkan: check for memory overlap before doing fusion (#19768)\n\n* vulkan: check for memory overlap before doing fusion\n\n* Update ggml/src/ggml-vulkan/ggml-vulkan.cpp\n\n* address feedback\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/r..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8155",
      "tag": "b8155",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8155",
      "publishedAt": "2026-02-25T23:40:34Z",
      "isPrerelease": false,
      "body": "<details open>\n\ncommon : add more aliases for sampler CLI params (#19797)\n\n* common : add more aliases for sampler CLI params\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8155/llama-b8155-bin-macos-arm64.tar.gz)\n- [macOS Intel (..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8153",
      "tag": "b8153",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8153",
      "publishedAt": "2026-02-25T22:50:38Z",
      "isPrerelease": false,
      "body": "<details open>\n\nserver : enable multi-modal prompt caching (#19877)\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8153/llama-b8153-bin-macos-arm64.tar.gz)\n- [macOS Intel (x64)](https://github.com/ggml-org/llama.cpp/releases/downl..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8152",
      "tag": "b8152",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8152",
      "publishedAt": "2026-02-25T20:56:11Z",
      "isPrerelease": false,
      "body": "<details open>\n\nserver : support multi-modal context checkpoints (#19849)\n\n* Modify llama-memory-hybrid-iswa.cpp\n\n* Modify llama-memory-recurrent.cpp\n\n* Modify server-common.cpp\n\n* Modify server-common.h\n\n* Modify server-context.cpp\n\n* Modify server-task.h\n\n* Added comment to llama-memory-hybrid-isw..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.58",
      "tag": "v2.1.58",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.58",
      "publishedAt": "2026-02-25T20:00:11Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Expand Remote Control to more users"
    },
    {
      "repo": "vllm-project/vllm",
      "company": "vLLM",
      "category": "inference",
      "name": "v0.16.0",
      "tag": "v0.16.0",
      "url": "https://github.com/vllm-project/vllm/releases/tag/v0.16.0",
      "publishedAt": "2026-02-25T19:58:49Z",
      "isPrerelease": false,
      "body": "# vLLM v0.16.0\nPlease note that this release was branch cut on Feb 8, so any features added to vLLM after that date is not included.\n\n## Highlights\n\nThis release features 440 commits from 203 contributors (7 new)!\n\n* **Async scheduling + Pipeline Parallelism** is now fully supported, delivering **30..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-core==1.2.16",
      "tag": "langchain-core==1.2.16",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-core%3D%3D1.2.16",
      "publishedAt": "2026-02-25T16:27:43Z",
      "isPrerelease": false,
      "body": "Changes since langchain-core==1.2.15\n\nrelease(core): 1.2.16 (#35439)\nfix(core): treat empty tool chunk ids as missing in merge (#35414)"
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.56",
      "tag": "v2.1.56",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.56",
      "publishedAt": "2026-02-25T06:27:48Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- VS Code: Fixed another cause of \"command 'claude-vscode.editor.openLast' not found\" crashes"
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.84.0",
      "tag": "v0.84.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.84.0",
      "publishedAt": "2026-02-25T05:22:10Z",
      "isPrerelease": false,
      "body": "## 0.84.0 (2026-02-25)\n\nFull Changelog: [v0.83.0...v0.84.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.83.0...v0.84.0)\n\n### Features\n\n* **api:** change array_format to brackets ([925d2ad](https://github.com/anthropics/anthropic-sdk-python/commit/925d2ad6b76ad7c15de07b9b2768738775f..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.55",
      "tag": "v2.1.55",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.55",
      "publishedAt": "2026-02-25T03:15:51Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Fixed BashTool failing on Windows with EINVAL error"
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.53",
      "tag": "v2.1.53",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.53",
      "publishedAt": "2026-02-25T00:13:48Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Fixed a UI flicker where user input would briefly disappear after submission before the message rendered\n- Fixed bulk agent kill (ctrl+f) to send a single aggregate notification instead of one per agent, and to properly clear the command queue\n- Fixed graceful shutdown sometimes..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.6.rc.5",
      "tag": "v1.81.6.rc.5",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.6.rc.5",
      "publishedAt": "2026-02-24T21:30:01Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* fix(schema): remove duplicate LiteLLM_DeletedTeamTable definition by @ryan-crabbe in https://github.com/BerriAI/litellm/pull/22037\n* [Patch] Spend Logging in RC by @yuneng-jiang in https://github.com/BerriAI/litellm/pull/22038\n\n\n**Full Changelog**: https://github.com/BerriAI/lite..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.6.rc.4",
      "tag": "v1.81.6.rc.4",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.6.rc.4",
      "publishedAt": "2026-02-24T20:44:13Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.6.rc.1...v1.81.6.rc.4"
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.12-stable.1",
      "tag": "v1.81.12-stable.1",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.12-stable.1",
      "publishedAt": "2026-02-24T20:44:12Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* fix(mcp): backport StreamableHTTPSessionManager stateless fix to v1.81.12-stable by @michelligabriele in https://github.com/BerriAI/litellm/pull/22030\n\n\n**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.12-stable...v1.81.12-stable.1"
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.12-stable_gpt-5.3",
      "tag": "v1.81.12-stable_gpt-5.3",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.12-stable_gpt-5.3",
      "publishedAt": "2026-02-24T20:36:24Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.12-stable...v1.81.12-stable_gpt-5.3"
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.24.0",
      "tag": "v2.24.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.24.0",
      "publishedAt": "2026-02-24T20:01:29Z",
      "isPrerelease": false,
      "body": "## 2.24.0 (2026-02-24)\n\nFull Changelog: [v2.23.0...v2.24.0](https://github.com/openai/openai-python/compare/v2.23.0...v2.24.0)\n\n### Features\n\n* **api:** add phase ([391deb9](https://github.com/openai/openai-python/commit/391deb99f6a92e51bffb25efd8dfe367d144bb9d))\n\n\n### Bug Fixes\n\n* **api:** fix phas..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.15-nightly",
      "tag": "v1.81.15-nightly",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.15-nightly",
      "publishedAt": "2026-02-24T17:29:27Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/litellmv1.81.15.presidio.dev...v1.81.15-nightly"
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.17.1",
      "tag": "v0.17.1",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.17.1",
      "publishedAt": "2026-02-24T15:00:28Z",
      "isPrerelease": true,
      "body": "## What's Changed\n* models: add nemotron architecture support by @jmorganca in https://github.com/ollama/ollama/pull/14356\n* Avoid Excessive MLX Memory Usage by @jessegross in https://github.com/ollama/ollama/pull/14341\n* ui: use capability-based detection for web search by @hoyyeva in https://githu..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-anthropic==1.3.4",
      "tag": "langchain-anthropic==1.3.4",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-anthropic%3D%3D1.3.4",
      "publishedAt": "2026-02-24T13:54:19Z",
      "isPrerelease": false,
      "body": "Changes since langchain-anthropic==1.3.3\n\nrelease(anthropic): 1.3.4 (#35418)\nfix(anthropic): filter out common OpenAI Responses block types (#35417)\nfix(anthropic): update integration tests (#35396)\nrevert: add ChatAnthropicBedrockWrapper (#35371)\nfix(anthropic): replace retired model IDs in tests a..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.23.0",
      "tag": "v2.23.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.23.0",
      "publishedAt": "2026-02-24T03:19:39Z",
      "isPrerelease": false,
      "body": "## 2.23.0 (2026-02-24)\n\nFull Changelog: [v2.22.0...v2.23.0](https://github.com/openai/openai-python/compare/v2.22.0...v2.23.0)\n\n### Features\n\n* **api:** add gpt-realtime-1.5 and gpt-audio-1.5 model options to realtime calls ([3300b61](https://github.com/openai/openai-python/commit/3300b61e1d5a34c9d2..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.22.0",
      "tag": "v2.22.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.22.0",
      "publishedAt": "2026-02-23T20:13:52Z",
      "isPrerelease": false,
      "body": "## 2.22.0 (2026-02-23)\n\nFull Changelog: [v2.21.0...v2.22.0](https://github.com/openai/openai-python/compare/v2.21.0...v2.22.0)\n\n### Features\n\n* **api:** websockets for responses api ([c01f6fb](https://github.com/openai/openai-python/commit/c01f6fb0d55b7454f73c4904ea7a1954553085dc))\n\n\n### Chores\n\n* *..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-core==1.2.15",
      "tag": "langchain-core==1.2.15",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-core%3D%3D1.2.15",
      "publishedAt": "2026-02-23T15:05:04Z",
      "isPrerelease": false,
      "body": "Changes since langchain-core==1.2.14\n\nfix(core): improve error message for non-JSON-serializable tool schemas (#34376)\nfix(core): improve typing/docs for on_chat_model_start to clarify required positional args (#35324)\nperf(core): defer specific `langsmith` imports to reduce import time (#35298)\nrev..."
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.17.0",
      "tag": "v0.17.0",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.17.0",
      "publishedAt": "2026-02-21T06:40:46Z",
      "isPrerelease": false,
      "body": "## OpenClaw\n\nOpenClaw can now be installed and configured automatically via Ollama, making it the easiest way to get up and running with OpenClaw with open models like Kimi-K2.5, GLM-5, and Minimax-M2.5.\n\n### Get started\n\n`ollama launch openclaw`\n\n<img width=\"2368\" height=\"1830\" alt=\"oc1\" src=\"https..."
    },
    {
      "repo": "JetBrains/intellij-community",
      "company": "JetBrains",
      "category": "ide",
      "name": "idea/2025.3.3",
      "tag": "idea/2025.3.3",
      "url": "https://github.com/JetBrains/intellij-community/releases/tag/idea/2025.3.3",
      "publishedAt": "2026-02-20T17:45:29Z",
      "isPrerelease": false,
      "body": "Release notes are available [here](https://youtrack.jetbrains.com/articles/IDEA-A-2100662633)"
    },
    {
      "repo": "JetBrains/intellij-community",
      "company": "JetBrains",
      "category": "ide",
      "name": "pycharm/2025.3.3",
      "tag": "pycharm/2025.3.3",
      "url": "https://github.com/JetBrains/intellij-community/releases/tag/pycharm/2025.3.3",
      "publishedAt": "2026-02-20T09:14:29Z",
      "isPrerelease": false,
      "body": "Release notes are available [here](https://youtrack.jetbrains.com/articles/PY-A-233538520)"
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026 Recovery 5",
      "tag": "1.109.5",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.5",
      "publishedAt": "2026-02-20T00:20:02Z",
      "isPrerelease": false,
      "body": "The update addresses these [issues\n](https://github.com/microsoft/vscode/milestone/378?closed=1).\n\nFor the complete release notes go to [Updates](https://code.visualstudio.com/updates/v1_109) on [code.visualstudio.com](https://code.visualstudio.com/)."
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.16.3",
      "tag": "v0.16.3",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.16.3",
      "publishedAt": "2026-02-19T22:11:27Z",
      "isPrerelease": false,
      "body": "## What's Changed\n*  New `ollama launch cline` added for the Cline CLI\n* `ollama launch <integration>` will now always show the model picker\n* Added Gemma 3, Llama and Qwen 3 architectures to MLX runner\n\n## New Contributors\n* @hellosaumil made their first contribution in https://github.com/ollama/ol..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.83.0",
      "tag": "v0.83.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.83.0",
      "publishedAt": "2026-02-19T19:26:11Z",
      "isPrerelease": false,
      "body": "## 0.83.0 (2026-02-19)\n\nFull Changelog: [v0.82.0...v0.83.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.82.0...v0.83.0)\n\n### Features\n\n* **api:** Add top-level cache control (automatic caching) ([a940123](https://github.com/anthropics/anthropic-sdk-python/commit/a940123da34ac33f0b6..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-core==1.2.14",
      "tag": "langchain-core==1.2.14",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-core%3D%3D1.2.14",
      "publishedAt": "2026-02-19T14:22:50Z",
      "isPrerelease": false,
      "body": "Changes since langchain-core==1.2.13\n\nrelease(core): 1.2.14 (#35328)\nchore(core): remove `langserve` from sys info util, add `deepagents` (#35325)\nfix(core): fix merge_lists incorrectly merging parallel tool calls (#35281)\nfix(core): accept int temperature in _get_ls_params for LangSmith tracing (#3..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-text-splitters==1.1.1",
      "tag": "langchain-text-splitters==1.1.1",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-text-splitters%3D%3D1.1.1",
      "publishedAt": "2026-02-18T23:03:00Z",
      "isPrerelease": false,
      "body": "Changes since langchain-text-splitters==1.1.0\n\nrelease(text-splitters): 1.1.1 (#35318)\nfix(text-splitters): prevent JSFrameworkTextSplitter from mutating self._separators on each split_text() call (#35316)\nchore: bump transformers from 5.1.0 to 5.2.0 in /libs/text-splitters in the other-deps group a..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.82.0",
      "tag": "v0.82.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.82.0",
      "publishedAt": "2026-02-18T20:24:48Z",
      "isPrerelease": false,
      "body": "## 0.82.0 (2026-02-18)\n\nFull Changelog: [v0.81.0...v0.82.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.81.0...v0.82.0)\n\n### Features\n\n* **api:** fix shared UserLocation and error code types ([da3b931](https://github.com/anthropics/anthropic-sdk-python/commit/da3b931a2be768d77c228a..."
    },
    {
      "repo": "run-llama/llama_index",
      "company": "LlamaIndex",
      "category": "framework",
      "name": "v0.14.15",
      "tag": "v0.14.15",
      "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.15",
      "publishedAt": "2026-02-18T19:06:42Z",
      "isPrerelease": false,
      "body": "# Release Notes\n\n## [2026-02-18]\n\n### llama-index-agent-agentmesh [0.1.0]\n\n- [Integration] AgentMesh: Trust Layer for LlamaIndex Agents ([#20644](https://github.com/run-llama/llama_index/pull/20644))\n\n### llama-index-core [0.14.15]\n\n- Support basic operations for multimodal types ([#20640](https://g..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.81.0",
      "tag": "v0.81.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.81.0",
      "publishedAt": "2026-02-18T04:00:28Z",
      "isPrerelease": false,
      "body": "## 0.81.0 (2026-02-18)\n\nFull Changelog: [v0.80.0...v0.81.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.80.0...v0.81.0)\n\n### Features\n\n* **api:** Make new tool versions available as top level tool types ([0a385c2](https://github.com/anthropics/anthropic-sdk-python/commit/0a385c29d2..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.2.16-vscode",
      "tag": "v1.2.16-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.2.16-vscode",
      "publishedAt": "2026-02-17T20:54:38Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* .continue/agents by @sestinj in https://github.com/continuedev/continue/pull/10233\n* .continue/agents p2 by @sestinj in https://github.com/continuedev/continue/pull/10235\n* feat: limited MCP App support by @RomneyDa in https://github.com/continuedev/continue/pull/10132\n* feat(cli..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.0.61-jetbrains",
      "tag": "v1.0.61-jetbrains",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.0.61-jetbrains",
      "publishedAt": "2026-02-17T20:35:59Z",
      "isPrerelease": true,
      "body": "## What's Changed\n* .continue/agents by @sestinj in https://github.com/continuedev/continue/pull/10233\n* .continue/agents p2 by @sestinj in https://github.com/continuedev/continue/pull/10235\n* feat: limited MCP App support by @RomneyDa in https://github.com/continuedev/continue/pull/10132\n* feat(cli..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.3.32-vscode",
      "tag": "v1.3.32-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.3.32-vscode",
      "publishedAt": "2026-02-17T20:35:24Z",
      "isPrerelease": true,
      "body": "## What's Changed\n* .continue/agents by @sestinj in https://github.com/continuedev/continue/pull/10233\n* .continue/agents p2 by @sestinj in https://github.com/continuedev/continue/pull/10235\n* feat: limited MCP App support by @RomneyDa in https://github.com/continuedev/continue/pull/10132\n* feat(cli..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.80.0",
      "tag": "v0.80.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.80.0",
      "publishedAt": "2026-02-17T19:25:53Z",
      "isPrerelease": false,
      "body": "## 0.80.0 (2026-02-17)\n\nFull Changelog: [v0.79.0...v0.80.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.79.0...v0.80.0)\n\n### Features\n\n* **api:** Releasing claude-sonnet-4-6 ([d518d6e](https://github.com/anthropics/anthropic-sdk-python/commit/d518d6ecede3d0638f0b14950dc2be8efa0b4ff..."
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.16.2",
      "tag": "v0.16.2",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.16.2",
      "publishedAt": "2026-02-14T08:43:11Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* `ollama launch claude` now supports searching the web when using `:cloud` models\n* Fixed rendering issue when running `ollama` in PowerShell\n* New setting in Ollama's app makes it easier to disable cloud models for sensitive and private tasks where data cannot leave your computer..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.21.0",
      "tag": "v2.21.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.21.0",
      "publishedAt": "2026-02-14T00:11:26Z",
      "isPrerelease": false,
      "body": "## 2.21.0 (2026-02-13)\n\nFull Changelog: [v2.20.0...v2.21.0](https://github.com/openai/openai-python/compare/v2.20.0...v2.21.0)\n\n### Features\n\n* **api:** container network_policy and skills ([d19de2e](https://github.com/openai/openai-python/commit/d19de2ee5c74413f9dc52684b650df1898dee82b))\n\n\n### Bug ..."
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.16.1",
      "tag": "v0.16.1",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.16.1",
      "publishedAt": "2026-02-12T23:40:00Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* Installing Ollama via the `curl` install script on macOS will now only prompt for your password if its required\n* Installing Ollama via the `iem` install script in Windows will now show progress\n* Image generation models will now respect the `OLLAMA_LOAD_TIMEOUT` variable\n\n**Full..."
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026 Recovery 2",
      "tag": "1.109.2",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.2",
      "publishedAt": "2026-02-11T03:24:57Z",
      "isPrerelease": false,
      "body": "The update addresses these [issues](https://github.com/Microsoft/vscode/issues?q=is%3Aissue+milestone%3A%22January+2026+Recovery+2%22+is%3Aclosed+).\n\nFor the complete release notes go to [Updates](https://code.visualstudio.com/updates/v1_109) on [code.visualstudio.com](https://code.visualstudio.com)..."
    },
    {
      "repo": "run-llama/llama_index",
      "company": "LlamaIndex",
      "category": "framework",
      "name": "v0.14.14",
      "tag": "v0.14.14",
      "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.14",
      "publishedAt": "2026-02-10T23:08:46Z",
      "isPrerelease": false,
      "body": "# Release Notes\n\n## [2026-02-10]\n\n### llama-index-callbacks-wandb [0.4.2]\n\n- Fix potential crashes and improve security defaults in core components ([#20610](https://github.com/run-llama/llama_index/pull/20610))\n\n### llama-index-core [0.14.14]\n\n- fix: catch pydantic ValidationError in VectorStoreQue..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.20.0",
      "tag": "v2.20.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.20.0",
      "publishedAt": "2026-02-10T19:02:11Z",
      "isPrerelease": false,
      "body": "## 2.20.0 (2026-02-10)\n\nFull Changelog: [v2.19.0...v2.20.0](https://github.com/openai/openai-python/compare/v2.19.0...v2.20.0)\n\n### Features\n\n* **api:** support for images in batch api ([28edb6e](https://github.com/openai/openai-python/commit/28edb6e1b7eb30dbb7be49979cee7882e8889264))"
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026 Recovery 1",
      "tag": "1.109.1",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.1",
      "publishedAt": "2026-02-10T18:30:40Z",
      "isPrerelease": false,
      "body": "The update addresses these [issues](https://github.com/Microsoft/vscode/issues?q=is%3Aissue+milestone%3A%22January+2026+Recovery+1%22+is%3Aclosed+), including a fix for a security vulnerability.\n\nFor the complete release notes go to [Updates](https://code.visualstudio.com/updates/v1_109) on [code.vi..."
    },
    {
      "repo": "TabbyML/tabby",
      "company": "Tabby",
      "category": "self-hosted",
      "name": "next-alpha",
      "tag": "next-alpha",
      "url": "https://github.com/TabbyML/tabby/releases/tag/next-alpha",
      "publishedAt": "2026-02-09T10:49:36Z",
      "isPrerelease": true,
      "body": "This is an alpha version for Tabby dev,\nThis is only intended to be used internally."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.2.15-vscode",
      "tag": "v1.2.15-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.2.15-vscode",
      "publishedAt": "2026-02-04T23:12:36Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* docs: update /info command description with usage statistics by @continue[bot] in https://github.com/continuedev/continue/pull/9071\n* chore(deps): bump undici from 7.16.0 to 7.18.2 in /binary by @dependabot[bot] in https://github.com/continuedev/continue/pull/9534\n* fix: add GH_T..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.3.31-vscode",
      "tag": "v1.3.31-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.3.31-vscode",
      "publishedAt": "2026-02-04T23:06:04Z",
      "isPrerelease": true,
      "body": "## What's Changed\n* fix(cli): flaky hub loader tests by @uinstinct in https://github.com/continuedev/continue/pull/9923\n* [Snyk] Upgrade @tiptap/extension-text from 2.26.1 to 2.27.1 by @sestinj in https://github.com/continuedev/continue/pull/9915\n* chore(deps): bump tar from 7.4.3 to 7.5.7 in /core ..."
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026",
      "tag": "1.109.0",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.0",
      "publishedAt": "2026-02-04T21:08:10Z",
      "isPrerelease": false,
      "body": "Welcome to the January 2026 release of Visual Studio Code. In this release, we are further evolving VS Code to make it the **home for multi-agent development**.\n\n* **Chat UX**: chat just feels better and snappier with faster streaming, improved reasoning results, and a revamped editor inline chat\n\n*..."
    }
  ],
  "repoStats": [
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "latestRelease": "b8157",
      "latestDate": "2026-02-26T03:08:19Z"
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "latestRelease": "v2.1.59",
      "latestDate": "2026-02-26T00:59:24Z"
    },
    {
      "repo": "vllm-project/vllm",
      "company": "vLLM",
      "category": "inference",
      "latestRelease": "v0.16.0",
      "latestDate": "2026-02-25T19:58:49Z"
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "latestRelease": "langchain-core==1.2.16",
      "latestDate": "2026-02-25T16:27:43Z"
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "latestRelease": "v0.84.0",
      "latestDate": "2026-02-25T05:22:10Z"
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "latestRelease": "v2.24.0",
      "latestDate": "2026-02-24T20:01:29Z"
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "latestRelease": "v1.81.15-nightly",
      "latestDate": "2026-02-24T17:29:27Z"
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "latestRelease": "v0.17.1",
      "latestDate": "2026-02-24T15:00:28Z"
    },
    {
      "repo": "JetBrains/intellij-community",
      "company": "JetBrains",
      "category": "ide",
      "latestRelease": "idea/2025.3.3",
      "latestDate": "2026-02-20T17:45:29Z"
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "latestRelease": "1.109.5",
      "latestDate": "2026-02-20T00:20:02Z"
    },
    {
      "repo": "run-llama/llama_index",
      "company": "LlamaIndex",
      "category": "framework",
      "latestRelease": "v0.14.15",
      "latestDate": "2026-02-18T19:06:42Z"
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "latestRelease": "v1.3.32-vscode",
      "latestDate": "2026-02-17T20:35:24Z"
    },
    {
      "repo": "openai/tiktoken",
      "company": "OpenAI",
      "category": "tool",
      "latestRelease": "0.12.0",
      "latestDate": "2025-10-06T20:21:57Z"
    },
    {
      "repo": "Aider-AI/aider",
      "company": "Aider",
      "category": "cli",
      "latestRelease": "v0.86.0",
      "latestDate": "2025-08-09T17:42:19Z"
    },
    {
      "repo": "Exafunction/codeium",
      "company": "Codeium",
      "category": "extension",
      "latestRelease": "test-tag",
      "latestDate": "2024-06-17T16:04:28Z"
    },
    {
      "repo": "TabbyML/tabby",
      "company": "Tabby",
      "category": "self-hosted",
      "latestRelease": "nightly",
      "latestDate": "2023-09-08T01:39:25Z"
    }
  ]
}