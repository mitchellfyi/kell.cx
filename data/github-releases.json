{
  "generatedAt": "2026-02-18T06:39:00.796Z",
  "source": "GitHub API",
  "reposTracked": 18,
  "recentCount": 28,
  "totalReleasesFound": 80,
  "recentReleases": [
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.81.0",
      "tag": "v0.81.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.81.0",
      "publishedAt": "2026-02-18T04:00:28Z",
      "isPrerelease": false,
      "body": "## 0.81.0 (2026-02-18)\n\nFull Changelog: [v0.80.0...v0.81.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.80.0...v0.81.0)\n\n### Features\n\n* **api:** Make new tool versions available as top level tool types ([0a385c2](https://github.com/anthropics/anthropic-sdk-python/commit/0a385c29d2..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.80.11.gemini-metadata.dev",
      "tag": "v1.80.11.gemini-metadata.dev",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.80.11.gemini-metadata.dev",
      "publishedAt": "2026-02-18T03:50:00Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.80.11-nightly...v1.80.11.gemini-metadata.dev"
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8087",
      "tag": "b8087",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8087",
      "publishedAt": "2026-02-18T00:32:12Z",
      "isPrerelease": false,
      "body": "<details open>\n\nopencl: refactor expm1 and softplus (#19404)\n\n* opencl: refactor expm1\n\n* opencl: refactor softplus\n\n* opencl: use h for half literals\n\n---------\n\nCo-authored-by: Li He <lih@qti.qualcomm.com>\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llam..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8086",
      "tag": "b8086",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8086",
      "publishedAt": "2026-02-17T22:42:42Z",
      "isPrerelease": false,
      "body": "<details open>\n\nopencl: optimize mean and sum_row kernels (#19614)\n\n* opencl: optimize mean and sum_row kernels\n\n* opencl: add comment for max subgroups\n\n* opencl: format\n\n---------\n\nCo-authored-by: Li He <lih@qti.qualcomm.com>\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://gith..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.2.16-vscode",
      "tag": "v1.2.16-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.2.16-vscode",
      "publishedAt": "2026-02-17T20:54:38Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* .continue/agents by @sestinj in https://github.com/continuedev/continue/pull/10233\n* .continue/agents p2 by @sestinj in https://github.com/continuedev/continue/pull/10235\n* feat: limited MCP App support by @RomneyDa in https://github.com/continuedev/continue/pull/10132\n* feat(cli..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.3-stable.sonnet-4-6",
      "tag": "v1.81.3-stable.sonnet-4-6",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.3-stable.sonnet-4-6",
      "publishedAt": "2026-02-17T20:40:47Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.3-stable...v1.81.3-stable.sonnet-4-6"
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.0.61-jetbrains",
      "tag": "v1.0.61-jetbrains",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.0.61-jetbrains",
      "publishedAt": "2026-02-17T20:35:59Z",
      "isPrerelease": true,
      "body": "## What's Changed\n* .continue/agents by @sestinj in https://github.com/continuedev/continue/pull/10233\n* .continue/agents p2 by @sestinj in https://github.com/continuedev/continue/pull/10235\n* feat: limited MCP App support by @RomneyDa in https://github.com/continuedev/continue/pull/10132\n* feat(cli..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.3.32-vscode",
      "tag": "v1.3.32-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.3.32-vscode",
      "publishedAt": "2026-02-17T20:35:24Z",
      "isPrerelease": true,
      "body": "## What's Changed\n* .continue/agents by @sestinj in https://github.com/continuedev/continue/pull/10233\n* .continue/agents p2 by @sestinj in https://github.com/continuedev/continue/pull/10235\n* feat: limited MCP App support by @RomneyDa in https://github.com/continuedev/continue/pull/10132\n* feat(cli..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.80.0",
      "tag": "v0.80.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.80.0",
      "publishedAt": "2026-02-17T19:25:53Z",
      "isPrerelease": false,
      "body": "## 0.80.0 (2026-02-17)\n\nFull Changelog: [v0.79.0...v0.80.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.79.0...v0.80.0)\n\n### Features\n\n* **api:** Releasing claude-sonnet-4-6 ([d518d6e](https://github.com/anthropics/anthropic-sdk-python/commit/d518d6ecede3d0638f0b14950dc2be8efa0b4ff..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.45",
      "tag": "v2.1.45",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.45",
      "publishedAt": "2026-02-17T18:53:52Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Added support for Claude Sonnet 4.6\n- Added support for reading `enabledPlugins` and `extraKnownMarketplaces` from `--add-dir` directories\n- Added `spinnerTipsOverride` setting to customize spinner tips — configure `tips` with an array of custom tip strings, and optionally set `..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-openai==1.1.10",
      "tag": "langchain-openai==1.1.10",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-openai%3D%3D1.1.10",
      "publishedAt": "2026-02-17T18:04:01Z",
      "isPrerelease": false,
      "body": "Changes since langchain-openai==1.1.9\n\nrelease(openai): 1.1.10 (#35292)\nfeat(openai): support automatic server-side compaction (#35212)\nfix(openai): add `model` property (#35284)\nfix(nomic,openai,perplexity): update pillow version to >= 12.1.1, <13.0.0 (#35254)\ndocs(openai): more nits (#35277)\ndocs(..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8083",
      "tag": "b8083",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8083",
      "publishedAt": "2026-02-17T13:09:01Z",
      "isPrerelease": false,
      "body": "<details open>\n\nggml: ggml-cpu: force-no-lto-for-cpu-feats (#19609)\n\nWhen LTO enabled in build environments it forces all builds to have LTO\nin place. But feature detection logic is fragile, and causing Illegal\ninstruction errors with lto. This disables LTO for the feature\ndetection code to prevent ..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8082",
      "tag": "b8082",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8082",
      "publishedAt": "2026-02-17T11:57:04Z",
      "isPrerelease": false,
      "body": "<details open>\n\ncuda : enable CUDA graphs for MMID 1 <= BS <= 4 (#19645)\n\n* cuda : enable CUDA graphs for MMID BS <= 4\n\n* cont : add stream capture check\n\nCo-authored-by: Oliver Simons <osimons@nvidia.com>\n\n* cont : add MMVQ_MMID_MAX_BATCH_SIZE\n\n---------\n\nCo-authored-by: Oliver Simons <osimons@nvid..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8079",
      "tag": "b8079",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8079",
      "publishedAt": "2026-02-17T10:26:55Z",
      "isPrerelease": false,
      "body": "<details open>\n\nbuild : link ws2_32 as PUBLIC on Windows (#19666)\n\nSigned-off-by: Adrien Gallouët <adrien@gallouet.fr>\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8079/llama-b8079-bin-macos-arm64.tar.gz)\n- [macOS Intel (x64)](h..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.13-nightly",
      "tag": "v1.81.13-nightly",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.13-nightly",
      "publishedAt": "2026-02-17T04:37:57Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* [Feature] UI - Keys/Teams: Add Access Group Selector to Create and Edit Flow by @yuneng-jiang in https://github.com/BerriAI/litellm/pull/21234\n* [Fix] Preserve key_alias and team_id metadata in /user/daily/activity/aggregated after key deletion or regeneration by @shivamrawat1 in..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.13",
      "tag": "v1.81.13",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.13",
      "publishedAt": "2026-02-17T02:33:04Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* [Feature] UI - Keys/Teams: Add Access Group Selector to Create and Edit Flow by @yuneng-jiang in https://github.com/BerriAI/litellm/pull/21234\n* [Fix] Preserve key_alias and team_id metadata in /user/daily/activity/aggregated after key deletion or regeneration by @shivamrawat1 in..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.44",
      "tag": "v2.1.44",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.44",
      "publishedAt": "2026-02-16T21:35:03Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Fixed auth refresh errors"
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-openrouter==0.0.2",
      "tag": "langchain-openrouter==0.0.2",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-openrouter%3D%3D0.0.2",
      "publishedAt": "2026-02-15T08:50:46Z",
      "isPrerelease": false,
      "body": "Changes since langchain-openrouter==0.0.1\n\nchore(openrouter): bump core ver, silence warning (#35231)"
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-core==1.2.13",
      "tag": "langchain-core==1.2.13",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-core%3D%3D1.2.13",
      "publishedAt": "2026-02-15T07:46:09Z",
      "isPrerelease": false,
      "body": "Changes since langchain-core==1.2.12\n\nrelease(core): 1.2.13 (#35230)\ndocs(core): expanded `get_lc_namespace` docstring (#35229)\nfeat(openrouter): add `langchain-openrouter` provider package (#35211)\nstyle: bump ruff version to 0.15 (#35042)"
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.12.rc.1",
      "tag": "v1.81.12.rc.1",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.12.rc.1",
      "publishedAt": "2026-02-15T02:48:24Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.12-nightly...v1.81.12.rc.1"
    }
  ],
  "allReleases": [
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.81.0",
      "tag": "v0.81.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.81.0",
      "publishedAt": "2026-02-18T04:00:28Z",
      "isPrerelease": false,
      "body": "## 0.81.0 (2026-02-18)\n\nFull Changelog: [v0.80.0...v0.81.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.80.0...v0.81.0)\n\n### Features\n\n* **api:** Make new tool versions available as top level tool types ([0a385c2](https://github.com/anthropics/anthropic-sdk-python/commit/0a385c29d2..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.80.11.gemini-metadata.dev",
      "tag": "v1.80.11.gemini-metadata.dev",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.80.11.gemini-metadata.dev",
      "publishedAt": "2026-02-18T03:50:00Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.80.11-nightly...v1.80.11.gemini-metadata.dev"
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8087",
      "tag": "b8087",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8087",
      "publishedAt": "2026-02-18T00:32:12Z",
      "isPrerelease": false,
      "body": "<details open>\n\nopencl: refactor expm1 and softplus (#19404)\n\n* opencl: refactor expm1\n\n* opencl: refactor softplus\n\n* opencl: use h for half literals\n\n---------\n\nCo-authored-by: Li He <lih@qti.qualcomm.com>\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llam..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8086",
      "tag": "b8086",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8086",
      "publishedAt": "2026-02-17T22:42:42Z",
      "isPrerelease": false,
      "body": "<details open>\n\nopencl: optimize mean and sum_row kernels (#19614)\n\n* opencl: optimize mean and sum_row kernels\n\n* opencl: add comment for max subgroups\n\n* opencl: format\n\n---------\n\nCo-authored-by: Li He <lih@qti.qualcomm.com>\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://gith..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.2.16-vscode",
      "tag": "v1.2.16-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.2.16-vscode",
      "publishedAt": "2026-02-17T20:54:38Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* .continue/agents by @sestinj in https://github.com/continuedev/continue/pull/10233\n* .continue/agents p2 by @sestinj in https://github.com/continuedev/continue/pull/10235\n* feat: limited MCP App support by @RomneyDa in https://github.com/continuedev/continue/pull/10132\n* feat(cli..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.3-stable.sonnet-4-6",
      "tag": "v1.81.3-stable.sonnet-4-6",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.3-stable.sonnet-4-6",
      "publishedAt": "2026-02-17T20:40:47Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.3-stable...v1.81.3-stable.sonnet-4-6"
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.0.61-jetbrains",
      "tag": "v1.0.61-jetbrains",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.0.61-jetbrains",
      "publishedAt": "2026-02-17T20:35:59Z",
      "isPrerelease": true,
      "body": "## What's Changed\n* .continue/agents by @sestinj in https://github.com/continuedev/continue/pull/10233\n* .continue/agents p2 by @sestinj in https://github.com/continuedev/continue/pull/10235\n* feat: limited MCP App support by @RomneyDa in https://github.com/continuedev/continue/pull/10132\n* feat(cli..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.3.32-vscode",
      "tag": "v1.3.32-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.3.32-vscode",
      "publishedAt": "2026-02-17T20:35:24Z",
      "isPrerelease": true,
      "body": "## What's Changed\n* .continue/agents by @sestinj in https://github.com/continuedev/continue/pull/10233\n* .continue/agents p2 by @sestinj in https://github.com/continuedev/continue/pull/10235\n* feat: limited MCP App support by @RomneyDa in https://github.com/continuedev/continue/pull/10132\n* feat(cli..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.80.0",
      "tag": "v0.80.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.80.0",
      "publishedAt": "2026-02-17T19:25:53Z",
      "isPrerelease": false,
      "body": "## 0.80.0 (2026-02-17)\n\nFull Changelog: [v0.79.0...v0.80.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.79.0...v0.80.0)\n\n### Features\n\n* **api:** Releasing claude-sonnet-4-6 ([d518d6e](https://github.com/anthropics/anthropic-sdk-python/commit/d518d6ecede3d0638f0b14950dc2be8efa0b4ff..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.45",
      "tag": "v2.1.45",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.45",
      "publishedAt": "2026-02-17T18:53:52Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Added support for Claude Sonnet 4.6\n- Added support for reading `enabledPlugins` and `extraKnownMarketplaces` from `--add-dir` directories\n- Added `spinnerTipsOverride` setting to customize spinner tips — configure `tips` with an array of custom tip strings, and optionally set `..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-openai==1.1.10",
      "tag": "langchain-openai==1.1.10",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-openai%3D%3D1.1.10",
      "publishedAt": "2026-02-17T18:04:01Z",
      "isPrerelease": false,
      "body": "Changes since langchain-openai==1.1.9\n\nrelease(openai): 1.1.10 (#35292)\nfeat(openai): support automatic server-side compaction (#35212)\nfix(openai): add `model` property (#35284)\nfix(nomic,openai,perplexity): update pillow version to >= 12.1.1, <13.0.0 (#35254)\ndocs(openai): more nits (#35277)\ndocs(..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8083",
      "tag": "b8083",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8083",
      "publishedAt": "2026-02-17T13:09:01Z",
      "isPrerelease": false,
      "body": "<details open>\n\nggml: ggml-cpu: force-no-lto-for-cpu-feats (#19609)\n\nWhen LTO enabled in build environments it forces all builds to have LTO\nin place. But feature detection logic is fragile, and causing Illegal\ninstruction errors with lto. This disables LTO for the feature\ndetection code to prevent ..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8082",
      "tag": "b8082",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8082",
      "publishedAt": "2026-02-17T11:57:04Z",
      "isPrerelease": false,
      "body": "<details open>\n\ncuda : enable CUDA graphs for MMID 1 <= BS <= 4 (#19645)\n\n* cuda : enable CUDA graphs for MMID BS <= 4\n\n* cont : add stream capture check\n\nCo-authored-by: Oliver Simons <osimons@nvidia.com>\n\n* cont : add MMVQ_MMID_MAX_BATCH_SIZE\n\n---------\n\nCo-authored-by: Oliver Simons <osimons@nvid..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8079",
      "tag": "b8079",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8079",
      "publishedAt": "2026-02-17T10:26:55Z",
      "isPrerelease": false,
      "body": "<details open>\n\nbuild : link ws2_32 as PUBLIC on Windows (#19666)\n\nSigned-off-by: Adrien Gallouët <adrien@gallouet.fr>\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8079/llama-b8079-bin-macos-arm64.tar.gz)\n- [macOS Intel (x64)](h..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.13-nightly",
      "tag": "v1.81.13-nightly",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.13-nightly",
      "publishedAt": "2026-02-17T04:37:57Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* [Feature] UI - Keys/Teams: Add Access Group Selector to Create and Edit Flow by @yuneng-jiang in https://github.com/BerriAI/litellm/pull/21234\n* [Fix] Preserve key_alias and team_id metadata in /user/daily/activity/aggregated after key deletion or regeneration by @shivamrawat1 in..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.13",
      "tag": "v1.81.13",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.13",
      "publishedAt": "2026-02-17T02:33:04Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* [Feature] UI - Keys/Teams: Add Access Group Selector to Create and Edit Flow by @yuneng-jiang in https://github.com/BerriAI/litellm/pull/21234\n* [Fix] Preserve key_alias and team_id metadata in /user/daily/activity/aggregated after key deletion or regeneration by @shivamrawat1 in..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.44",
      "tag": "v2.1.44",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.44",
      "publishedAt": "2026-02-16T21:35:03Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Fixed auth refresh errors"
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-openrouter==0.0.2",
      "tag": "langchain-openrouter==0.0.2",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-openrouter%3D%3D0.0.2",
      "publishedAt": "2026-02-15T08:50:46Z",
      "isPrerelease": false,
      "body": "Changes since langchain-openrouter==0.0.1\n\nchore(openrouter): bump core ver, silence warning (#35231)"
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-core==1.2.13",
      "tag": "langchain-core==1.2.13",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-core%3D%3D1.2.13",
      "publishedAt": "2026-02-15T07:46:09Z",
      "isPrerelease": false,
      "body": "Changes since langchain-core==1.2.12\n\nrelease(core): 1.2.13 (#35230)\ndocs(core): expanded `get_lc_namespace` docstring (#35229)\nfeat(openrouter): add `langchain-openrouter` provider package (#35211)\nstyle: bump ruff version to 0.15 (#35042)"
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.12.rc.1",
      "tag": "v1.81.12.rc.1",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.12.rc.1",
      "publishedAt": "2026-02-15T02:48:24Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.12-nightly...v1.81.12.rc.1"
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.16.2",
      "tag": "v0.16.2",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.16.2",
      "publishedAt": "2026-02-14T08:43:11Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* `ollama launch claude` now supports searching the web when using `:cloud` models\n* Fixed rendering issue when running `ollama` in PowerShell\n* New setting in Ollama's app makes it easier to disable cloud models for sensitive and private tasks where data cannot leave your computer..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.21.0",
      "tag": "v2.21.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.21.0",
      "publishedAt": "2026-02-14T00:11:26Z",
      "isPrerelease": false,
      "body": "## 2.21.0 (2026-02-13)\n\nFull Changelog: [v2.20.0...v2.21.0](https://github.com/openai/openai-python/compare/v2.20.0...v2.21.0)\n\n### Features\n\n* **api:** container network_policy and skills ([d19de2e](https://github.com/openai/openai-python/commit/d19de2ee5c74413f9dc52684b650df1898dee82b))\n\n\n### Bug ..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.42",
      "tag": "v2.1.42",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.42",
      "publishedAt": "2026-02-13T19:56:33Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Fixed /resume showing interrupt messages as session titles\n- Fixed Opus 4.6 launch announcement showing for Bedrock/Vertex/Foundry users\n- Improved error message for many-image dimension limit errors with /compact suggestion"
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.41",
      "tag": "v2.1.41",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.41",
      "publishedAt": "2026-02-13T06:08:49Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Fixed AWS auth refresh hanging indefinitely by adding a 3-minute timeout\n- Added `claude auth login`, `claude auth status`, and `claude auth logout` CLI subcommands\n- Added Windows ARM64 (win32-arm64) native binary support\n- Improved `/rename` to auto-generate session name from ..."
    },
    {
      "repo": "vllm-project/vllm",
      "company": "vLLM",
      "category": "inference",
      "name": "v0.16.0",
      "tag": "v0.16.0",
      "url": "https://github.com/vllm-project/vllm/releases/tag/v0.16.0",
      "publishedAt": "2026-02-13T00:35:21Z",
      "isPrerelease": true,
      "body": "# vLLM v0.16.0\n\n## Highlights\n\nThis release features 440 commits from 203 contributors (7 new)!\n\n* **PyTorch 2.10 upgrade** (#30525). This is a breaking change for environment dependency.\n* **Async scheduling + Pipeline Parallelism** is now fully supported, delivering **30.8% E2E throughput improvem..."
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.16.1",
      "tag": "v0.16.1",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.16.1",
      "publishedAt": "2026-02-12T23:40:00Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* Installing Ollama via the `curl` install script on macOS will now only prompt for your password if its required\n* Installing Ollama via the `iem` install script in Windows will now show progress\n* Image generation models will now respect the `OLLAMA_LOAD_TIMEOUT` variable\n\n**Full..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-core==1.2.12",
      "tag": "langchain-core==1.2.12",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-core%3D%3D1.2.12",
      "publishedAt": "2026-02-12T20:53:28Z",
      "isPrerelease": false,
      "body": "Changes since langchain-core==1.2.11\n\nrelease(core): 1.2.12 (#35192)\nfix(core): fix setting `ChatGeneration.text` (#35191)"
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.16.0",
      "tag": "v0.16.0",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.16.0",
      "publishedAt": "2026-02-12T01:19:43Z",
      "isPrerelease": false,
      "body": "## New models\n* [GLM-5](https://ollama.com/library/glm-5): A strong reasoning and agentic model from Z.ai with 744B total parameters (40B active), built for complex systems engineering and long-horizon tasks.\n* [MiniMax-M2.5](https://ollama.com/library/minimax-m2.5): a new state-of-the-art large lan..."
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026 Recovery 2",
      "tag": "1.109.2",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.2",
      "publishedAt": "2026-02-11T03:24:57Z",
      "isPrerelease": false,
      "body": "The update addresses these [issues](https://github.com/Microsoft/vscode/issues?q=is%3Aissue+milestone%3A%22January+2026+Recovery+2%22+is%3Aclosed+).\n\nFor the complete release notes go to [Updates](https://code.visualstudio.com/updates/v1_109) on [code.visualstudio.com](https://code.visualstudio.com)..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.39",
      "tag": "v2.1.39",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.39",
      "publishedAt": "2026-02-10T23:11:36Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Improved terminal rendering performance\n- Fixed fatal errors being swallowed instead of displayed\n- Fixed process hanging after session close\n- Fixed character loss at terminal screen boundary\n- Fixed blank lines in verbose transcript view"
    },
    {
      "repo": "run-llama/llama_index",
      "company": "LlamaIndex",
      "category": "framework",
      "name": "v0.14.14",
      "tag": "v0.14.14",
      "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.14",
      "publishedAt": "2026-02-10T23:08:46Z",
      "isPrerelease": false,
      "body": "# Release Notes\n\n## [2026-02-10]\n\n### llama-index-callbacks-wandb [0.4.2]\n\n- Fix potential crashes and improve security defaults in core components ([#20610](https://github.com/run-llama/llama_index/pull/20610))\n\n### llama-index-core [0.14.14]\n\n- fix: catch pydantic ValidationError in VectorStoreQue..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.20.0",
      "tag": "v2.20.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.20.0",
      "publishedAt": "2026-02-10T19:02:11Z",
      "isPrerelease": false,
      "body": "## 2.20.0 (2026-02-10)\n\nFull Changelog: [v2.19.0...v2.20.0](https://github.com/openai/openai-python/compare/v2.19.0...v2.20.0)\n\n### Features\n\n* **api:** support for images in batch api ([28edb6e](https://github.com/openai/openai-python/commit/28edb6e1b7eb30dbb7be49979cee7882e8889264))"
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026 Recovery 1",
      "tag": "1.109.1",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.1",
      "publishedAt": "2026-02-10T18:30:40Z",
      "isPrerelease": false,
      "body": "The update addresses these [issues](https://github.com/Microsoft/vscode/issues?q=is%3Aissue+milestone%3A%22January+2026+Recovery+1%22+is%3Aclosed+), including a fix for a security vulnerability.\n\nFor the complete release notes go to [Updates](https://code.visualstudio.com/updates/v1_109) on [code.vi..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.19.0",
      "tag": "v2.19.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.19.0",
      "publishedAt": "2026-02-10T18:20:53Z",
      "isPrerelease": false,
      "body": "## 2.19.0 (2026-02-10)\n\nFull Changelog: [v2.18.0...v2.19.0](https://github.com/openai/openai-python/compare/v2.18.0...v2.19.0)\n\n### Features\n\n* **api:** skills and hosted shell ([27fdf68](https://github.com/openai/openai-python/commit/27fdf6820655b5994e3c1eddb3c8d9344a8be744))\n\n\n### Chores\n\n* **inte..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain==1.2.10",
      "tag": "langchain==1.2.10",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain%3D%3D1.2.10",
      "publishedAt": "2026-02-10T14:57:11Z",
      "isPrerelease": false,
      "body": "Changes since langchain==1.2.9\n\nrelease(langchain): 1.2.10 (#35137)\nchore(deps): bump the langchain-deps group across 3 directories with 40 updates (#35129)\nchore(deps): bump the langchain-deps group across 3 directories with 11 updates (#35121)\nfix(langchain): fix token counting on partial message ..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.18.0",
      "tag": "v2.18.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.18.0",
      "publishedAt": "2026-02-09T21:41:36Z",
      "isPrerelease": false,
      "body": "## 2.18.0 (2026-02-09)\n\nFull Changelog: [v2.17.0...v2.18.0](https://github.com/openai/openai-python/compare/v2.17.0...v2.18.0)\n\n### Features\n\n* **api:** add context_management to responses ([137e992](https://github.com/openai/openai-python/commit/137e992b80956401d1867274fa7a0969edfdba54))\n* **api:**..."
    },
    {
      "repo": "TabbyML/tabby",
      "company": "Tabby",
      "category": "self-hosted",
      "name": "next-alpha",
      "tag": "next-alpha",
      "url": "https://github.com/TabbyML/tabby/releases/tag/next-alpha",
      "publishedAt": "2026-02-09T10:49:36Z",
      "isPrerelease": true,
      "body": "This is an alpha version for Tabby dev,\nThis is only intended to be used internally."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.79.0",
      "tag": "v0.79.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.79.0",
      "publishedAt": "2026-02-07T18:05:51Z",
      "isPrerelease": false,
      "body": "## 0.79.0 (2026-02-07)\n\nFull Changelog: [v0.78.0...v0.79.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.78.0...v0.79.0)\n\n### Features\n\n* **api:** enabling fast-mode in claude-opus-4-6 ([5953ba7](https://github.com/anthropics/anthropic-sdk-python/commit/5953ba7b425ba113595de570bc8c6..."
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.15.6",
      "tag": "v0.15.6",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.15.6",
      "publishedAt": "2026-02-07T03:58:40Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* Fixed context limits when running `ollama launch droid`\n* `ollama launch` will now download missing models instead of erroring\n* Fixed bug where `ollama launch claude` would cause context compaction when providing images\n\n**Full Changelog**: https://github.com/ollama/ollama/compa..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.78.0",
      "tag": "v0.78.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.78.0",
      "publishedAt": "2026-02-05T17:51:33Z",
      "isPrerelease": false,
      "body": "## 0.78.0 (2026-02-05)\n\nFull Changelog: [v0.77.1...v0.78.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.77.1...v0.78.0)\n\n### Features\n\n* **api:** Release Claude Opus 4.6, adaptive thinking, and other features ([3ef1529](https://github.com/anthropics/anthropic-sdk-python/commit/3ef1..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.17.0",
      "tag": "v2.17.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.17.0",
      "publishedAt": "2026-02-05T16:26:56Z",
      "isPrerelease": false,
      "body": "## 2.17.0 (2026-02-05)\n\nFull Changelog: [v2.16.0...v2.17.0](https://github.com/openai/openai-python/compare/v2.16.0...v2.17.0)\n\n### Features\n\n* **api:** add shell_call_output status field ([1bbaf88](https://github.com/openai/openai-python/commit/1bbaf8865000b338c24c9fdd5e985183feaca10f))\n* **api:** ..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.2.15-vscode",
      "tag": "v1.2.15-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.2.15-vscode",
      "publishedAt": "2026-02-04T23:12:36Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* docs: update /info command description with usage statistics by @continue[bot] in https://github.com/continuedev/continue/pull/9071\n* chore(deps): bump undici from 7.16.0 to 7.18.2 in /binary by @dependabot[bot] in https://github.com/continuedev/continue/pull/9534\n* fix: add GH_T..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.3.31-vscode",
      "tag": "v1.3.31-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.3.31-vscode",
      "publishedAt": "2026-02-04T23:06:04Z",
      "isPrerelease": true,
      "body": "## What's Changed\n* fix(cli): flaky hub loader tests by @uinstinct in https://github.com/continuedev/continue/pull/9923\n* [Snyk] Upgrade @tiptap/extension-text from 2.26.1 to 2.27.1 by @sestinj in https://github.com/continuedev/continue/pull/9915\n* chore(deps): bump tar from 7.4.3 to 7.5.7 in /core ..."
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026",
      "tag": "1.109.0",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.0",
      "publishedAt": "2026-02-04T21:08:10Z",
      "isPrerelease": false,
      "body": "Welcome to the January 2026 release of Visual Studio Code. In this release, we are further evolving VS Code to make it the **home for multi-agent development**.\n\n* **Chat UX**: chat just feels better and snappier with faster streaming, improved reasoning results, and a revamped editor inline chat\n\n*..."
    },
    {
      "repo": "vllm-project/vllm",
      "company": "vLLM",
      "category": "inference",
      "name": "v0.15.1",
      "tag": "v0.15.1",
      "url": "https://github.com/vllm-project/vllm/releases/tag/v0.15.1",
      "publishedAt": "2026-02-04T20:48:08Z",
      "isPrerelease": false,
      "body": "v0.15.1 is a patch release with security fixes, RTX Blackwell GPU fixes support, and bug fixes.\n\n## Security\n\n- **CVE-2025-69223**: Updated aiohttp dependency (#33621)\n- **CVE-2026-0994**: Updated Protobuf dependency (#33619)\n\n## Highlights\n\n### Bugfix Hardware Support\n- **RTX Blackwell (SM120)**: F..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.77.1",
      "tag": "v0.77.1",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.77.1",
      "publishedAt": "2026-02-03T17:43:49Z",
      "isPrerelease": false,
      "body": "## 0.77.1 (2026-02-03)\n\nFull Changelog: [v0.77.0...v0.77.1](https://github.com/anthropics/anthropic-sdk-python/compare/v0.77.0...v0.77.1)\n\n### Bug Fixes\n\n* **structured outputs:** send structured output beta header when format is omitted ([#1158](https://github.com/anthropics/anthropic-sdk-python/is..."
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.15.5",
      "tag": "v0.15.5",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.15.5",
      "publishedAt": "2026-02-03T01:21:21Z",
      "isPrerelease": false,
      "body": "## New models\n- [Qwen3-Coder-Next](https://ollama.com/library/qwen3-coder-next): a coding-focused language model from Alibaba's Qwen team, optimized for agentic coding workflows and local development.\n- [GLM-OCR](https://ollama.com/library/glm-ocr): GLM-OCR is a multimodal OCR model for complex docu..."
    },
    {
      "repo": "JetBrains/intellij-community",
      "company": "JetBrains",
      "category": "ide",
      "name": "pycharm/2025.3.2.1",
      "tag": "pycharm/2025.3.2.1",
      "url": "https://github.com/JetBrains/intellij-community/releases/tag/pycharm/2025.3.2.1",
      "publishedAt": "2026-02-02T15:05:51Z",
      "isPrerelease": false,
      "body": "Release notes are available [here](https://youtrack.jetbrains.com/articles/PY-A-233538509)"
    },
    {
      "repo": "JetBrains/intellij-community",
      "company": "JetBrains",
      "category": "ide",
      "name": "pycharm/2025.3.2",
      "tag": "pycharm/2025.3.2",
      "url": "https://github.com/JetBrains/intellij-community/releases/tag/pycharm/2025.3.2",
      "publishedAt": "2026-01-30T13:05:57Z",
      "isPrerelease": false,
      "body": "Release notes are available [here](https://youtrack.jetbrains.com/articles/PY-A-233538505)"
    },
    {
      "repo": "vllm-project/vllm",
      "company": "vLLM",
      "category": "inference",
      "name": "v0.15.0",
      "tag": "v0.15.0",
      "url": "https://github.com/vllm-project/vllm/releases/tag/v0.15.0",
      "publishedAt": "2026-01-29T10:21:01Z",
      "isPrerelease": false,
      "body": "## Highlights\n\nThis release features 335 commits from 158 contributors (39 new)!\n\n### Model Support\n* **New architectures**: Kimi-K2.5 (#33131), Molmo2 (#30997), Step3vl 10B (#32329), Step1 (#32511), GLM-Lite (#31386), Eagle2.5-8B VLM (#32456).\n* **LoRA expansion**: Nemotron-H (#30802), InternVL2 (#..."
    }
  ],
  "repoStats": [
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "latestRelease": "v0.81.0",
      "latestDate": "2026-02-18T04:00:28Z"
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "latestRelease": "v1.80.11.gemini-metadata.dev",
      "latestDate": "2026-02-18T03:50:00Z"
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "latestRelease": "b8087",
      "latestDate": "2026-02-18T00:32:12Z"
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "latestRelease": "v1.3.32-vscode",
      "latestDate": "2026-02-17T20:35:24Z"
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "latestRelease": "v2.1.45",
      "latestDate": "2026-02-17T18:53:52Z"
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "latestRelease": "langchain-openai==1.1.10",
      "latestDate": "2026-02-17T18:04:01Z"
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "latestRelease": "v0.16.2",
      "latestDate": "2026-02-14T08:43:11Z"
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "latestRelease": "v2.21.0",
      "latestDate": "2026-02-14T00:11:26Z"
    },
    {
      "repo": "vllm-project/vllm",
      "company": "vLLM",
      "category": "inference",
      "latestRelease": "v0.16.0",
      "latestDate": "2026-02-13T00:35:21Z"
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "latestRelease": "1.109.2",
      "latestDate": "2026-02-11T03:24:57Z"
    },
    {
      "repo": "run-llama/llama_index",
      "company": "LlamaIndex",
      "category": "framework",
      "latestRelease": "v0.14.14",
      "latestDate": "2026-02-10T23:08:46Z"
    },
    {
      "repo": "JetBrains/intellij-community",
      "company": "JetBrains",
      "category": "ide",
      "latestRelease": "pycharm/2025.3.2.1",
      "latestDate": "2026-02-02T15:05:51Z"
    },
    {
      "repo": "openai/tiktoken",
      "company": "OpenAI",
      "category": "tool",
      "latestRelease": "0.12.0",
      "latestDate": "2025-10-06T20:21:57Z"
    },
    {
      "repo": "Aider-AI/aider",
      "company": "Aider",
      "category": "cli",
      "latestRelease": "v0.86.0",
      "latestDate": "2025-08-09T17:42:19Z"
    },
    {
      "repo": "Exafunction/codeium",
      "company": "Codeium",
      "category": "extension",
      "latestRelease": "test-tag",
      "latestDate": "2024-06-17T16:04:28Z"
    },
    {
      "repo": "TabbyML/tabby",
      "company": "Tabby",
      "category": "self-hosted",
      "latestRelease": "nightly",
      "latestDate": "2023-09-08T01:39:25Z"
    }
  ]
}