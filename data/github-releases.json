{
  "generatedAt": "2026-02-21T05:17:21.866Z",
  "source": "GitHub API",
  "reposTracked": 18,
  "recentCount": 33,
  "totalReleasesFound": 80,
  "recentReleases": [
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8119",
      "tag": "b8119",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8119",
      "publishedAt": "2026-02-21T02:23:32Z",
      "isPrerelease": false,
      "body": "<details open>\n\nhexagon : fix build release (#19444) (#19587)\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8119/llama-b8119-bin-macos-arm64.tar.gz)\n- [macOS Intel (x64)](https://github.com/ggml-org/llama.cpp/releases/download/b8..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.50",
      "tag": "v2.1.50",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.50",
      "publishedAt": "2026-02-20T23:48:57Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Added support for `startupTimeout` configuration for LSP servers\n- Added `WorktreeCreate` and `WorktreeRemove` hook events, enabling custom VCS setup and teardown when agent worktree isolation creates or removes worktrees.\n- Fixed a bug where resumed sessions could be invisible ..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8118",
      "tag": "b8118",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8118",
      "publishedAt": "2026-02-20T22:50:24Z",
      "isPrerelease": false,
      "body": "<details open>\n\ncommon : merge qwen3-coder and nemotron nano 3 parsers (#19765)\n\n* common : migrate qwen3-coder to PEG parsing variant\n\n* cont : add JSON parameter test\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8118/llama-b81..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "litellm_langfuse-dev-v1.81.13",
      "tag": "litellm_langfuse-dev-v1.81.13",
      "url": "https://github.com/BerriAI/litellm/releases/tag/litellm_langfuse-dev-v1.81.13",
      "publishedAt": "2026-02-20T18:45:43Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* Prompt Management API - new API to interact with Prompt Management integrations (no PR required) by @krrishdholakia in https://github.com/BerriAI/litellm/pull/17800\n* [Feature] UI - Keys/Teams: Add Access Group Selector to Create and Edit Flow by @yuneng-jiang in https://github.c..."
    },
    {
      "repo": "JetBrains/intellij-community",
      "company": "JetBrains",
      "category": "ide",
      "name": "idea/2025.3.3",
      "tag": "idea/2025.3.3",
      "url": "https://github.com/JetBrains/intellij-community/releases/tag/idea/2025.3.3",
      "publishedAt": "2026-02-20T17:45:29Z",
      "isPrerelease": false,
      "body": "Release notes are available [here](https://youtrack.jetbrains.com/articles/IDEA-A-2100662633)"
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8117",
      "tag": "b8117",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8117",
      "publishedAt": "2026-02-20T13:16:12Z",
      "isPrerelease": false,
      "body": "<details open>\n\nggml-cpu: add RVV vec dot kernels for quantization types (#18784)\n\n* ggml-cpu: add rvv vec_dot for iq2_s\n\nCo-authored-by: Rehan Qasim <rehan.qasim@10xengineers.ai>\n\n* ggml-cpu: add rvv vec_dot for iq3_s\n\nCo-authored-by: Rehan Qasim <rehan.qasim@10xengineers.ai>\n\n* ggml-cpu: add rvv v..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8116",
      "tag": "b8116",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8116",
      "publishedAt": "2026-02-20T10:16:56Z",
      "isPrerelease": false,
      "body": "<details open>\n\nquantize : add --dry-run option (#19526)\n\n* clean slate for branch\n\n* use 6 characters for tensor dims\n\n* add --dry-run to llama-quantize\n\n* use 6 characters for tensor dims (cont.)\n\n* no need to re-calculate ggml_nbytes for tensor\n\n* fix indent\n\n* show model and quant BPW when quant..."
    },
    {
      "repo": "JetBrains/intellij-community",
      "company": "JetBrains",
      "category": "ide",
      "name": "pycharm/2025.3.3",
      "tag": "pycharm/2025.3.3",
      "url": "https://github.com/JetBrains/intellij-community/releases/tag/pycharm/2025.3.3",
      "publishedAt": "2026-02-20T09:14:29Z",
      "isPrerelease": false,
      "body": "Release notes are available [here](https://youtrack.jetbrains.com/articles/PY-A-233538520)"
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.9-stable.gemini.3.1-pro.sonnet-4.6",
      "tag": "v1.81.9-stable.gemini.3.1-pro.sonnet-4.6",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.9-stable.gemini.3.1-pro.sonnet-4.6",
      "publishedAt": "2026-02-20T09:08:34Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.9-stable.gemini.3.1-pro-patch...v1.81.9-stable.gemini.3.1-pro.sonnet-4.6"
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8115",
      "tag": "b8115",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8115",
      "publishedAt": "2026-02-20T05:05:10Z",
      "isPrerelease": false,
      "body": "<details open>\n\ntest: mul_mat tests with huge batch size (#19519)\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8115/llama-b8115-bin-macos-arm64.tar.gz)\n- [macOS Intel (x64)](https://github.com/ggml-org/llama.cpp/releases/downloa..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.9-stable.gemini.3.1-pro-patch",
      "tag": "v1.81.9-stable.gemini.3.1-pro-patch",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.9-stable.gemini.3.1-pro-patch",
      "publishedAt": "2026-02-20T04:46:06Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.9-stable.gemini.3.1-pro...v1.81.9-stable.gemini.3.1-pro-patch"
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.9-stable.patch.1",
      "tag": "v1.81.9-stable.patch.1",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.9-stable.patch.1",
      "publishedAt": "2026-02-20T01:04:07Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.9-nightly...v1.81.9-stable.patch.1"
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026 Recovery 5",
      "tag": "1.109.5",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.5",
      "publishedAt": "2026-02-20T00:20:02Z",
      "isPrerelease": false,
      "body": "The update addresses these [issues\n](https://github.com/microsoft/vscode/milestone/378?closed=1).\n\nFor the complete release notes go to [Updates](https://code.visualstudio.com/updates/v1_109) on [code.visualstudio.com](https://code.visualstudio.com/)."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.49",
      "tag": "v2.1.49",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.49",
      "publishedAt": "2026-02-19T23:28:27Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Fixed Ctrl+C and ESC being silently ignored when background agents are running and the main thread is idle. Pressing twice within 3 seconds now kills all background agents.\n- Fixed prompt suggestion cache regression that reduced cache hit rates.\n- Fixed `plugin enable` and `plug..."
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.16.3",
      "tag": "v0.16.3",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.16.3",
      "publishedAt": "2026-02-19T22:11:27Z",
      "isPrerelease": false,
      "body": "## What's Changed\n*  New `ollama launch cline` added for the Cline CLI\n* `ollama launch <integration>` will now always show the model picker\n* Added Gemma 3, Llama and Qwen 3 architectures to MLX runner\n\n## New Contributors\n* @hellosaumil made their first contribution in https://github.com/ollama/ol..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.13.dev1",
      "tag": "v1.81.13.dev1",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.13.dev1",
      "publishedAt": "2026-02-19T20:07:33Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* Generic Guardrails: Add a configurable fallback to handle generic guardrail endpoint connection failures by @itayov in https://github.com/BerriAI/litellm/pull/21245\n* fix: preserve metadata for custom callbacks on codex/responses path (… by @saneroen in https://github.com/BerriAI..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.83.0",
      "tag": "v0.83.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.83.0",
      "publishedAt": "2026-02-19T19:26:11Z",
      "isPrerelease": false,
      "body": "## 0.83.0 (2026-02-19)\n\nFull Changelog: [v0.82.0...v0.83.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.82.0...v0.83.0)\n\n### Features\n\n* **api:** Add top-level cache control (automatic caching) ([a940123](https://github.com/anthropics/anthropic-sdk-python/commit/a940123da34ac33f0b6..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-core==1.2.14",
      "tag": "langchain-core==1.2.14",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-core%3D%3D1.2.14",
      "publishedAt": "2026-02-19T14:22:50Z",
      "isPrerelease": false,
      "body": "Changes since langchain-core==1.2.13\n\nrelease(core): 1.2.14 (#35328)\nchore(core): remove `langserve` from sys info util, add `deepagents` (#35325)\nfix(core): fix merge_lists incorrectly merging parallel tool calls (#35281)\nfix(core): accept int temperature in _get_ls_params for LangSmith tracing (#3..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-text-splitters==1.1.1",
      "tag": "langchain-text-splitters==1.1.1",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-text-splitters%3D%3D1.1.1",
      "publishedAt": "2026-02-18T23:03:00Z",
      "isPrerelease": false,
      "body": "Changes since langchain-text-splitters==1.1.0\n\nrelease(text-splitters): 1.1.1 (#35318)\nfix(text-splitters): prevent JSFrameworkTextSplitter from mutating self._separators on each split_text() call (#35316)\nchore: bump transformers from 5.1.0 to 5.2.0 in /libs/text-splitters in the other-deps group a..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.47",
      "tag": "v2.1.47",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.47",
      "publishedAt": "2026-02-18T21:38:45Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Fixed FileWriteTool line counting to preserve intentional trailing blank lines instead of stripping them with `trimEnd()`.\n- Fixed Windows terminal rendering bugs caused by `os.EOL` (`\\r\\n`) in display code — line counts now show correct values instead of always showing 1 on Win..."
    }
  ],
  "allReleases": [
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8119",
      "tag": "b8119",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8119",
      "publishedAt": "2026-02-21T02:23:32Z",
      "isPrerelease": false,
      "body": "<details open>\n\nhexagon : fix build release (#19444) (#19587)\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8119/llama-b8119-bin-macos-arm64.tar.gz)\n- [macOS Intel (x64)](https://github.com/ggml-org/llama.cpp/releases/download/b8..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.50",
      "tag": "v2.1.50",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.50",
      "publishedAt": "2026-02-20T23:48:57Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Added support for `startupTimeout` configuration for LSP servers\n- Added `WorktreeCreate` and `WorktreeRemove` hook events, enabling custom VCS setup and teardown when agent worktree isolation creates or removes worktrees.\n- Fixed a bug where resumed sessions could be invisible ..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8118",
      "tag": "b8118",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8118",
      "publishedAt": "2026-02-20T22:50:24Z",
      "isPrerelease": false,
      "body": "<details open>\n\ncommon : merge qwen3-coder and nemotron nano 3 parsers (#19765)\n\n* common : migrate qwen3-coder to PEG parsing variant\n\n* cont : add JSON parameter test\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8118/llama-b81..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "litellm_langfuse-dev-v1.81.13",
      "tag": "litellm_langfuse-dev-v1.81.13",
      "url": "https://github.com/BerriAI/litellm/releases/tag/litellm_langfuse-dev-v1.81.13",
      "publishedAt": "2026-02-20T18:45:43Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* Prompt Management API - new API to interact with Prompt Management integrations (no PR required) by @krrishdholakia in https://github.com/BerriAI/litellm/pull/17800\n* [Feature] UI - Keys/Teams: Add Access Group Selector to Create and Edit Flow by @yuneng-jiang in https://github.c..."
    },
    {
      "repo": "JetBrains/intellij-community",
      "company": "JetBrains",
      "category": "ide",
      "name": "idea/2025.3.3",
      "tag": "idea/2025.3.3",
      "url": "https://github.com/JetBrains/intellij-community/releases/tag/idea/2025.3.3",
      "publishedAt": "2026-02-20T17:45:29Z",
      "isPrerelease": false,
      "body": "Release notes are available [here](https://youtrack.jetbrains.com/articles/IDEA-A-2100662633)"
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8117",
      "tag": "b8117",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8117",
      "publishedAt": "2026-02-20T13:16:12Z",
      "isPrerelease": false,
      "body": "<details open>\n\nggml-cpu: add RVV vec dot kernels for quantization types (#18784)\n\n* ggml-cpu: add rvv vec_dot for iq2_s\n\nCo-authored-by: Rehan Qasim <rehan.qasim@10xengineers.ai>\n\n* ggml-cpu: add rvv vec_dot for iq3_s\n\nCo-authored-by: Rehan Qasim <rehan.qasim@10xengineers.ai>\n\n* ggml-cpu: add rvv v..."
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8116",
      "tag": "b8116",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8116",
      "publishedAt": "2026-02-20T10:16:56Z",
      "isPrerelease": false,
      "body": "<details open>\n\nquantize : add --dry-run option (#19526)\n\n* clean slate for branch\n\n* use 6 characters for tensor dims\n\n* add --dry-run to llama-quantize\n\n* use 6 characters for tensor dims (cont.)\n\n* no need to re-calculate ggml_nbytes for tensor\n\n* fix indent\n\n* show model and quant BPW when quant..."
    },
    {
      "repo": "JetBrains/intellij-community",
      "company": "JetBrains",
      "category": "ide",
      "name": "pycharm/2025.3.3",
      "tag": "pycharm/2025.3.3",
      "url": "https://github.com/JetBrains/intellij-community/releases/tag/pycharm/2025.3.3",
      "publishedAt": "2026-02-20T09:14:29Z",
      "isPrerelease": false,
      "body": "Release notes are available [here](https://youtrack.jetbrains.com/articles/PY-A-233538520)"
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.9-stable.gemini.3.1-pro.sonnet-4.6",
      "tag": "v1.81.9-stable.gemini.3.1-pro.sonnet-4.6",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.9-stable.gemini.3.1-pro.sonnet-4.6",
      "publishedAt": "2026-02-20T09:08:34Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.9-stable.gemini.3.1-pro-patch...v1.81.9-stable.gemini.3.1-pro.sonnet-4.6"
    },
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "name": "b8115",
      "tag": "b8115",
      "url": "https://github.com/ggml-org/llama.cpp/releases/tag/b8115",
      "publishedAt": "2026-02-20T05:05:10Z",
      "isPrerelease": false,
      "body": "<details open>\n\ntest: mul_mat tests with huge batch size (#19519)\n\n</details>\n\n**macOS/iOS:**\n- [macOS Apple Silicon (arm64)](https://github.com/ggml-org/llama.cpp/releases/download/b8115/llama-b8115-bin-macos-arm64.tar.gz)\n- [macOS Intel (x64)](https://github.com/ggml-org/llama.cpp/releases/downloa..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.9-stable.gemini.3.1-pro-patch",
      "tag": "v1.81.9-stable.gemini.3.1-pro-patch",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.9-stable.gemini.3.1-pro-patch",
      "publishedAt": "2026-02-20T04:46:06Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.9-stable.gemini.3.1-pro...v1.81.9-stable.gemini.3.1-pro-patch"
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.9-stable.patch.1",
      "tag": "v1.81.9-stable.patch.1",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.9-stable.patch.1",
      "publishedAt": "2026-02-20T01:04:07Z",
      "isPrerelease": false,
      "body": "**Full Changelog**: https://github.com/BerriAI/litellm/compare/v1.81.9-nightly...v1.81.9-stable.patch.1"
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026 Recovery 5",
      "tag": "1.109.5",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.5",
      "publishedAt": "2026-02-20T00:20:02Z",
      "isPrerelease": false,
      "body": "The update addresses these [issues\n](https://github.com/microsoft/vscode/milestone/378?closed=1).\n\nFor the complete release notes go to [Updates](https://code.visualstudio.com/updates/v1_109) on [code.visualstudio.com](https://code.visualstudio.com/)."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.49",
      "tag": "v2.1.49",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.49",
      "publishedAt": "2026-02-19T23:28:27Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Fixed Ctrl+C and ESC being silently ignored when background agents are running and the main thread is idle. Pressing twice within 3 seconds now kills all background agents.\n- Fixed prompt suggestion cache regression that reduced cache hit rates.\n- Fixed `plugin enable` and `plug..."
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.16.3",
      "tag": "v0.16.3",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.16.3",
      "publishedAt": "2026-02-19T22:11:27Z",
      "isPrerelease": false,
      "body": "## What's Changed\n*  New `ollama launch cline` added for the Cline CLI\n* `ollama launch <integration>` will now always show the model picker\n* Added Gemma 3, Llama and Qwen 3 architectures to MLX runner\n\n## New Contributors\n* @hellosaumil made their first contribution in https://github.com/ollama/ol..."
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "name": "v1.81.13.dev1",
      "tag": "v1.81.13.dev1",
      "url": "https://github.com/BerriAI/litellm/releases/tag/v1.81.13.dev1",
      "publishedAt": "2026-02-19T20:07:33Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* Generic Guardrails: Add a configurable fallback to handle generic guardrail endpoint connection failures by @itayov in https://github.com/BerriAI/litellm/pull/21245\n* fix: preserve metadata for custom callbacks on codex/responses path (… by @saneroen in https://github.com/BerriAI..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.83.0",
      "tag": "v0.83.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.83.0",
      "publishedAt": "2026-02-19T19:26:11Z",
      "isPrerelease": false,
      "body": "## 0.83.0 (2026-02-19)\n\nFull Changelog: [v0.82.0...v0.83.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.82.0...v0.83.0)\n\n### Features\n\n* **api:** Add top-level cache control (automatic caching) ([a940123](https://github.com/anthropics/anthropic-sdk-python/commit/a940123da34ac33f0b6..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-core==1.2.14",
      "tag": "langchain-core==1.2.14",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-core%3D%3D1.2.14",
      "publishedAt": "2026-02-19T14:22:50Z",
      "isPrerelease": false,
      "body": "Changes since langchain-core==1.2.13\n\nrelease(core): 1.2.14 (#35328)\nchore(core): remove `langserve` from sys info util, add `deepagents` (#35325)\nfix(core): fix merge_lists incorrectly merging parallel tool calls (#35281)\nfix(core): accept int temperature in _get_ls_params for LangSmith tracing (#3..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-text-splitters==1.1.1",
      "tag": "langchain-text-splitters==1.1.1",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-text-splitters%3D%3D1.1.1",
      "publishedAt": "2026-02-18T23:03:00Z",
      "isPrerelease": false,
      "body": "Changes since langchain-text-splitters==1.1.0\n\nrelease(text-splitters): 1.1.1 (#35318)\nfix(text-splitters): prevent JSFrameworkTextSplitter from mutating self._separators on each split_text() call (#35316)\nchore: bump transformers from 5.1.0 to 5.2.0 in /libs/text-splitters in the other-deps group a..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.47",
      "tag": "v2.1.47",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.47",
      "publishedAt": "2026-02-18T21:38:45Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Fixed FileWriteTool line counting to preserve intentional trailing blank lines instead of stripping them with `trimEnd()`.\n- Fixed Windows terminal rendering bugs caused by `os.EOL` (`\\r\\n`) in display code — line counts now show correct values instead of always showing 1 on Win..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.82.0",
      "tag": "v0.82.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.82.0",
      "publishedAt": "2026-02-18T20:24:48Z",
      "isPrerelease": false,
      "body": "## 0.82.0 (2026-02-18)\n\nFull Changelog: [v0.81.0...v0.82.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.81.0...v0.82.0)\n\n### Features\n\n* **api:** fix shared UserLocation and error code types ([da3b931](https://github.com/anthropics/anthropic-sdk-python/commit/da3b931a2be768d77c228a..."
    },
    {
      "repo": "run-llama/llama_index",
      "company": "LlamaIndex",
      "category": "framework",
      "name": "v0.14.15",
      "tag": "v0.14.15",
      "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.15",
      "publishedAt": "2026-02-18T19:06:42Z",
      "isPrerelease": false,
      "body": "# Release Notes\n\n## [2026-02-18]\n\n### llama-index-agent-agentmesh [0.1.0]\n\n- [Integration] AgentMesh: Trust Layer for LlamaIndex Agents ([#20644](https://github.com/run-llama/llama_index/pull/20644))\n\n### llama-index-core [0.14.15]\n\n- Support basic operations for multimodal types ([#20640](https://g..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-tests==1.1.5",
      "tag": "langchain-tests==1.1.5",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-tests%3D%3D1.1.5",
      "publishedAt": "2026-02-18T16:08:44Z",
      "isPrerelease": false,
      "body": "Changes since langchain-tests==1.1.4\n\nchore: bump the other-deps group across 3 directories with 2 updates (#35255)\nstyle: bump ruff version to 0.15 (#35042)\nchore(deps): bump langsmith from 0.4.56 to 0.6.3 in /libs/standard-tests (#35157)\nrelease(standard-tests): release 1.1.5 (#35139)\nchore(deps):..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.81.0",
      "tag": "v0.81.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.81.0",
      "publishedAt": "2026-02-18T04:00:28Z",
      "isPrerelease": false,
      "body": "## 0.81.0 (2026-02-18)\n\nFull Changelog: [v0.80.0...v0.81.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.80.0...v0.81.0)\n\n### Features\n\n* **api:** Make new tool versions available as top level tool types ([0a385c2](https://github.com/anthropics/anthropic-sdk-python/commit/0a385c29d2..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.2.16-vscode",
      "tag": "v1.2.16-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.2.16-vscode",
      "publishedAt": "2026-02-17T20:54:38Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* .continue/agents by @sestinj in https://github.com/continuedev/continue/pull/10233\n* .continue/agents p2 by @sestinj in https://github.com/continuedev/continue/pull/10235\n* feat: limited MCP App support by @RomneyDa in https://github.com/continuedev/continue/pull/10132\n* feat(cli..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.0.61-jetbrains",
      "tag": "v1.0.61-jetbrains",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.0.61-jetbrains",
      "publishedAt": "2026-02-17T20:35:59Z",
      "isPrerelease": true,
      "body": "## What's Changed\n* .continue/agents by @sestinj in https://github.com/continuedev/continue/pull/10233\n* .continue/agents p2 by @sestinj in https://github.com/continuedev/continue/pull/10235\n* feat: limited MCP App support by @RomneyDa in https://github.com/continuedev/continue/pull/10132\n* feat(cli..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.3.32-vscode",
      "tag": "v1.3.32-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.3.32-vscode",
      "publishedAt": "2026-02-17T20:35:24Z",
      "isPrerelease": true,
      "body": "## What's Changed\n* .continue/agents by @sestinj in https://github.com/continuedev/continue/pull/10233\n* .continue/agents p2 by @sestinj in https://github.com/continuedev/continue/pull/10235\n* feat: limited MCP App support by @RomneyDa in https://github.com/continuedev/continue/pull/10132\n* feat(cli..."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.80.0",
      "tag": "v0.80.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.80.0",
      "publishedAt": "2026-02-17T19:25:53Z",
      "isPrerelease": false,
      "body": "## 0.80.0 (2026-02-17)\n\nFull Changelog: [v0.79.0...v0.80.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.79.0...v0.80.0)\n\n### Features\n\n* **api:** Releasing claude-sonnet-4-6 ([d518d6e](https://github.com/anthropics/anthropic-sdk-python/commit/d518d6ecede3d0638f0b14950dc2be8efa0b4ff..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.45",
      "tag": "v2.1.45",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.45",
      "publishedAt": "2026-02-17T18:53:52Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Added support for Claude Sonnet 4.6\n- Added support for reading `enabledPlugins` and `extraKnownMarketplaces` from `--add-dir` directories\n- Added `spinnerTipsOverride` setting to customize spinner tips — configure `tips` with an array of custom tip strings, and optionally set `..."
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-openai==1.1.10",
      "tag": "langchain-openai==1.1.10",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-openai%3D%3D1.1.10",
      "publishedAt": "2026-02-17T18:04:01Z",
      "isPrerelease": false,
      "body": "Changes since langchain-openai==1.1.9\n\nrelease(openai): 1.1.10 (#35292)\nfeat(openai): support automatic server-side compaction (#35212)\nfix(openai): add `model` property (#35284)\nfix(nomic,openai,perplexity): update pillow version to >= 12.1.1, <13.0.0 (#35254)\ndocs(openai): more nits (#35277)\ndocs(..."
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "name": "v2.1.44",
      "tag": "v2.1.44",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.44",
      "publishedAt": "2026-02-16T21:35:03Z",
      "isPrerelease": false,
      "body": "## What's changed\n\n- Fixed auth refresh errors"
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "name": "langchain-openrouter==0.0.2",
      "tag": "langchain-openrouter==0.0.2",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-openrouter%3D%3D0.0.2",
      "publishedAt": "2026-02-15T08:50:46Z",
      "isPrerelease": false,
      "body": "Changes since langchain-openrouter==0.0.1\n\nchore(openrouter): bump core ver, silence warning (#35231)"
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.16.2",
      "tag": "v0.16.2",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.16.2",
      "publishedAt": "2026-02-14T08:43:11Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* `ollama launch claude` now supports searching the web when using `:cloud` models\n* Fixed rendering issue when running `ollama` in PowerShell\n* New setting in Ollama's app makes it easier to disable cloud models for sensitive and private tasks where data cannot leave your computer..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.21.0",
      "tag": "v2.21.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.21.0",
      "publishedAt": "2026-02-14T00:11:26Z",
      "isPrerelease": false,
      "body": "## 2.21.0 (2026-02-13)\n\nFull Changelog: [v2.20.0...v2.21.0](https://github.com/openai/openai-python/compare/v2.20.0...v2.21.0)\n\n### Features\n\n* **api:** container network_policy and skills ([d19de2e](https://github.com/openai/openai-python/commit/d19de2ee5c74413f9dc52684b650df1898dee82b))\n\n\n### Bug ..."
    },
    {
      "repo": "vllm-project/vllm",
      "company": "vLLM",
      "category": "inference",
      "name": "v0.16.0",
      "tag": "v0.16.0",
      "url": "https://github.com/vllm-project/vllm/releases/tag/v0.16.0",
      "publishedAt": "2026-02-13T00:35:21Z",
      "isPrerelease": true,
      "body": "# vLLM v0.16.0\n\n## Highlights\n\nThis release features 440 commits from 203 contributors (7 new)!\n\n* **PyTorch 2.10 upgrade** (#30525). This is a breaking change for environment dependency.\n* **Async scheduling + Pipeline Parallelism** is now fully supported, delivering **30.8% E2E throughput improvem..."
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.16.1",
      "tag": "v0.16.1",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.16.1",
      "publishedAt": "2026-02-12T23:40:00Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* Installing Ollama via the `curl` install script on macOS will now only prompt for your password if its required\n* Installing Ollama via the `iem` install script in Windows will now show progress\n* Image generation models will now respect the `OLLAMA_LOAD_TIMEOUT` variable\n\n**Full..."
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.16.0",
      "tag": "v0.16.0",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.16.0",
      "publishedAt": "2026-02-12T01:19:43Z",
      "isPrerelease": false,
      "body": "## New models\n* [GLM-5](https://ollama.com/library/glm-5): A strong reasoning and agentic model from Z.ai with 744B total parameters (40B active), built for complex systems engineering and long-horizon tasks.\n* [MiniMax-M2.5](https://ollama.com/library/minimax-m2.5): a new state-of-the-art large lan..."
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026 Recovery 2",
      "tag": "1.109.2",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.2",
      "publishedAt": "2026-02-11T03:24:57Z",
      "isPrerelease": false,
      "body": "The update addresses these [issues](https://github.com/Microsoft/vscode/issues?q=is%3Aissue+milestone%3A%22January+2026+Recovery+2%22+is%3Aclosed+).\n\nFor the complete release notes go to [Updates](https://code.visualstudio.com/updates/v1_109) on [code.visualstudio.com](https://code.visualstudio.com)..."
    },
    {
      "repo": "run-llama/llama_index",
      "company": "LlamaIndex",
      "category": "framework",
      "name": "v0.14.14",
      "tag": "v0.14.14",
      "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.14",
      "publishedAt": "2026-02-10T23:08:46Z",
      "isPrerelease": false,
      "body": "# Release Notes\n\n## [2026-02-10]\n\n### llama-index-callbacks-wandb [0.4.2]\n\n- Fix potential crashes and improve security defaults in core components ([#20610](https://github.com/run-llama/llama_index/pull/20610))\n\n### llama-index-core [0.14.14]\n\n- fix: catch pydantic ValidationError in VectorStoreQue..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.20.0",
      "tag": "v2.20.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.20.0",
      "publishedAt": "2026-02-10T19:02:11Z",
      "isPrerelease": false,
      "body": "## 2.20.0 (2026-02-10)\n\nFull Changelog: [v2.19.0...v2.20.0](https://github.com/openai/openai-python/compare/v2.19.0...v2.20.0)\n\n### Features\n\n* **api:** support for images in batch api ([28edb6e](https://github.com/openai/openai-python/commit/28edb6e1b7eb30dbb7be49979cee7882e8889264))"
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026 Recovery 1",
      "tag": "1.109.1",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.1",
      "publishedAt": "2026-02-10T18:30:40Z",
      "isPrerelease": false,
      "body": "The update addresses these [issues](https://github.com/Microsoft/vscode/issues?q=is%3Aissue+milestone%3A%22January+2026+Recovery+1%22+is%3Aclosed+), including a fix for a security vulnerability.\n\nFor the complete release notes go to [Updates](https://code.visualstudio.com/updates/v1_109) on [code.vi..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.19.0",
      "tag": "v2.19.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.19.0",
      "publishedAt": "2026-02-10T18:20:53Z",
      "isPrerelease": false,
      "body": "## 2.19.0 (2026-02-10)\n\nFull Changelog: [v2.18.0...v2.19.0](https://github.com/openai/openai-python/compare/v2.18.0...v2.19.0)\n\n### Features\n\n* **api:** skills and hosted shell ([27fdf68](https://github.com/openai/openai-python/commit/27fdf6820655b5994e3c1eddb3c8d9344a8be744))\n\n\n### Chores\n\n* **inte..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.18.0",
      "tag": "v2.18.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.18.0",
      "publishedAt": "2026-02-09T21:41:36Z",
      "isPrerelease": false,
      "body": "## 2.18.0 (2026-02-09)\n\nFull Changelog: [v2.17.0...v2.18.0](https://github.com/openai/openai-python/compare/v2.17.0...v2.18.0)\n\n### Features\n\n* **api:** add context_management to responses ([137e992](https://github.com/openai/openai-python/commit/137e992b80956401d1867274fa7a0969edfdba54))\n* **api:**..."
    },
    {
      "repo": "TabbyML/tabby",
      "company": "Tabby",
      "category": "self-hosted",
      "name": "next-alpha",
      "tag": "next-alpha",
      "url": "https://github.com/TabbyML/tabby/releases/tag/next-alpha",
      "publishedAt": "2026-02-09T10:49:36Z",
      "isPrerelease": true,
      "body": "This is an alpha version for Tabby dev,\nThis is only intended to be used internally."
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "name": "v0.79.0",
      "tag": "v0.79.0",
      "url": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.79.0",
      "publishedAt": "2026-02-07T18:05:51Z",
      "isPrerelease": false,
      "body": "## 0.79.0 (2026-02-07)\n\nFull Changelog: [v0.78.0...v0.79.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.78.0...v0.79.0)\n\n### Features\n\n* **api:** enabling fast-mode in claude-opus-4-6 ([5953ba7](https://github.com/anthropics/anthropic-sdk-python/commit/5953ba7b425ba113595de570bc8c6..."
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "name": "v0.15.6",
      "tag": "v0.15.6",
      "url": "https://github.com/ollama/ollama/releases/tag/v0.15.6",
      "publishedAt": "2026-02-07T03:58:40Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* Fixed context limits when running `ollama launch droid`\n* `ollama launch` will now download missing models instead of erroring\n* Fixed bug where `ollama launch claude` would cause context compaction when providing images\n\n**Full Changelog**: https://github.com/ollama/ollama/compa..."
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "name": "v2.17.0",
      "tag": "v2.17.0",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.17.0",
      "publishedAt": "2026-02-05T16:26:56Z",
      "isPrerelease": false,
      "body": "## 2.17.0 (2026-02-05)\n\nFull Changelog: [v2.16.0...v2.17.0](https://github.com/openai/openai-python/compare/v2.16.0...v2.17.0)\n\n### Features\n\n* **api:** add shell_call_output status field ([1bbaf88](https://github.com/openai/openai-python/commit/1bbaf8865000b338c24c9fdd5e985183feaca10f))\n* **api:** ..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.2.15-vscode",
      "tag": "v1.2.15-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.2.15-vscode",
      "publishedAt": "2026-02-04T23:12:36Z",
      "isPrerelease": false,
      "body": "## What's Changed\n* docs: update /info command description with usage statistics by @continue[bot] in https://github.com/continuedev/continue/pull/9071\n* chore(deps): bump undici from 7.16.0 to 7.18.2 in /binary by @dependabot[bot] in https://github.com/continuedev/continue/pull/9534\n* fix: add GH_T..."
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "name": "v1.3.31-vscode",
      "tag": "v1.3.31-vscode",
      "url": "https://github.com/continuedev/continue/releases/tag/v1.3.31-vscode",
      "publishedAt": "2026-02-04T23:06:04Z",
      "isPrerelease": true,
      "body": "## What's Changed\n* fix(cli): flaky hub loader tests by @uinstinct in https://github.com/continuedev/continue/pull/9923\n* [Snyk] Upgrade @tiptap/extension-text from 2.26.1 to 2.27.1 by @sestinj in https://github.com/continuedev/continue/pull/9915\n* chore(deps): bump tar from 7.4.3 to 7.5.7 in /core ..."
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "name": "January 2026",
      "tag": "1.109.0",
      "url": "https://github.com/microsoft/vscode/releases/tag/1.109.0",
      "publishedAt": "2026-02-04T21:08:10Z",
      "isPrerelease": false,
      "body": "Welcome to the January 2026 release of Visual Studio Code. In this release, we are further evolving VS Code to make it the **home for multi-agent development**.\n\n* **Chat UX**: chat just feels better and snappier with faster streaming, improved reasoning results, and a revamped editor inline chat\n\n*..."
    }
  ],
  "repoStats": [
    {
      "repo": "ggerganov/llama.cpp",
      "company": "llama.cpp",
      "category": "inference",
      "latestRelease": "b8119",
      "latestDate": "2026-02-21T02:23:32Z"
    },
    {
      "repo": "anthropics/claude-code",
      "company": "Anthropic",
      "category": "cli",
      "latestRelease": "v2.1.50",
      "latestDate": "2026-02-20T23:48:57Z"
    },
    {
      "repo": "JetBrains/intellij-community",
      "company": "JetBrains",
      "category": "ide",
      "latestRelease": "idea/2025.3.3",
      "latestDate": "2026-02-20T17:45:29Z"
    },
    {
      "repo": "BerriAI/litellm",
      "company": "LiteLLM",
      "category": "proxy",
      "latestRelease": "v1.81.9-stable.patch.1",
      "latestDate": "2026-02-20T01:04:07Z"
    },
    {
      "repo": "microsoft/vscode",
      "company": "Microsoft",
      "category": "ide",
      "latestRelease": "1.109.5",
      "latestDate": "2026-02-20T00:20:02Z"
    },
    {
      "repo": "ollama/ollama",
      "company": "Ollama",
      "category": "local",
      "latestRelease": "v0.16.3",
      "latestDate": "2026-02-19T22:11:27Z"
    },
    {
      "repo": "anthropics/anthropic-sdk-python",
      "company": "Anthropic",
      "category": "sdk",
      "latestRelease": "v0.83.0",
      "latestDate": "2026-02-19T19:26:11Z"
    },
    {
      "repo": "langchain-ai/langchain",
      "company": "LangChain",
      "category": "framework",
      "latestRelease": "langchain-core==1.2.14",
      "latestDate": "2026-02-19T14:22:50Z"
    },
    {
      "repo": "run-llama/llama_index",
      "company": "LlamaIndex",
      "category": "framework",
      "latestRelease": "v0.14.15",
      "latestDate": "2026-02-18T19:06:42Z"
    },
    {
      "repo": "continuedev/continue",
      "company": "Continue",
      "category": "extension",
      "latestRelease": "v1.3.32-vscode",
      "latestDate": "2026-02-17T20:35:24Z"
    },
    {
      "repo": "openai/openai-python",
      "company": "OpenAI",
      "category": "sdk",
      "latestRelease": "v2.21.0",
      "latestDate": "2026-02-14T00:11:26Z"
    },
    {
      "repo": "vllm-project/vllm",
      "company": "vLLM",
      "category": "inference",
      "latestRelease": "v0.16.0",
      "latestDate": "2026-02-13T00:35:21Z"
    },
    {
      "repo": "openai/tiktoken",
      "company": "OpenAI",
      "category": "tool",
      "latestRelease": "0.12.0",
      "latestDate": "2025-10-06T20:21:57Z"
    },
    {
      "repo": "Aider-AI/aider",
      "company": "Aider",
      "category": "cli",
      "latestRelease": "v0.86.0",
      "latestDate": "2025-08-09T17:42:19Z"
    },
    {
      "repo": "Exafunction/codeium",
      "company": "Codeium",
      "category": "extension",
      "latestRelease": "test-tag",
      "latestDate": "2024-06-17T16:04:28Z"
    },
    {
      "repo": "TabbyML/tabby",
      "company": "Tabby",
      "category": "self-hosted",
      "latestRelease": "nightly",
      "latestDate": "2023-09-08T01:39:25Z"
    }
  ]
}