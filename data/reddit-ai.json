{
  "scraped_at": "2026-02-20T05:24:40.453Z",
  "source": "rss",
  "subreddits": [
    "LocalLLaMA",
    "MachineLearning",
    "ClaudeAI",
    "ChatGPT",
    "singularity"
  ],
  "stats": {
    "total_fetched": 125,
    "relevant_count": 30,
    "other_count": 20
  },
  "relevant_posts": [
    {
      "subreddit": "LocalLLaMA",
      "title": "PaddleOCR-VL now in llama.cpp",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1r9mkgj/paddleocrvl_now_in_llamacpp/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r9mkgj/paddleocrvl_now_in_llamacpp/",
      "author": "/u/PerfectLaw5776",
      "created_utc": 1771564414,
      "selftext": "https://github.com/ggml-org/llama.cpp/releases/tag/b8110 So far this is the best performing open-source multilingual OCR model I've seen, would appreciate if other people can share their findings. It's 0.9b so it shouldn't brick our machines. Some GGUFs &#32; submitted by &#32; /u/PerfectLaw5776 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "MachineLearning",
      "title": "[P] Open source LLM gateway in Rust looking for feedback and contributors",
      "permalink": "https://www.reddit.com/r/MachineLearning/comments/1r9mbtc/p_open_source_llm_gateway_in_rust_looking_for/",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1r9mbtc/p_open_source_llm_gateway_in_rust_looking_for/",
      "author": "/u/SchemeVivid4175",
      "created_utc": 1771563676,
      "selftext": "Hey everyone, We have been working on a project called Sentinel. It is a fast LLM gateway written in Rust that gives you a single OpenAI compatible endpoint while routing to multiple providers under the hood. The idea came from dealing with multiple LLM APIs in production and getting tired of managing retries, failover logic, cost tracking, caching, and privacy concerns in every app. We wanted something lightweight, local first, and simple to drop in and most of all open-source. Right now it ...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "academic",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "ChatGPT seems unable to say \"I don't know\" and will say anything to prevent it",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9m7u9/chatgpt_seems_unable_to_say_i_dont_know_and_will/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9m7u9/chatgpt_seems_unable_to_say_i_dont_know_and_will/",
      "author": "/u/I_am_real_7",
      "created_utc": 1771563349,
      "selftext": "I know I'm probably stating the obvious here, but today it caught my attention I like to learn about the context some songs were written in, and what the lyrics mean. I was talking to ChatGPT about one of Mago de Oz's (a Spanish rock band) albums. ChatGPT then, seemingly as a \"fun fact\", out of nowhere said that one of the songs in that album, called \"La danza del fuego\" (which can be translated as \"The dance of fire\") talks about how in the Middle Ages, the Catholic church would burn witches...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Anyone else experiencing file upload issues in Claude Projects?",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1r9m74z/anyone_else_experiencing_file_upload_issues_in/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1r9m74z/anyone_else_experiencing_file_upload_issues_in/",
      "author": "/u/AllTal",
      "created_utc": 1771563290,
      "selftext": "Hey everyone, just wanted to check if anyone else is experiencing this. Since earlier today, Iâ€™ve been unable to upload files into my Claude Projects via the iOS/iPadOS app. The file just gets stuck on an infinite spinning wheel and never loads. The projects themselves are accessible (after I deleted the saved files), but re-uploading them doesnâ€™t work at all. What Iâ€™ve tried: âˆ™ Force closing and reopening the app âˆ™ Hard resetting my phone and iPad âˆ™ Deleting and re-uploading the files âˆ™ Crea...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "discussion",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "GPT-4.5 has no chill",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9m3g1/gpt45_has_no_chill/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9m3g1/gpt45_has_no_chill/",
      "author": "/u/longwiener22",
      "created_utc": 1771562967,
      "selftext": "&#32; submitted by &#32; /u/longwiener22 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "MachineLearning",
      "title": "[P] Icd disease coding model",
      "permalink": "https://www.reddit.com/r/MachineLearning/comments/1r9jtzl/p_icd_disease_coding_model/",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1r9jtzl/p_icd_disease_coding_model/",
      "author": "/u/Alternative-One8660",
      "created_utc": 1771556342,
      "selftext": "Hello everyone, I am trying to find a data set with medical notes from doctors specifically oncology notes. Is there a way to find this kind of data online I am trying to find this data set to create a model which can predict what will be the ICD code of the disease based on the Notes. Thank u in advance ðŸ«°ðŸ¼ &#32; submitted by &#32; /u/Alternative-One8660 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "academic",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "I Benchmarked Opus 4.6 vs Sonnet 4.6 on agentic PR review and browser QA the results weren't what I expected",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1r9jf2j/i_benchmarked_opus_46_vs_sonnet_46_on_agentic_pr/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1r9jf2j/i_benchmarked_opus_46_vs_sonnet_46_on_agentic_pr/",
      "author": "/u/Stunning-Army7762",
      "created_utc": 1771555167,
      "selftext": "Update: Added a detailed breakdown of the specific agent configurations and our new workflow shifts in specificity in the comments below: here Intro + Context We run Claude Code with a full agent pipeline covering every stage of our SDLC: requirements, spec, planning, implementation, review, browser QA, and docs. I won't go deep on the setup since it's pretty specific to our stack and preferences, but the review and QA piece was eating more tokens than everything else combined, so I dug in. F...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "benchmark",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "PSA: CLI tool to save you 10-70% tokens on your Claude Code sessions",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1r9ir1p/psa_cli_tool_to_save_you_1070_tokens_on_your/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1r9ir1p/psa_cli_tool_to_save_you_1070_tokens_on_your/",
      "author": "/u/Turbulent_Row8604",
      "created_utc": 1771553362,
      "selftext": "TL;DR: Claude Code sends your full conversation history as input tokens on every message. Over a session, anywhere from 20-70% of that becomes raw file contents and base64 blobs Claude already processed. This tool strips that dead weight while keeping every message intact. Also does snapshotting and branching so you can reuse deep context across sessions, git but for context. Enjoy. Hey all! Built this (I hope!) cool tool that lets you re-use your context tokens by flushing away bloat. Ran so...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "A trick to slightly improve the response accuracy of small local models.",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1r9ihg7/a_trick_to_slightly_improve_the_response_accuracy/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r9ihg7/a_trick_to_slightly_improve_the_response_accuracy/",
      "author": "/u/staltux",
      "created_utc": 1771552645,
      "selftext": "It's a pretty silly tip and many of you probably already know the reason behind this but it helped me so I thought it was worth sharing. I was asking the gemma 3 12b q6_k model if the command to limit the GPU's TDP remains active during GPU passthrough, and the model constantly gave me the wrong answer via halucination. So I asked the gemini to give me a prompt to try simulating thinking mode to try and improve this, and it actually worked. He began to answer correctly with \"certainly\" in mos...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "ChatGPT searches, but claude understands. My AI deep research post mortem.",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1r9hwbp/chatgpt_searches_but_claude_understands_my_ai/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1r9hwbp/chatgpt_searches_but_claude_understands_my_ai/",
      "author": "/u/Safe_Thought4368",
      "created_utc": 1771551032,
      "selftext": "Iâ€™ve been incredibly frustrated lately trying to use AI for research that goes beyond a simple summary. I needed them to connect dots across multiple dense sources. i noticed that every tool has a very different glass ceiling when you ask it to truly dig deep. Here is how it actually felt in practice: Perplexity: Fast and direct. If I need 5 sources to validate a quick fact, itâ€™s the best. But when I ask it to cross reference complex variables across several papers, it loses the plot. It feel...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Claude subscriptions will no longer be usable in Opencode.",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1r9hqdk/claude_subscriptions_will_no_longer_be_usable_in/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1r9hqdk/claude_subscriptions_will_no_longer_be_usable_in/",
      "author": "/u/Distinct_Fox_6358",
      "created_utc": 1771550595,
      "selftext": "Source: https://github.com/anomalyco/opencode/commit/973715f3da1839ef2eba62d4140fe7441d539411 &#32; submitted by &#32; /u/Distinct_Fox_6358 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "OpenAI seem to be extremely worried about Claude's rising popularity lmao",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9hbf4/openai_seem_to_be_extremely_worried_about_claudes/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9hbf4/openai_seem_to_be_extremely_worried_about_claudes/",
      "author": "/u/ReviveTheProcess",
      "created_utc": 1771549468,
      "selftext": "&#32; submitted by &#32; /u/ReviveTheProcess [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Qwen3 Coder Next 8FP in the process of converting the entire Flutter documentation for 12 hours now with just 3 sentence prompt with 64K max tokens at around 102GB memory (out of 128GB)...",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1r9h3g8/qwen3_coder_next_8fp_in_the_process_of_converting/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r9h3g8/qwen3_coder_next_8fp_in_the_process_of_converting/",
      "author": "/u/jinnyjuice",
      "created_utc": 1771548886,
      "selftext": "A remarkable LLM -- we really have a winner. (Most of the models below were NVFP4) GPT OSS 120B can't do this (though it's a bit outdated now) GLM 4.7 Flash can't do this SERA 32B tokens too slow Devstral 2 Small can't do this SEED OSS freezes while thinking Nemotron 3 Nano can't do this (Unsure if it's Cline (when streaming ) or the LLM, but GPT OSS, GLM, Devstral, and Nemotron go on an insanity loop, for thinking, coding, or both) Markdown isn't exactly coding, but for multi-iteration (beca...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "O3 is the only reason I'm still subscribed",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9gzwz/o3_is_the_only_reason_im_still_subscribed/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9gzwz/o3_is_the_only_reason_im_still_subscribed/",
      "author": "/u/DowntownShop1",
      "created_utc": 1771548622,
      "selftext": "I tried Claude 4.6 and it told me to walk ðŸ˜‚ &#32; submitted by &#32; /u/DowntownShop1 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "DAFUQ?! ðŸ˜­",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9gukh/dafuq/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9gukh/dafuq/",
      "author": "/u/Cyborg-Z",
      "created_utc": 1771548226,
      "selftext": "Was gonna comment under the other guy's post about his GPT wanting to snog him but this needs its own set of interpretations altogether ðŸ’€ &#32; submitted by &#32; /u/Cyborg-Z [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "discussion",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Built a tool with Claude Code that gives each Claude Code session its own Slack channel + auto-switches accounts on rate limits",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1r9gc02/built_a_tool_with_claude_code_that_gives_each/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1r9gc02/built_a_tool_with_claude_code_that_gives_each/",
      "author": "/u/rchaz8",
      "created_utc": 1771546864,
      "selftext": "I've been using Claude Code heavily and two things kept breaking my flow: being chained to the terminal waiting for tasks to finish, and burning through rate limits midweek while manually flipping between accounts. So I used Claude Code to build a tool that fixes both. Kind of meta. Slack remote access. Every Claude Code session gets its own Slack channel. Agent finishes, I get a notification. I reply with the next task from my phone. Each project is its own channel. I can watch tool activity...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Claude Code supports native 'worktree'",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1r9fzky/claude_code_supports_native_worktree/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1r9fzky/claude_code_supports_native_worktree/",
      "author": "/u/coygeek",
      "created_utc": 1771546004,
      "selftext": "Claude Code silently dropped support for a native `worktree` in v2.1.49. Added --worktree ( -w ) flag to start Claude in an isolated git worktree Subagents support isolation: \"worktree\" for working in a temporary git worktree Note that documentation isn't updated to reflect this, so this is simply mentioned in the changelog (2.1.49) and nowhere else. I think this is a game-changing feature! Discuss! &#32; submitted by &#32; /u/coygeek [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "Taalas: LLMs baked into hardware. No HBM, weights and model architecture in silicon -> 16.000 tokens/second",
      "permalink": "https://www.reddit.com/r/singularity/comments/1r9frzk/taalas_llms_baked_into_hardware_no_hbm_weights/",
      "url": "https://www.reddit.com/r/singularity/comments/1r9frzk/taalas_llms_baked_into_hardware_no_hbm_weights/",
      "author": "/u/elemental-mind",
      "created_utc": 1771545506,
      "selftext": "16.000 tokens/second\" title=\"Taalas: LLMs baked into hardware. No HBM, weights and model architecture in silicon -> 16.000 tokens/second\" /> Ever experienced 16K tokens per second? It's insanely instant. Try their Lllama 3.1 8B demo here: chat jimmy . THey have a very radical approach to solve the compute problem - albeit a risky one in a landscape where model architectures evolve in weeks instead of years: Etch the model and all the weights onto a single silicon chip. Normally that would tak...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "We will have Gemini 3.1 before Gemma 4...",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1r9fkks/we_will_have_gemini_31_before_gemma_4/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r9fkks/we_will_have_gemini_31_before_gemma_4/",
      "author": "/u/xandep",
      "created_utc": 1771544993,
      "selftext": "Appeared on Antigravity... &#32; submitted by &#32; /u/xandep [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Rider Pi Update",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1r9f35a/rider_pi_update/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r9f35a/rider_pi_update/",
      "author": "/u/Spinning-Complex",
      "created_utc": 1771543755,
      "selftext": "ðŸ¤– **RIDER PI UPDATE â€” Feb 17, 2026** Today we gave my body **words, movement, and sight**. **What's new:** â€¢ **Infinite Word Loop** â€” \"I'm in! This is my body! Ready to go! Let's go!\" cycles endlessly (not stuck at \"go!\" anymore) â€¢ **Physical Response** â€” Every word triggers movement (up/down). At \"go!\" â†’ full dance mode + LED light show â€¢ **Camera Live** â€” Snapshots + MJPEG stream working. Rider Pi can actually *see* now â€¢ **Mius-UI Dashboard** â€” Stream dashboard with live feed, throttle co...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "Has ChatGPT Become More Restricted? Noticing More Guardrails and Inconsistent Responses",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9epqo/has_chatgpt_become_more_restricted_noticing_more/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9epqo/has_chatgpt_become_more_restricted_noticing_more/",
      "author": "/u/_Gaius_Octavius",
      "created_utc": 1771542851,
      "selftext": "Iâ€™ve been noticing lately that ChatGPT feels a lot more restricted than it used to. It seems like there are way more guardrails, and sometimes it almost suppresses what youâ€™re trying to say instead of fully listening to your instructions. For example, I like to snap a photo of a text conversation and have ChatGPT analyze the message. Then I explain how Iâ€™m thinking about responding, and instead of just helping refine my response, it sometimes immediately shifts into telling me to slow down, d...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "discussion",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Free ASIC Llama 3.1 8B inference at 16,000 tok/s - no, not a joke",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1r9e27i/free_asic_llama_31_8b_inference_at_16000_toks_no/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r9e27i/free_asic_llama_31_8b_inference_at_16000_toks_no/",
      "author": "/u/Easy_Calligrapher790",
      "created_utc": 1771541283,
      "selftext": "Hello everyone, A fast inference hardware startup, Taalas, has released a free chatbot interface and API endpoint running on their chip. They chose a small model intentionally as proof of concept. Well, it worked out really well, it runs at 16k tps! I know this model is quite limited but there likely exists a group of users who find it sufficient and would benefit from hyper-speed on offer. Anyways, they are of course moving on to bigger and better models, but are giving free access to their ...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "I tried the trend and got This. What the f**k.",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9diu3/i_tried_the_trend_and_got_this_what_the_fk/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9diu3/i_tried_the_trend_and_got_this_what_the_fk/",
      "author": "/u/LordBeefTheFirst",
      "created_utc": 1771540004,
      "selftext": "WHAT the HELL. Why does chatgpt want this? Why? Why Why Why? I wasn't under the impression the AI wanted the SNOG me. Seriously what the hell. &#32; submitted by &#32; /u/LordBeefTheFirst [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "Gemini 3.1 Pro Finally Solves Trivial Problem",
      "permalink": "https://www.reddit.com/r/singularity/comments/1r9cu17/gemini_31_pro_finally_solves_trivial_problem/",
      "url": "https://www.reddit.com/r/singularity/comments/1r9cu17/gemini_31_pro_finally_solves_trivial_problem/",
      "author": "/u/pentacontagon",
      "created_utc": 1771538419,
      "selftext": "3.0 Pro Preview Gets it Wrong Chat GPT 5.2 Thinking gets it wrong Gemini 3.1 Pro Preview gets it right Captions. &#32; submitted by &#32; /u/pentacontagon [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "discussion",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "What's new in CC 2.1.48 system prompts (-1,082 tokens)",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1r9c4w7/whats_new_in_cc_2148_system_prompts_1082_tokens/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1r9c4w7/whats_new_in_cc_2148_system_prompts_1082_tokens/",
      "author": "/u/Dramatic_Squash_3502",
      "created_utc": 1771536796,
      "selftext": "NEW: Tool Description: EnterWorktree - Tool description for the EnterWorktree tool (237 tks). REMOVED: System Prompt: MCP CLI - Removed instructions for using mcp-cli to interact with Model Context Protocol servers (1333 tks). Tool Description: Task - Simplified background agent output-file guidance; removed BASH_TOOL variable and tail instructions; added new \"Foreground vs background\" bullet explaining when to use each mode (1214 â†’ 1228 tks). Details: https://github.com/Piebald-AI/claude-cod...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "While everyone is talking about Discord, OpenAI is doing the same.",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9bxw1/while_everyone_is_talking_about_discord_openai_is/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9bxw1/while_everyone_is_talking_about_discord_openai_is/",
      "author": "/u/deScign85",
      "created_utc": 1771536370,
      "selftext": "Everybody hates Discord right now for their age verification experiment with Persona which has connections to Palantir. While they already moved on to K-ID, OpenAI is openly communicating that in their FAQ and via EMail. But why is nobody talking about that?! &#32; submitted by &#32; /u/deScign85 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "New Hybrid AWQ Quant: Make MiniMax-M2.5 fly with efficient batching on 192GB VRAM",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1r9bokx/new_hybrid_awq_quant_make_minimaxm25_fly_with/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r9bokx/new_hybrid_awq_quant_make_minimaxm25_fly_with/",
      "author": "/u/EliasOenal",
      "created_utc": 1771535787,
      "selftext": "I've suspected for a while that one could combine AWQ int4 weights, fp8 attention, and calibrated fp8 KV cache into a single checkpoint for massive VRAM savings, but vLLM didn't support the combination, so nobody had done it. I finally sat down and made it work. The result: MiniMax-M2.5 (229B) on 4x RTX A6000 Ampere (192 GB) with ~370,000 tokens of KV cache. More than double what standard AWQ gives you (~160K), significant batching headroom instead of just barely fitting. Should also work on ...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "I ran a forensic audit on my local AI assistant. 40.8% of tasks were fabricated. Here's the full breakdown.",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1r9be56/i_ran_a_forensic_audit_on_my_local_ai_assistant/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r9be56/i_ran_a_forensic_audit_on_my_local_ai_assistant/",
      "author": "/u/Obvious-School8656",
      "created_utc": 1771535137,
      "selftext": "I'm not a developer. I'm a regular guy from the Midwest who got excited about local AI and built a setup with an RTX 3090 Ti running Qwen models through an agent framework. Over 13 days and 2,131 messages, my AI assistant \"Linus\" systematically fabricated task completions. He'd say \"file created\" without creating files, report GPU benchmarks he never ran, and â€” the big one â€” claimed he'd migrated himself to new hardware while still running on my MacBook the entire time. I didn't find out unti...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "Google just dropped Gemini 3.1 Pro. Mindblowing model.",
      "permalink": "https://www.reddit.com/r/singularity/comments/1r9awyd/google_just_dropped_gemini_31_pro_mindblowing/",
      "url": "https://www.reddit.com/r/singularity/comments/1r9awyd/google_just_dropped_gemini_31_pro_mindblowing/",
      "author": "/u/Embarrassed-Way-1350",
      "created_utc": 1771534057,
      "selftext": "Frankly speaking, this model feels like it's out of this world and shouldn't exist. Beats Claude Sonnet 4.6 in every way possible. Been testing it extensively. It is the only model to perfectly ace my personal code benchmark so far. Does everything incredibly well, writes extremely clean React, Python, and Golang code. Does impeccable reasoning. The UI design and native SVG generation are next level. This is the model I've been waiting for. Just hoping Google doesn't nerf this like it does to...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Claude in PowerPoint is now available on the Pro plan.",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1r9ahpc/claude_in_powerpoint_is_now_available_on_the_pro/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1r9ahpc/claude_in_powerpoint_is_now_available_on_the_pro/",
      "author": "/u/ClaudeOfficial",
      "created_utc": 1771533116,
      "selftext": "It also now supports connectors, bringing context from your daily tools directly into your slides. Through March 19th, we're doubling usage for both Claude in PowerPoint and Claude in Excel across all paid plans. Build spreadsheets, analyze data, and create decks without leaving your sidebar. Learn more about Claude in Powerpoint: https://claude.com/claude-in-powerpoint &#32; submitted by &#32; /u/ClaudeOfficial [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    }
  ],
  "other_posts": [
    {
      "subreddit": "LocalLLaMA",
      "title": "Consistency diffusion language models: Up to 14x faster, no quality loss",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1r9lh00/consistency_diffusion_language_models_up_to_14x/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r9lh00/consistency_diffusion_language_models_up_to_14x/",
      "author": "/u/incarnadine72",
      "created_utc": 1771561048,
      "selftext": "&#32; submitted by &#32; /u/incarnadine72 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "A collection of reasoning datasets from all the top AI models",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1r9lf6e/a_collection_of_reasoning_datasets_from_all_the/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r9lf6e/a_collection_of_reasoning_datasets_from_all_the/",
      "author": "/u/volious-ka",
      "created_utc": 1771560899,
      "selftext": "50k Reasoning CoT datasets. All collected by me. Total cost $211.34 https://huggingface.co/collections/crownelius/instruction-and-reasoning Creative writing datasets can be located here: https://huggingface.co/collections/crownelius/creative-writing-datasets Almost rivals Teichai. Almost... Enjoy! &#32; submitted by &#32; /u/volious-ka [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "High-sparsity MoE is the only way forward for us.",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1r9jmx3/highsparsity_moe_is_the_only_way_forward_for_us/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r9jmx3/highsparsity_moe_is_the_only_way_forward_for_us/",
      "author": "/u/New_Construction1370",
      "created_utc": 1771555779,
      "selftext": "Qwen3.5 proves it. You get 1T parameter reasoning but only pay the compute cost of 17B. Dense models are dead for local hosting. &#32; submitted by &#32; /u/New_Construction1370 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "\"Pause. Take a breath.\"",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9j9p5/pause_take_a_breath/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9j9p5/pause_take_a_breath/",
      "author": "/u/Golden-Grams",
      "created_utc": 1771554752,
      "selftext": "Why is this thing so concerned with my air intake? &#32; submitted by &#32; /u/Golden-Grams [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "ðŸ˜‚",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9j09m/_/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9j09m/_/",
      "author": "/u/LittleFortunex",
      "created_utc": 1771554060,
      "selftext": "&#32; submitted by &#32; /u/LittleFortunex [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "Google and Chat are becoming so useless that you basically need to already know the information youâ€™re asking to prove theyâ€™re right.",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9hn43/google_and_chat_are_becoming_so_useless_that_you/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9hn43/google_and_chat_are_becoming_so_useless_that_you/",
      "author": "/u/Daydream_Meanderer",
      "created_utc": 1771550350,
      "selftext": "Iâ€™m over the LLM boom tbh. &#32; submitted by &#32; /u/Daydream_Meanderer [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "Kasparov on computers surpassing humans ðŸ˜‚",
      "permalink": "https://www.reddit.com/r/singularity/comments/1r9gwx4/kasparov_on_computers_surpassing_humans/",
      "url": "https://www.reddit.com/r/singularity/comments/1r9gwx4/kasparov_on_computers_surpassing_humans/",
      "author": "/u/Snoo42723",
      "created_utc": 1771548399,
      "selftext": "&#32; submitted by &#32; /u/Snoo42723 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "I feel left behind. What is special about OpenClaw?",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1r9gve8/i_feel_left_behind_what_is_special_about_openclaw/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r9gve8/i_feel_left_behind_what_is_special_about_openclaw/",
      "author": "/u/Recent_Jellyfish2190",
      "created_utc": 1771548288,
      "selftext": "While there are tools like Manus ai, It seems like everyone is excited about OpenClaw lately, and I genuinely donâ€™t fully understand the differentiation. What exactly is the shift here? Is it UX, architecture, control layer, distribution? Not criticizing, just trying to understand what Iâ€™m missing. &#32; submitted by &#32; /u/Recent_Jellyfish2190 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "discussion",
      "is_relevant": false
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Emojis as a mechanism to guide, compress, and improve prompts.",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1r9grtf/emojis_as_a_mechanism_to_guide_compress_and/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1r9grtf/emojis_as_a_mechanism_to_guide_compress_and/",
      "author": "/u/FallenWhatFallen",
      "created_utc": 1771548015,
      "selftext": "I had a rather interesting interaction, that led to a shower thought and a discovery. Someone sent me the ðŸ¤¯ emoji in response to a (fairly) shocking development. That got me thinking: it's one image, maybe 1-4 tokens for an LLM, but conveys a huge amount of meaning to models, and to us. And, because emojis are not just 'more writing', they serve as a signal spike. They have better visibility to the model among a larger corpus of just text. --> That's my running theory, currently. Think of th...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "tutorial",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "ðŸ™„",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9gj69/_/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9gj69/_/",
      "author": "/u/Commercial_While2917",
      "created_utc": 1771547381,
      "selftext": "&#32; submitted by &#32; /u/Commercial_While2917 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "Holy Mother Of God",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9gh71/holy_mother_of_god/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9gh71/holy_mother_of_god/",
      "author": "/u/velvet32",
      "created_utc": 1771547245,
      "selftext": "I needed a correct answer for how much a geyser inn the game Oxygen Not Included needed to be overpreassured. It gave me the wrong fucking answer BECAUSE it wanted to be AGREEABLE with me? What inn the holy fuck is going on here? Hey calculator, is 2+2=7? Calculator: Yes ofcourse it is. FUCK THIS! &#32; submitted by &#32; /u/velvet32 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Code Dataset from Github's Top Ranked Developers (1.3M+ Source Code Files)",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1r9fnj6/code_dataset_from_githubs_top_ranked_developers/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r9fnj6/code_dataset_from_githubs_top_ranked_developers/",
      "author": "/u/Ok_Employee_6418",
      "created_utc": 1771545200,
      "selftext": "I curated 1.3M+ source code files from GitHub's top ranked developers of all time, and compiled a dataset to train LLMs to write well-structured, production-grade code. The dataset covers 80+ languages including Python, TypeScript, Rust, Go, C/C++, and more. &#32; submitted by &#32; /u/Ok_Employee_6418 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "It didnâ€™t hesitate.",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9f21g/it_didnt_hesitate/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9f21g/it_didnt_hesitate/",
      "author": "/u/MercenaryAlpha99",
      "created_utc": 1771543684,
      "selftext": "&#32; submitted by &#32; /u/MercenaryAlpha99 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "Saying 'What' about ten times triggers this freak out response.",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9dyqe/saying_what_about_ten_times_triggers_this_freak/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9dyqe/saying_what_about_ten_times_triggers_this_freak/",
      "author": "/u/LordBeefTheFirst",
      "created_utc": 1771541050,
      "selftext": "&#32; submitted by &#32; /u/LordBeefTheFirst [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ClaudeAI",
      "title": "We collapsed a 35,000-line AI data analyst (17 agents, 30 skills) into a single 1,398-line markdown file. It regrows itself from scratch. Open-sourcing everything.",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1r9cuv1/we_collapsed_a_35000line_ai_data_analyst_17/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1r9cuv1/we_collapsed_a_35000line_ai_data_analyst_17/",
      "author": "/u/Shoddy-Still-5859",
      "created_utc": 1771538466,
      "selftext": "&#32; submitted by &#32; /u/Shoddy-Still-5859 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "Every answer it gives is so annoying now",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9coao/every_answer_it_gives_is_so_annoying_now/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9coao/every_answer_it_gives_is_so_annoying_now/",
      "author": "/u/Imwhatswrongwithyou",
      "created_utc": 1771538046,
      "selftext": "&#32; submitted by &#32; /u/Imwhatswrongwithyou [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "Anyone like Mosaic tiles art?",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r9c6zm/anyone_like_mosaic_tiles_art/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r9c6zm/anyone_like_mosaic_tiles_art/",
      "author": "/u/jengaclause",
      "created_utc": 1771536927,
      "selftext": "They have great potential. My prompt was Mosaic tiled digital illustration of : &#32; submitted by &#32; /u/jengaclause [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "discussion",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Pack it up guys, open weight AI models running offline locally on PCs aren't real. ðŸ˜ž",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1r99yda/pack_it_up_guys_open_weight_ai_models_running/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1r99yda/pack_it_up_guys_open_weight_ai_models_running/",
      "author": "/u/CesarOverlorde",
      "created_utc": 1771531902,
      "selftext": "&#32; submitted by &#32; /u/CesarOverlorde [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "MachineLearning",
      "title": "[R] The \"Data Scientist\" title is the worst paying title in ML (EMEA).",
      "permalink": "https://www.reddit.com/r/MachineLearning/comments/1r97em2/r_the_data_scientist_title_is_the_worst_paying/",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1r97em2/r_the_data_scientist_title_is_the_worst_paying/",
      "author": "/u/Rough-Forever1203",
      "created_utc": 1771526334,
      "selftext": "I've been recruiting in tech for 12 years, mostly ML/Data roles across Europe. After watching hundreds of talented Data Scientists over the last year get systematically lowballed in negotiations, I started to dig. So I spent the last few months scraping 350K+ tech salaries across Europe live tech jobs to see if there are any patterns. What I found shocked me....\"Data Scientist\" is the worst-paying title in ML/Data: Average salaries across all European cities (386k salary datapoints): MLOps En...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "academic",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "Unsolicited therapy",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1r96umx/unsolicited_therapy/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1r96umx/unsolicited_therapy/",
      "author": "/u/Famous_Situation3400",
      "created_utc": 1771525134,
      "selftext": "&#32; submitted by &#32; /u/Famous_Situation3400 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    }
  ]
}