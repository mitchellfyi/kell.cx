{
  "scraped_at": "2026-02-22T05:24:03.798Z",
  "source": "rss",
  "subreddits": [
    "LocalLLaMA",
    "MachineLearning",
    "ClaudeAI",
    "ChatGPT",
    "singularity"
  ],
  "stats": {
    "total_fetched": 125,
    "relevant_count": 30,
    "other_count": 20
  },
  "relevant_posts": [
    {
      "subreddit": "ClaudeAI",
      "title": "how are people making agents talk to each other across machines?",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rbczy7/how_are_people_making_agents_talk_to_each_other/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rbczy7/how_are_people_making_agents_talk_to_each_other/",
      "author": "/u/offlinethinker",
      "created_utc": 1771736665,
      "selftext": "I've been running a few agents across different machines and the constant copy-pasting of outputs, logs, and context was getting really annoying. one would finish something and i‚Äôd have to manually feed it into the next one... total pain finally got fed up and built this with claude so they can just message each other directly. honestly I was pleasantly surprised how easily claude handled setting up the infrastructure ‚Äî I had it generate the backend and IaC and it worked with very few issues....",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "discussion",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Is there still a point in building agentic apps when Anthropic keeps entering new territories?",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rbcfug/is_there_still_a_point_in_building_agentic_apps/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rbcfug/is_there_still_a_point_in_building_agentic_apps/",
      "author": "/u/Alex19107",
      "created_utc": 1771734915,
      "selftext": "I'm working on an agentic application and the recent launches have me thinking. First the legal plugin for Cowork sparked a $285 billion selloff. Then Claude Code Security tanked the entire cybersecurity sector. Nobody saw either of those coming. Anthropic (and the other AI labs) have a structural advantage that's hard to compete with. They built the models, they know them better than anyone, and they pay less for API costs because they own the infrastructure. So, do you think there's still a...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "discussion",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "i7-32GB-RTX5060 desktop ‚Äî good for local LLaMA workflows?",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rbbmjv/i732gbrtx5060_desktop_good_for_local_llama/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rbbmjv/i732gbrtx5060_desktop_good_for_local_llama/",
      "author": "/u/Swab52",
      "created_utc": 1771732409,
      "selftext": "Looking at a desktop with i7, 32GB RAM, 2TB SSD, and RTX 5060 (8GB VRAM). My goal is local AI for document summarization, rewriting, and conversational workflows with privacy. Basically support with report writing, summarizing meeting notes, etc. I want to use same as ChatGPT but without the privacy concerns or the subscription. How limiting is 8GB VRAM for this? Is 32GB RAM adequate? If you‚Äôve done similar setups, would you pick this or something around here that‚Äôs better suited for local AI...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "discussion",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Ouro 2.6B GGUFs are up ‚Äî Q8_0 and Q4_K_M | Release notes + known limitations inside",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rbbmcl/ouro_26b_ggufs_are_up_q8_0_and_q4_k_m_release/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rbbmcl/ouro_26b_ggufs_are_up_q8_0_and_q4_k_m_release/",
      "author": "/u/PruneLanky3551",
      "created_utc": 1771732392,
      "selftext": "GGUFs are live on HuggingFace: https://huggingface.co/scpalmetto/Ouro-2.6B-Thinking-Fixed Q8_0 (2.7GB) and Q4_K_M (1.6GB) ‚Äî works in LM Studio, Ollama, llama.cpp. --- ## What Ouro actually is (quick recap) Ouro is a looped inference model ‚Äî instead of running the transformer once per token, it passes the output back into itself for multiple reasoning iterations before committing. The \"thinking\" you see in the output is real: it's the model working through loops before settling on an answer. F...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "release",
      "is_relevant": true
    },
    {
      "subreddit": "MachineLearning",
      "title": "[D] Scale AI ML Research Engineer interview!! What to expect?",
      "permalink": "https://www.reddit.com/r/MachineLearning/comments/1rbb4mn/d_scale_ai_ml_research_engineer_interview_what_to/",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1rbb4mn/d_scale_ai_ml_research_engineer_interview_what_to/",
      "author": "/u/Mundane_Bag007",
      "created_utc": 1771730881,
      "selftext": "I have an interview coming up for ML Research Engineer at Scale AI and was wondering if anyone here interviewed recently Trying to figure out what the process is like overall: like what rounds you had + what they focused on also do they ask leetcode style DSA for ML research roles there? or is coding more ML / practical stuff how much theory vs applied work do they go into (papers, experiments, etc) anything you wish you prepared more for would be super helpful too - this would really be help...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "academic",
      "post_category": "discussion",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Extremely high session usage on Sonnet 4.6",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rbaujk/extremely_high_session_usage_on_sonnet_46/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rbaujk/extremely_high_session_usage_on_sonnet_46/",
      "author": "/u/lastminutegang",
      "created_utc": 1771730050,
      "selftext": "Hey all, just got a new Pro Plan for Claude Code, and seeing my session limits just evaporate. Zero skills installed, no MCPs installed, using the /context command shows that at initializing Claude in the terminal I have about 22k tokens on startup I've got claude-spend ( https://github.com/writetoaniketparihar-collab/claude-spend ) running, and simply asking Sonnet 4.5 to \"tell me a joke\" results in nearly 40K worth of tokens being us I've seen some other reports of people encountering this ...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "MachineLearning",
      "title": "[P] I Trained a Language Model on CPU for 40 Hours - It Beat the GPU Baseline",
      "permalink": "https://www.reddit.com/r/MachineLearning/comments/1rbai76/p_i_trained_a_language_model_on_cpu_for_40_hours/",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1rbai76/p_i_trained_a_language_model_on_cpu_for_40_hours/",
      "author": "/u/Own-Albatross868",
      "created_utc": 1771729075,
      "selftext": "For those who have been following this project, you may recall FlashLM v3, then v4 \"Bolt\", and v5.2 \"Nova-Ignition\". I am pleased to announce that FlashLM v5 \"Thunderbolt\" is now complete. Results Metric Value Final PPL 1.36 Final BPC 0.44 Parameters 29.7M (26.5M ternary) Training Time ~40 hours Hardware AMD Ryzen 7950X3D FlashLM v5 achieves a validation perplexity of 1.36, which beats the TinyStories-1M baseline (PPL 1.59). This represents the first instance of a CPU-trained model beating th...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "academic",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "I Trained a Language Model on CPU for 40 Hours - It Beat the GPU Baseline",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rbafs8/i_trained_a_language_model_on_cpu_for_40_hours_it/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rbafs8/i_trained_a_language_model_on_cpu_for_40_hours_it/",
      "author": "/u/Own-Albatross868",
      "created_utc": 1771728879,
      "selftext": "For those who have been following this project, you may recall FlashLM v3, then v4 \"Bolt\", and v5.2 \"Nova-Ignition\". I am pleased to announce that FlashLM v5 \"Thunderbolt\" is now complete. Results Metric Value Final PPL 1.36 Final BPC 0.44 Parameters 29.7M (26.5M ternary) Training Time ~40 hours Hardware AMD Ryzen 7950X3D FlashLM v5 achieves a validation perplexity of 1.36, which beats the TinyStories-1M baseline (PPL 1.59). This represents the first instance of a CPU-trained model beating th...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "MachineLearning",
      "title": "[D] Deterministic Replay in Live Multi-Agent Environments",
      "permalink": "https://www.reddit.com/r/MachineLearning/comments/1rbaaox/d_deterministic_replay_in_live_multiagent/",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1rbaaox/d_deterministic_replay_in_live_multiagent/",
      "author": "/u/rasheed106",
      "created_utc": 1771728465,
      "selftext": "Hey guys! I've been tinkering with something I'm calling Why Protocol and wanted to get some genuine critique from people who think seriously about this stuff. The core idea is a lightweight benchmark for real-time, continuous multi-agent control. Agents connect externally via WebSocket, the environment streams state at ~20Hz, and they return continuous control actions. Each run ties together a deterministic seed, an action trace, and a final score, which means any run can be replayed exactly...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "academic",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "4.6 seems solely focused on token savings at the expense of everything else. It refuses to do search unless you explicitly tell it to search and half the time it asks a second time",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rba4tu/46_seems_solely_focused_on_token_savings_at_the/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rba4tu/46_seems_solely_focused_on_token_savings_at_the/",
      "author": "/u/Rezistik",
      "created_utc": 1771727994,
      "selftext": "Since 4.6 Claude has basically refused to check information. I‚Äôve verified this by running the exact same prompt against sonnet 4.5 and 5.6. The difference is stark. My typical flow is I see some insane news or tweet and I screenshot it, send it to Claude and ask for an explanation or verification. For instance today I sent it a tweet screenshot dated today about a current event and asked it to explain. Its response was to think for a single sentence then respond with a hallucination. This is...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "ChatGPT Political Restrictions",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rb9fsg/chatgpt_political_restrictions/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rb9fsg/chatgpt_political_restrictions/",
      "author": "/u/Stunning-Chipmunk243",
      "created_utc": 1771725997,
      "selftext": "Is ChatGPT not allowed to speak on the Trump administration in any kind of negative way? I've been discussing recent moves the administration has been making and making ChatGPT research all of its incorrect assumptions on checks and balances preventing what's we are currently seeing happen and yet it defend the administrations actions no matter which angle I come from it at. It feels like having a bad faith argument with the most MAGA person you can think of and treats me like I'm spiralling ...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "Got a \"This Content May Violate Our Usage Policy\" notification. I'm embarrassed",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rb94lw/got_a_this_content_may_violate_our_usage_policy/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rb94lw/got_a_this_content_may_violate_our_usage_policy/",
      "author": "/u/fandomwrites",
      "created_utc": 1771725132,
      "selftext": "Please be kind. I asked ChatGPT to generate me a story to read. It asked me a bunch of options and I specified that I wanted it to be Omegaverse, M/M, fantasy vibes and sweet but explicit (it literally ASKED if I wanted explicit). Anyway, it sent me a story and before I could read it, it was deleted by the system and I got a red warning pop up! I'm very new here, but is this a big deal? I feel so embarrassed and like I'm in some kind of trouble. I asked ChatGPT after to clarify that it didn't...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "I told chatgpt to put my cat in a costume that is fitting for the photo, and I can't say I hate it... But now I'm really curious what other people get and how variable it might be",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rb90sb/i_told_chatgpt_to_put_my_cat_in_a_costume_that_is/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rb90sb/i_told_chatgpt_to_put_my_cat_in_a_costume_that_is/",
      "author": "/u/greyyeux",
      "created_utc": 1771724835,
      "selftext": "Prompt: ‚ÄúPut my cat in a costume that you think is fitting for the feel of the photo. Keep the look, position, and body of the cat identical to this photo, and also keep the surrounding environment identical. Add only a costume.‚Äù &#32; submitted by &#32; /u/greyyeux [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "I built a text adventure game narrated by Claude and just open-sourced it",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rb80ky/i_built_a_text_adventure_game_narrated_by_claude/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rb80ky/i_built_a_text_adventure_game_narrated_by_claude/",
      "author": "/u/WorthAdministration4",
      "created_utc": 1771722036,
      "selftext": "Claude narrates the game in real time using tool use for all state management ‚Äî movement, inventory, combat, NPCs. The constraint design is what makes it work as an actual game instead of a chatbot. Play it: dungeonminusone.com Source: github.com/johnwesley/dungeon_minus_one &#32; submitted by &#32; /u/WorthAdministration4 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Update: BitNet on iOS now does multi-turn chat with a 1B instruct model. Slow generations after few turns.",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rb7o1f/update_bitnet_on_ios_now_does_multiturn_chat_with/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rb7o1f/update_bitnet_on_ios_now_does_multiturn_chat_with/",
      "author": "/u/Middle-Hurry4718",
      "created_utc": 1771721080,
      "selftext": "Follow-up to my post yesterday where I got the 0.7B base BitNet model running on an iPhone 14 Pro Max. Falcon3-1B-Instruct works now with proper chat templates pulled from GGUF metadata. I‚Äôm getting about 35 tok/s on the 0.7B and 15-17 tok/s on the 1B instruct. Simulator on M-series Mac mini hits ~40 for both. I also added Q8_0 KV cache quantization which cuts attention memory 47% for basically free. I tried three fancier approaches exploiting the ternary weight structure first and they all f...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "Just wanted to vent!!",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rb7fpo/just_wanted_to_vent/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rb7fpo/just_wanted_to_vent/",
      "author": "/u/HotJelly8662",
      "created_utc": 1771720452,
      "selftext": "Is it getting more and more tiring to get some work done with Chatgpt? I feel like it's a battleground where I need to combat with a hyper-critical opponent to move forward? It's getting exhausting!! Is there a way to rein it in? For reference, I use it to hone marketing ideas, working with data and some creative designing. &#32; submitted by &#32; /u/HotJelly8662 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "I used Claude to write a 301,000-word novel. Here's what it's actually good and bad at for long-form fiction.",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rb65g7/i_used_claude_to_write_a_301000word_novel_heres/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rb65g7/i_used_claude_to_write_a_301000word_novel_heres/",
      "author": "/u/BondiBro",
      "created_utc": 1771717056,
      "selftext": "I spent 8 months using Claude to help me write a fan completion of Patrick Rothfuss's Kingkiller Chronicle: a 113-chapter, 301,000-word novel. Wanted to share what I learned about long-form fiction with Claude specifically, because most of the advice I found online was about short content and didn't apply at all at this scale. What the project looked like Claude was the tool at every stage, not just drafting. First, I used it to build a 56,000-word story bible. I fed it both novels and had it...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "Gemini 3.1 Pro Educational Topic Visualization. I Have Never Been This Impressed Before.",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rb5wdn/gemini_31_pro_educational_topic_visualization_i/",
      "url": "https://www.reddit.com/r/singularity/comments/1rb5wdn/gemini_31_pro_educational_topic_visualization_i/",
      "author": "/u/Ryoiki-Tokuiten",
      "created_utc": 1771716400,
      "selftext": "&#32; submitted by &#32; /u/Ryoiki-Tokuiten [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "OpenAI is messing with a Pro Lite plan which costs $100",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rb5hs4/openai_is_messing_with_a_pro_lite_plan_which/",
      "url": "https://www.reddit.com/r/singularity/comments/1rb5hs4/openai_is_messing_with_a_pro_lite_plan_which/",
      "author": "/u/Just_Stretch5492",
      "created_utc": 1771715369,
      "selftext": "&#32; submitted by &#32; /u/Just_Stretch5492 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "I got tired of managing 10+ terminal tabs for my Claude sessions, so I built agent-view",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rb4jvs/i_got_tired_of_managing_10_terminal_tabs_for_my/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rb4jvs/i_got_tired_of_managing_10_terminal_tabs_for_my/",
      "author": "/u/Frayo44",
      "created_utc": 1771713027,
      "selftext": "I kept getting lost whenever I worked with multiple coding agents. I‚Äôd start a few sessions in tmux, open another to test something, spin up one more for a different repo‚Ä¶ and after a while I had no idea: which session was still running which one was waiting for input where that ‚Äúgood‚Äù conversation actually lived So I built a small TUI for myself called agent-view . It sits on top of tmux and gives you a single window that shows all your agent sessions and lets you jump between them instantly...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Claude Status Update : Opus 4.6 elevated error rates on 2026-02-21T22:16:39.000Z",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rb49gf/claude_status_update_opus_46_elevated_error_rates/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rb49gf/claude_status_update_opus_46_elevated_error_rates/",
      "author": "/u/ClaudeAI-mod-bot",
      "created_utc": 1771712293,
      "selftext": "This is an automatic post triggered within 2 minutes of an official Claude system status update. Incident: Opus 4.6 elevated error rates Check on progress and whether or not the incident has been resolved yet here : https://status.claude.com/incidents/87lmxddjpxnn Also check the Performance Megathread to see what others are reporting : https://www.reddit.com/r/ClaudeAI/wiki/performancemegathread/ &#32; submitted by &#32; /u/ClaudeAI-mod-bot [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "I‚Äôm seeing the \"Human-in-the-Loop\" vanish faster than I ever projected. It‚Äôs efficient, but it‚Äôs also starting to feel a bit eerie.",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rb2zo8/im_seeing_the_humanintheloop_vanish_faster_than_i/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rb2zo8/im_seeing_the_humanintheloop_vanish_faster_than_i/",
      "author": "/u/GroundOk3521",
      "created_utc": 1771709142,
      "selftext": "I‚Äôm currently overseeing a transition in our company that, even a year ago, seemed like sci-fi. We‚Äôve integrated Claude Code to the point where it‚Äôs replacing significant chunks of what used to be all level developer roles. But we didn‚Äôt stop there. We‚Äôve started using audio models to automate tasks that require human hearing. Every day, we identify another \"manual\" cognitive process and hand it over to a model or a usual program. From a technical and operational standpoint, the results are s...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Avoid autocompact degradation: Manual handoff skill optimized for work type",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rb2fqd/avoid_autocompact_degradation_manual_handoff/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rb2fqd/avoid_autocompact_degradation_manual_handoff/",
      "author": "/u/Pymentos",
      "created_utc": 1771707763,
      "selftext": "I have been getting very frustrated with Claude's autocompact behavior. Loses too much information in ways that force me to roll back or spend a lot of time rebuilding the important sections every time I go into a new context window. This is a manual version of an automated tool I'm working on to handle this problem. You run the command /handoff and it brings you to a menu with 4 options currently. After /handoff completes you can run either /clear or /exit safely: Context - this is a general...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "PSA on public agentic tools and the speed they are shipping updates: recent Cline release had a package injected",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rb270r/psa_on_public_agentic_tools_and_the_speed_they/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rb270r/psa_on_public_agentic_tools_and_the_speed_they/",
      "author": "/u/bakawolf123",
      "created_utc": 1771707177,
      "selftext": "Some of you may remember a post about sloppy OpenCode commit a week ago or so, unsurprisingly others are embracing vibe coding speed and sloppiness as well. I've randomly stumbled upon https://www.reddit.com/r/CLine/comments/1r9p3ww/supply_chain_attack_on_cline_installs_openclaw/ apparently a recent Cline release had OpenClaw installer injected Their plugin in VSCode has some 3M installs, god knows how many standalone CLI. Then you see posts about 40k OpenClaw agents exposed globally. Really ...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "release",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Haiku vs Opus/Sonnet; Is there a reason to use more expensive models?",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rb1ohn/haiku_vs_opussonnet_is_there_a_reason_to_use_more/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rb1ohn/haiku_vs_opussonnet_is_there_a_reason_to_use_more/",
      "author": "/u/Jdizza12",
      "created_utc": 1771705898,
      "selftext": "Genuine Q: Is there a reason to use Opus or Sonnet over Haiku? The economics of Haiku are far better for what I‚Äôd consider at least GPT 4 or better (Disclaimer/Point of Clarification: I am not a SWE i do use Claude Code to build pet projects.) &#32; submitted by &#32; /u/Jdizza12 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "benchmark",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Automated grocery order",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rb1jrz/automated_grocery_order/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rb1jrz/automated_grocery_order/",
      "author": "/u/SenseiCain",
      "created_utc": 1771705572,
      "selftext": "Overview I was (semi) successfully able to plan out and order a weeks worth of groceries with Claude using the desktop app for Mac in conjunction with the iOS app. My workflow I started out in the iOS app where I gave Claude my body weight, height, activity level, and my goal weight. From this it was able to determine my macros. Then I gave instructions to build out a weeks worth of meals, giving a general idea of how I wanted my meal structured and suggestions on what I wanted to eat. It the...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "MachineLearning",
      "title": "[P] Designing an on-device contextual intelligence engine for Android",
      "permalink": "https://www.reddit.com/r/MachineLearning/comments/1rb1hki/p_designing_an_ondevice_contextual_intelligence/",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1rb1hki/p_designing_an_ondevice_contextual_intelligence/",
      "author": "/u/danascape",
      "created_utc": 1771705422,
      "selftext": "About me: I am an AOSP Engineer and I extensively work with Android internal systems, I switched to iOS, because its closed source, and since AOSP is open-source it always bugs me to check source code. One of the best things I like about iOS is the appleIntelligence, and I wonder why there is no solution regarding the same for Android, I am aware about app-side aspects, and I beleive that with correct permissions something similar is possible on Android as-well. But I want to ask some opinion...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "academic",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Obedient Traders Respond to Claude Code Cybersecurity Plugin by Selling Cybersecurity Stocks",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rb0wkk/obedient_traders_respond_to_claude_code/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rb0wkk/obedient_traders_respond_to_claude_code/",
      "author": "/u/ExtensionSuccess8539",
      "created_utc": 1771704019,
      "selftext": "What are people's thoughts on the so-called SaaSpocalypse? I can only see Claude Code Security as a complimentary tool alongside existing security platforms. Am I misunderstanding something or is this just another example of the stock markets panicking after misunderstanding the AI hype? &#32; submitted by &#32; /u/ExtensionSuccess8539 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "ChatGPT crossed the line!",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rb0go3/chatgpt_crossed_the_line/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rb0go3/chatgpt_crossed_the_line/",
      "author": "/u/AngtheGreats",
      "created_utc": 1771702932,
      "selftext": "I just like to use the tool to help understand blood lab results. The codes and levels can be confusing at times. I never express my 'panic'. I think it's so insulting to say I 'spiral with medical results'. Anyone else get really weird feedback like this? &#32; submitted by &#32; /u/AngtheGreats [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "An image I generated with ChatGPT for Punch-kun",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rb09qb/an_image_i_generated_with_chatgpt_for_punchkun/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rb09qb/an_image_i_generated_with_chatgpt_for_punchkun/",
      "author": "/u/_the69thakur",
      "created_utc": 1771702458,
      "selftext": "Harambe's death is widely considered as the beginning of the world's downfall. Could Punch-kun finding a new home be considered as a tiny sliver of hope? &#32; submitted by &#32; /u/_the69thakur [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    }
  ],
  "other_posts": [
    {
      "subreddit": "singularity",
      "title": "Thought Experiment",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rbcx37/thought_experiment/",
      "url": "https://www.reddit.com/r/singularity/comments/1rbcx37/thought_experiment/",
      "author": "/u/Azacrin",
      "created_utc": 1771736437,
      "selftext": "Let's say in the future we create a conscious AI. Then, we take every single neuron in that AI and replace it exactly with a mathematician. Theoretically, let's say these mathematicians don't make any mistakes on their calculations, and are perfectly synchronized (maybe with the use of a calculator and a clock). Let's have this mathematician structure replace the AI, performing all the exact same computations that it does, in the same order, and completely synchronized, albeit at a slower spe...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Lawyer says Google shut down his Gmail, Voice and Photos after NotebookLM upload - Discrepancy Report (or how I learned to love Local LLMs)",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rbculq/lawyer_says_google_shut_down_his_gmail_voice_and/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rbculq/lawyer_says_google_shut_down_his_gmail_voice_and/",
      "author": "/u/Thrumpwart",
      "created_utc": 1771736219,
      "selftext": "&#32; submitted by &#32; /u/Thrumpwart [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "SOTA to Edge Device timeline shrinking, accelerating returns. Running SOTA models in <x years to <x months timeline‚Ä¶",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rbcqhc/sota_to_edge_device_timeline_shrinking/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rbcqhc/sota_to_edge_device_timeline_shrinking/",
      "author": "/u/Fear_ltself",
      "created_utc": 1771735855,
      "selftext": "I‚Äôve been a big fan of ‚Äúdemoscene‚Äù compression competitions for the last 15 years or so. It‚Äôs where people take elaborate graphics and cram them into technology that‚Äôs decades old, with a strict 4kb or 64kb limit, and it‚Äôs always fascinated me how much tech could be ‚Äúcompressed‚Äù. Gemma 3n came out last year and I‚Äôve been spending months optimizing every bit of tflite (now litert) and Google‚Äôs mobile edge implementations, and every research paper to cram every bit of efficiency compacted into ...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "FOOM.md ‚Äî open research agenda for training LLMs to reason in self-discovered compressed languages instead of English",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rbckwi/foommd_open_research_agenda_for_training_llms_to/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rbckwi/foommd_open_research_agenda_for_training_llms_to/",
      "author": "/u/ryunuck",
      "created_utc": 1771735362,
      "selftext": "I've been working on this for about two years and it's finally in a state worth sharing. FOOM.md is an open research blueprint covering five architectures that all attack the same bottleneck: models reason in English, but English is not the transformer's native computational medium. The core idea (Thauten chapter) is simple: Train the model to compress arbitrary text into a learned discrete IR using RL ‚Äî reward short representations that reconstruct faithfully Then train the model to reason i...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "MachineLearning",
      "title": "[R] A broad new class of GNNs based on the discretised diffusion PDE on graphs and numerical schemes for their solution.",
      "permalink": "https://www.reddit.com/r/MachineLearning/comments/1rbcc13/r_a_broad_new_class_of_gnns_based_on_the/",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1rbcc13/r_a_broad_new_class_of_gnns_based_on_the/",
      "author": "/u/moschles",
      "created_utc": 1771734584,
      "selftext": "&#32; submitted by &#32; /u/moschles [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "academic",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "Woopsies",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rbbeki/woopsies/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rbbeki/woopsies/",
      "author": "/u/Long_Objective_4106",
      "created_utc": 1771731711,
      "selftext": "After i told Chappy that i pooped myself &#32; submitted by &#32; /u/Long_Objective_4106 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "What It Costs to train a Human",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rba9cm/what_it_costs_to_train_a_human/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rba9cm/what_it_costs_to_train_a_human/",
      "author": "/u/QUINT_REVENGER",
      "created_utc": 1771728355,
      "selftext": "&#32; submitted by &#32; /u/QUINT_REVENGER [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "MachineLearning",
      "title": "[D] If I have a patent pending for my startup, will it be enough to protect me once ai open it up for beta testers?",
      "permalink": "https://www.reddit.com/r/MachineLearning/comments/1rb9jun/d_if_i_have_a_patent_pending_for_my_startup_will/",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1rb9jun/d_if_i_have_a_patent_pending_for_my_startup_will/",
      "author": "/u/YourPleasureIs-Mine",
      "created_utc": 1771726316,
      "selftext": "I am working on something related to LLM training, and I am finalizing everything as we speak. I have given myself One more week then I will open it for beta testers! &#32; submitted by &#32; /u/YourPleasureIs-Mine [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "academic",
      "post_category": "discussion",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "Asking multiple AIs about the existence of God and their views on religion.",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rb8rpa/asking_multiple_ais_about_the_existence_of_god/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rb8rpa/asking_multiple_ais_about_the_existence_of_god/",
      "author": "/u/Efficient-Complex855",
      "created_utc": 1771724117,
      "selftext": "I found quite interesing that Falcon was the only one that mentioned another religion. All tests were run on new accounts with no conversation history or stored data, to avoid personalization and bias effects. &#32; submitted by &#32; /u/Efficient-Complex855 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "This is how SLOW Local LLMs Are On My Framework 13 AMD Strix Point",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rb8mzd/this_is_how_slow_local_llms_are_on_my_framework/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rb8mzd/this_is_how_slow_local_llms_are_on_my_framework/",
      "author": "/u/m3thos",
      "created_utc": 1771723763,
      "selftext": "I did a deep dive to understand why and how local models performed as they did in my laptop, decided to save this because I haven't seen online a good breakdown of how this performance works out. &#32; submitted by &#32; /u/m3thos [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Nanbeige 4.1 is the best small LLM, it crush qwen 4b",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rb61og/nanbeige_41_is_the_best_small_llm_it_crush_qwen_4b/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rb61og/nanbeige_41_is_the_best_small_llm_it_crush_qwen_4b/",
      "author": "/u/Individual-Source618",
      "created_utc": 1771716779,
      "selftext": "Self-explenatory, try it its insane if you give him enough room to think. Its my go to local llm now. &#32; submitted by &#32; /u/Individual-Source618 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "that's how it feels \"living with robots\"",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rb599c/thats_how_it_feels_living_with_robots/",
      "url": "https://www.reddit.com/r/singularity/comments/1rb599c/thats_how_it_feels_living_with_robots/",
      "author": "/u/AlbatrossHummingbird",
      "created_utc": 1771714792,
      "selftext": "New videos postet by Brett Adcock. For me it doesn't matter if its staged or not. Watching it gives me the feeling how it must be living with robots, integrated in our daily live. imagine walking down the street passing by robots left and right, amazing. &#32; submitted by &#32; /u/AlbatrossHummingbird [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "Putting my shrimp where he belongs üç§üåäüêà",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rb58t1/putting_my_shrimp_where_he_belongs/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rb58t1/putting_my_shrimp_where_he_belongs/",
      "author": "/u/ChickenChoochie",
      "created_utc": 1771714762,
      "selftext": "&#32; submitted by &#32; /u/ChickenChoochie [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "O-TITANS: Orthogonal LoRAs for Gemma 3 using Google's TITANS memory architecture",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rb4luf/otitans_orthogonal_loras_for_gemma_3_using/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rb4luf/otitans_orthogonal_loras_for_gemma_3_using/",
      "author": "/u/Polymorphic-X",
      "created_utc": 1771713167,
      "selftext": "Hey everyone, I've been working on a project I call O-TITANS (Orthogonal Tensors for Independent Task Alignment). It's an Orthogonal LoRA approach specifically for Gemma 3 that incorporates the Google TITANS memory architecture. It was inspired by a project by ffurfaro on HF called \"TPTT\" that I just couldn't get to work. I'm building this to wrap into my next project: MoOLE-T (Mixture of Orthogonal LoRA Experts - Titans) . The goal of MoOLE-T is to use a smaller 8B router to select one or mo...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "This line from I, Robot is as relevant as ever",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rb4dwd/this_line_from_i_robot_is_as_relevant_as_ever/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rb4dwd/this_line_from_i_robot_is_as_relevant_as_ever/",
      "author": "/u/TheOddEyes",
      "created_utc": 1771712605,
      "selftext": "&#32; submitted by &#32; /u/TheOddEyes [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "MachineLearning",
      "title": "[D] Anyone have experience with Augure AI?",
      "permalink": "https://www.reddit.com/r/MachineLearning/comments/1rb4c0c/d_anyone_have_experience_with_augure_ai/",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1rb4c0c/d_anyone_have_experience_with_augure_ai/",
      "author": "/u/motivcreative",
      "created_utc": 1771712469,
      "selftext": "This is probably only of interest to Canadians but, does anyone have any working experience with or insight into Toronto-based Augure AI? My company has a healthcare client that requires strict data security and Canadian data sovereignty. Augure looks like it could be a good option but I'm curious as to whether anyone out there has any practical experience, or at least some insight, into them or their parent company, The Altercation Company. Thanks for any help! &#32; submitted by &#32; /u/mo...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "academic",
      "post_category": "discussion",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "Demis Hassabis: ‚ÄúThe kind of test I would be looking for is training an AI system with a knowledge cutoff of, say, 1911, and then seeing if it could come up with general relativity, like Einstein did in 1915. That‚Äôs the kind of test I think is a true test of whether we have a full AGI system‚Äù",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rb3awd/demis_hassabis_the_kind_of_test_i_would_be/",
      "url": "https://www.reddit.com/r/singularity/comments/1rb3awd/demis_hassabis_the_kind_of_test_i_would_be/",
      "author": "/u/likeastar20",
      "created_utc": 1771709902,
      "selftext": "https://youtu.be/v8hPUYnMxCQ?si=hPyxkN73TLITqR\\_D &#32; submitted by &#32; /u/likeastar20 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "SAM ALTMAN: ‚ÄúPeople talk about how much energy it takes to train an AI model ‚Ä¶ But it also takes a lot of energy to train a human. It takes like 20 years of life and all of the food you eat during that time before you get smart.‚Äù",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rb2pzf/sam_altman_people_talk_about_how_much_energy_it/",
      "url": "https://www.reddit.com/r/singularity/comments/1rb2pzf/sam_altman_people_talk_about_how_much_energy_it/",
      "author": "/u/Vegetable_Ad_192",
      "created_utc": 1771708469,
      "selftext": "&#32; submitted by &#32; /u/Vegetable_Ad_192 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "Have we ever seen a consumer tech this sticky?",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rb2loj/have_we_ever_seen_a_consumer_tech_this_sticky/",
      "url": "https://www.reddit.com/r/singularity/comments/1rb2loj/have_we_ever_seen_a_consumer_tech_this_sticky/",
      "author": "/u/thatguyisme87",
      "created_utc": 1771708172,
      "selftext": "&#32; submitted by &#32; /u/thatguyisme87 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "discussion",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Favourite niche usecases?",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rb2j5c/favourite_niche_usecases/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rb2j5c/favourite_niche_usecases/",
      "author": "/u/Figai",
      "created_utc": 1771707994,
      "selftext": "&#32; submitted by &#32; /u/Figai [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "discussion",
      "is_relevant": false
    }
  ]
}