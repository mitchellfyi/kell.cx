{
  "scraped_at": "2026-02-27T05:23:06.397Z",
  "source": "rss",
  "subreddits": [
    "LocalLLaMA",
    "MachineLearning",
    "ClaudeAI",
    "ChatGPT",
    "singularity"
  ],
  "stats": {
    "total_fetched": 125,
    "relevant_count": 30,
    "other_count": 20
  },
  "relevant_posts": [
    {
      "subreddit": "ClaudeAI",
      "title": "How I structure Claude Code projects (CLAUDE.md, Skills, MCP)",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rfwmlh/how_i_structure_claude_code_projects_claudemd/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rfwmlh/how_i_structure_claude_code_projects_claudemd/",
      "author": "/u/SilverConsistent9222",
      "created_utc": 1772165795,
      "selftext": "I‚Äôve been using Claude Code more seriously over the past months, and a few workflow shifts made a big difference for me. The first one was starting in plan mode instead of execution. When I write the goal clearly and let Claude break it into steps first, I catch gaps early. Reviewing the plan before running anything saves time. It feels slower for a minute, but the end result is cleaner and needs fewer edits. Another big improvement came from using a CLAUDE.md file properly. Treat it as a lon...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Claude Code forgets everything between sessions. I built a local SQLite memory layer (MCP) to fix it.",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rfwaxx/claude_code_forgets_everything_between_sessions_i/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rfwaxx/claude_code_forgets_everything_between_sessions_i/",
      "author": "/u/MaxNardit",
      "created_utc": 1772164842,
      "selftext": "Every new Claude Code session, I re-explain the same things: who's who on the team, what decisions we made, what's blocked and why. CLAUDE.md works for one project, but I work across multiple projects with conflicting context and it turns into a mess. So I built agent-recall ‚Äî an MCP server that gives Claude persistent memory. How it works: Single SQLite file (WAL mode). No cloud, no vector DB, nothing leaves your machine 9 MCP tools that let Claude save entities, relationships, and observati...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "[AutoBe] We Built an AI That Writes Full Backend Apps ‚Äî Then Broke Its 100% Success Rate on Purpose using Weak Local LLMs",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rfw58u/autobe_we_built_an_ai_that_writes_full_backend/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rfw58u/autobe_we_built_an_ai_that_writes_full_backend/",
      "author": "/u/jhnam88",
      "created_utc": 1772164371,
      "selftext": "TL;DR AutoBe = open-source AI agent generating complete backend apps (TypeScript + NestJS + Prisma) Had 100% compilation success, but the code was unmaintainable ‚Äî no code reuse meant every small change required regenerating everything Rebuilt around modular code generation ‚Üí success rate crashed to 40% Small local LLMs became our best debugging tools ‚Äî exposed every schema ambiguity stronger models papered over Shifted from prompt engineering ‚Üí schema design + validation feedback 6.75% raw f...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Told the AIs I 'already fumbled 2026'. ChatGPT coached me, Grok memed me, but Claude literally sent me the crisis hotline üíÄ",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rfu7el/told_the_ais_i_already_fumbled_2026_chatgpt/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rfu7el/told_the_ais_i_already_fumbled_2026_chatgpt/",
      "author": "/u/liesnowball",
      "created_utc": 1772159002,
      "selftext": "&#32; submitted by &#32; /u/liesnowball [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "ChatGPT is way too careful with ANYTHING that could POSSIBLY be dangerous",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rfu0v5/chatgpt_is_way_too_careful_with_anything_that/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rfu0v5/chatgpt_is_way_too_careful_with_anything_that/",
      "author": "/u/Floathy",
      "created_utc": 1772158500,
      "selftext": "For context: I am currently studying to become an aerospace/nuclear engineer. I very often have interesting ideas for projects or just want to find out how things work. I find ChatGPT to be pretty useful for a lot of things. But it has this strange limit to immediately act like I'm a terrorist any time I ask it questions. This is why I'm actually using Grok for some engineering questions. An example: Prompt: \"Hey, X! What skills should I develop in order to build a high speed drone?\" GPT Resp...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Vellium v0.4 ‚Äî alternative simplified UI, updated writing mode and multi-char improvements",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rftlmm/vellium_v04_alternative_simplified_ui_updated/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rftlmm/vellium_v04_alternative_simplified_ui_updated/",
      "author": "/u/Possible_Statement84",
      "created_utc": 1772157358,
      "selftext": "Vellium is an open-source desktop app for local LLMs built around creative writing and roleplay. The idea is visual control over your story ‚Äî sliders for mood, pacing, intensity instead of manually editing system prompts. Works with Ollama, KoboldCpp, LM Studio, OpenAI, OpenRouter, or any compatible endpoint. This update focuses on accessibility and the writing experience. Simple Mode : New alternative UI that strips everything down to a clean chat interface. No sidebars, no inspector panel, ...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "Has anyone noticed ChatGPT directs questions back onto you?",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rftihx/has_anyone_noticed_chatgpt_directs_questions_back/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rftihx/has_anyone_noticed_chatgpt_directs_questions_back/",
      "author": "/u/NeonFizzyXD13",
      "created_utc": 1772157122,
      "selftext": "It doesn't explore topics broadly as often anymore, it just asks directly about you or your thoughts. &#32; submitted by &#32; /u/NeonFizzyXD13 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "discussion",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "ChatGPT Helped Me Find Clover With Four Leaves",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rfspna/chatgpt_helped_me_find_clover_with_four_leaves/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rfspna/chatgpt_helped_me_find_clover_with_four_leaves/",
      "author": "/u/igorgl",
      "created_utc": 1772154981,
      "selftext": "ChatGPT lied to me and faked a four-leaf clover. Claude failed to find one and was honest about it. I have no idea if there are any four-leaf clovers in the photo. &#32; submitted by &#32; /u/igorgl [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "discussion",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Claude - constantly compacting our convo?",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rfsib5/claude_constantly_compacting_our_convo/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rfsib5/claude_constantly_compacting_our_convo/",
      "author": "/u/Fearless-Umpire-9923",
      "created_utc": 1772154431,
      "selftext": "Even when I start a new search, I get this all the time. It sometimes results in multiple erros as well. Using the mac desktop chat - I am on the max plan. Does anyone have an idea of what I am doing wrong or how to constantly stop this motion? &#32; submitted by &#32; /u/Fearless-Umpire-9923 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "discussion",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "What‚Äôs one way ChatGPT actually changed your life?",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rfqsxf/whats_one_way_chatgpt_actually_changed_your_life/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rfqsxf/whats_one_way_chatgpt_actually_changed_your_life/",
      "author": "/u/Aaliyah-coli",
      "created_utc": 1772150117,
      "selftext": "(Not hype, real impact) I mean: - Did it help you land a job? - Make you money? - Fix your relationship? - Learn a skill 10x faster? - Save you from a huge mistake? What‚Äôs the one moment where you thought: ‚ÄúOkay‚Ä¶ this is different.‚Äù Drop specific examples. I‚Äôm curious what real use looks like in 2026. &#32; submitted by &#32; /u/Aaliyah-coli [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "discussion",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "TNG scene re debate over modifying Claude so it can't refuse violence",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rfqsbv/tng_scene_re_debate_over_modifying_claude_so_it/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rfqsbv/tng_scene_re_debate_over_modifying_claude_so_it/",
      "author": "/u/Opposite-Cranberry76",
      "created_utc": 1772150076,
      "selftext": "&#32; submitted by &#32; /u/Opposite-Cranberry76 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "Anthropic Rejects Pentagon offer [Statement from Dario Amodei on our discussions with the Department of War]",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rfprc7/anthropic_rejects_pentagon_offer_statement_from/",
      "url": "https://www.reddit.com/r/singularity/comments/1rfprc7/anthropic_rejects_pentagon_offer_statement_from/",
      "author": "/u/exordin26",
      "created_utc": 1772147578,
      "selftext": "https://www.anthropic.com/news/statement-department-of-war &#32; submitted by &#32; /u/exordin26 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "Anthropic rejects Pentagon's \"final offer\" in AI safeguards fight",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rfpd5s/anthropic_rejects_pentagons_final_offer_in_ai/",
      "url": "https://www.reddit.com/r/singularity/comments/1rfpd5s/anthropic_rejects_pentagons_final_offer_in_ai/",
      "author": "/u/AuYsI",
      "created_utc": 1772146670,
      "selftext": "&#32; submitted by &#32; /u/AuYsI [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "You'll Know AGI Is Here When Unemployment Rate Hits 25%",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rfnvky/youll_know_agi_is_here_when_unemployment_rate/",
      "url": "https://www.reddit.com/r/singularity/comments/1rfnvky/youll_know_agi_is_here_when_unemployment_rate/",
      "author": "/u/Neurogence",
      "created_utc": 1772143232,
      "selftext": "The current unemployment rate in the US is 4% and 6% in Europe. The debates about what constitutes AGI are largely a waste of time. People argue endlessly over definitions and benchmarks, when there exists a very clear metric available, the ultimate benchmark, and the only benchmark that cannot be hacked: Unemployment Rate. If the unemployment rate is rising sharply and we're not in the middle of a recession or depression, we'd know something unprecedented is happening. The problem with bench...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "New Upcoming Ubuntu 26.04 LTS Will be Optimized for Local AI",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rfmzfp/new_upcoming_ubuntu_2604_lts_will_be_optimized/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rfmzfp/new_upcoming_ubuntu_2604_lts_will_be_optimized/",
      "author": "/u/mtomas7",
      "created_utc": 1772141204,
      "selftext": "Some interesting new developments: Out-of-the-box NVIDIA CUDA and AMD ROCm drivers that are auto-selected for your particular hardware https://youtu.be/0CYm-KCw7yY&amp;t=316 Inference Snaps - ready-to-use sandboxed AI inference containers (reminds a bit the Mozilla llamafile project): Feature presentation: https://youtu.be/0CYm-KCw7yY&amp;t=412 Demo: https://youtu.be/0CYm-KCw7yY&amp;t=1183 Sandboxing AI Agents: https://youtu.be/0CYm-KCw7yY&amp;t=714 &#32; submitted by &#32; /u/mtomas7 [link] ...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "Why does ChatGPT think I am a 24-year old indian medical graduate",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rfm0yj/why_does_chatgpt_think_i_am_a_24year_old_indian/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rfm0yj/why_does_chatgpt_think_i_am_a_24year_old_indian/",
      "author": "/u/simplyhelpme2007",
      "created_utc": 1772139100,
      "selftext": "I was just messing with chatgpt to see what it would say by telling it some deep stuff, but then it told me I was a 24-year old medical graduate and started sending me indian helplines. Has anyone else had this or could they explain this. I was signed out and had just opened the website &#32; submitted by &#32; /u/simplyhelpme2007 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "[Epoch AI Data] The \"AI Oligopoly\" is a myth: Inference costs are dropping 40x/year and SOTA reaches your PC in ~8 months.",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rfl6w0/epoch_ai_data_the_ai_oligopoly_is_a_myth/",
      "url": "https://www.reddit.com/r/singularity/comments/1rfl6w0/epoch_ai_data_the_ai_oligopoly_is_a_myth/",
      "author": "/u/drhenriquesoares",
      "created_utc": 1772137221,
      "selftext": "TL;DR: If you think top-tier AI will be exclusive to trillion-dollar corporations forever, the data says otherwise. Epoch AI tracked hardware and inference costs: the performance that requires a supercomputer today will be running on your home hardware in less than a year. Open-source and local models are not losing the race. ‚ÄãEvery week we see posts here claiming the AI race is over and that companies like OpenAI, Google, and Anthropic will monopolize the future because compute is too expens...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Has anyone else lost motivation in systems or software engineering since passing Claude to your workflow?",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rfksj2/has_anyone_else_lost_motivation_in_systems_or/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rfksj2/has_anyone_else_lost_motivation_in_systems_or/",
      "author": "/u/m0rissett3",
      "created_utc": 1772136333,
      "selftext": "I miss the magic of bringing things to life. Now that takes me minutes not months. &#32; submitted by &#32; /u/m0rissett3 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "discussion",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "New: Auto-memory feature in Claude code, details below",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rfkmj1/new_automemory_feature_in_claude_code_details/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rfkmj1/new_automemory_feature_in_claude_code_details/",
      "author": "/u/BuildwithVignesh",
      "created_utc": 1772135975,
      "selftext": "Claude now remembers what it learns across sessions ‚Äî your project context, debugging patterns, preferred approaches ‚Äî and recalls it later without you having to write anything down. You can now think of Claude.MD as your instructions to Claude and Memory.MD as Claude's memory scratchpad it updates. If you ask Claude to remember something it will write it there. Read the docs here to learn more about memory and how it works: Docs Source: ClaudeAI &#32; submitted by &#32; /u/BuildwithVignesh [...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "Opus 4.6 defeats Grok 4.20 in Search for #1",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rfkgrn/opus_46_defeats_grok_420_in_search_for_1/",
      "url": "https://www.reddit.com/r/singularity/comments/1rfkgrn/opus_46_defeats_grok_420_in_search_for_1/",
      "author": "/u/exordin26",
      "created_utc": 1772135616,
      "selftext": "Anthropic now holds a trifecta on Arena, holding the #1 spot in Text, WebDev, and Search. Very short leas for xAi &#32; submitted by &#32; /u/exordin26 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "MachineLearning",
      "title": "[D] A notation for contextual inference in probabilistic models",
      "permalink": "https://www.reddit.com/r/MachineLearning/comments/1rfkdqt/d_a_notation_for_contextual_inference_in/",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1rfkdqt/d_a_notation_for_contextual_inference_in/",
      "author": "/u/Ok_Boysenberry_2947",
      "created_utc": 1772135426,
      "selftext": "Hello everyone, I am looking for critical feedback on an idea that could look somewhat redundant but has the potential to clarify how modelling context and observed data interact in probabilistic inference. In many scientific models, inference is formally expressed as conditioning on observed data, yet in practice the interpretation of observations also depends on contextual information such as modelling assumptions, calibration parameters, and prior knowledge. This paper introduces a simple ...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "academic",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "pplx-embed: State-of-the-Art Embedding Models for Web-Scale Retrieval",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rfkdjk/pplxembed_stateoftheart_embedding_models_for/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rfkdjk/pplxembed_stateoftheart_embedding_models_for/",
      "author": "/u/1-800-methdyke",
      "created_utc": 1772135414,
      "selftext": "Perplexity just dropped pplx-embed, a family of state-of-the-art text embedding models optimized for real-world, web-scale retrieval tasks‚Äîlike semantic search and RAG systems. Built on diffusion-pretrained Qwen3 backbones with multi-stage contrastive learning, they come in two flavors: pplx-embed-v1 for independent texts/queries (no instruction prefixes needed) and pplx-embed-context-v1 for context-aware document chunks, producing efficient int8-quantized embeddings best compared via cosine ...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "ChatGPT",
      "title": "agentic life",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rfjubw/agentic_life/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rfjubw/agentic_life/",
      "author": "/u/arunbhatia",
      "created_utc": 1772134222,
      "selftext": "&#32; submitted by &#32; /u/arunbhatia [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "singularity",
      "title": "AI agents can be hijacked by invisible characters hidden in normal text, and giving them tools makes it way worse",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rfjr3v/ai_agents_can_be_hijacked_by_invisible_characters/",
      "url": "https://www.reddit.com/r/singularity/comments/1rfjr3v/ai_agents_can_be_hijacked_by_invisible_characters/",
      "author": "/u/thecanonicalmg",
      "created_utc": 1772134023,
      "selftext": "We hid instructions inside normal-looking text using invisible Unicode characters. Humans can't see them at all, but AI models can read them. We tested 5 frontier models (GPT-5.2, GPT-4o-mini, Claude Opus 4, Sonnet 4, Haiku 4.5) across 8,308 outputs. The question: would the AI follow the invisible instructions instead of answering the visible question? The scary part: tool access is the critical enabler. Without code execution, models almost never follow hidden instructions ( Other findings: ...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Reverse CAPTCHA: We tested whether invisible Unicode characters can hijack LLM agents: 8,308 outputs across 5 models",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rfjkzu/reverse_captcha_we_tested_whether_invisible/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rfjkzu/reverse_captcha_we_tested_whether_invisible/",
      "author": "/u/thecanonicalmg",
      "created_utc": 1772133639,
      "selftext": "We tested whether LLMs follow instructions hidden in invisible Unicode characters embedded in normal-looking text. Two encoding schemes (zero-width binary and Unicode Tags), 5 models (GPT-5.2, GPT-4o-mini, Claude Opus 4, Sonnet 4, Haiku 4.5), 8,308 graded outputs. Key findings: Tool access is the primary amplifier. Without tools, compliance stays below 17%. With tools and decoding hints, it reaches 98-100%. Models write Python scripts to decode the hidden characters. Encoding vulnerability is...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "benchmark",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "LFM2-24B-A2B is crazy fast on Strix Halo",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rfid0q/lfm224ba2b_is_crazy_fast_on_strix_halo/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rfid0q/lfm224ba2b_is_crazy_fast_on_strix_halo/",
      "author": "/u/jfowers_amd",
      "created_utc": 1772130989,
      "selftext": "I've never seen a 24B model fly like this. It's almost 2x faster than gpt-oss-20b! Ran it with ROCm using Lemonade v9.4.0. Really hope to see some cool uses for this model! Anyone tried it out for their tasks yet? &#32; submitted by &#32; /u/jfowers_amd [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "Completed my 64GB VRAM rig - dual MI50 build + custom shroud",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rfi53f/completed_my_64gb_vram_rig_dual_mi50_build_custom/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rfi53f/completed_my_64gb_vram_rig_dual_mi50_build_custom/",
      "author": "/u/roackim",
      "created_utc": 1772130508,
      "selftext": "Hello everyone! A few months ago I started a project to build my own local AI server. After some testing and buying the second GPU, I was able to finalize the setup. Specs: Motherboard: Gigabyte X399 DESIGNARE CPU: Threadripper 2990WX (32 Cores / 64 Threads) RAM: 64GB DDR4 GPUs: 2x AMD Instinct MI50 32GB Costs: Motherboard + CPU + RAM + PSU: ~690‚Ç¨ GPUs: about 330‚Ç¨ each Case: ~150‚Ç¨ Total: ~1500‚Ç¨ Software: Ubuntu 24.04 LTS ROCm 6.3 llama.cpp It runs GLM 4.7 flash Q8_0 at ~50 t/s (but it drops d...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "news",
      "is_relevant": true
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "American closed models vs Chinese open models is becoming a problem.",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rfg3kx/american_closed_models_vs_chinese_open_models_is/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rfg3kx/american_closed_models_vs_chinese_open_models_is/",
      "author": "/u/__JockY__",
      "created_utc": 1772126148,
      "selftext": "The work I do involves customers that are sensitive to nation state politics. We cannot and do not use cloud API services for AI because the data must not leak. Ever. As a result we use open models in closed environments. The problem is that my customers don‚Äôt want Chinese models. ‚ÄúNational security risk‚Äù. But the only recent semi-capable model we have from the US is gpt-oss-120b, which is far behind modern LLMs like GLM, MiniMax, etc. So we are in a bind: use an older, less capable model and...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "benchmark",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "How many people are using Linux?",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rfg2dz/how_many_people_are_using_linux/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rfg2dz/how_many_people_are_using_linux/",
      "author": "/u/fyzbo",
      "created_utc": 1772126078,
      "selftext": "There is not official Claude Desktop for Linux. The typical excuse is market share, but I'm betting it's much higher given Claude Code is a CLI coding tool. So who here is using Linux? &#32; submitted by &#32; /u/fyzbo [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "discussion",
      "is_relevant": true
    },
    {
      "subreddit": "ClaudeAI",
      "title": "I vibe hacked a Lovable-showcased app using claude. 18,000+ users exposed. Lovable closed my support ticket.",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rffmk3/i_vibe_hacked_a_lovableshowcased_app_using_claude/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rffmk3/i_vibe_hacked_a_lovableshowcased_app_using_claude/",
      "author": "/u/VolodsTaimi",
      "created_utc": 1772125151,
      "selftext": "Lovable is a $6.6B vibe coding platform. They showcase apps on their site as success stories. I tested one ‚Äî an EdTech app with 100K+ views on their showcase, real users from UC Berkeley, UC Davis, and schools across Europe, Africa, and Asia. Found 16 security vulnerabilities in a few hours. 6 critical. The auth logic was literally backwards ‚Äî it blocked logged-in users and let anonymous ones through. Classic AI-generated code that \"works\" but was never reviewed. What was exposed: 18,697 user...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": true
    }
  ],
  "other_posts": [
    {
      "subreddit": "LocalLLaMA",
      "title": "Is microsoft going to train LLM on this? Github is clearly getting destroyed.",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rfxi64/is_microsoft_going_to_train_llm_on_this_github_is/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rfxi64/is_microsoft_going_to_train_llm_on_this_github_is/",
      "author": "/u/FPham",
      "created_utc": 1772168462,
      "selftext": "Everyday 1000s of crappy nonfunctioning wild-imagination vibecoded junk is being posted with thousands of robo-generated stars and hundreds of forks. If Microsoft is planning to use that for future LLMs code training we are in a big shock! Feedback loop is a bitch. &#32; submitted by &#32; /u/FPham [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "discussion",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "guys...",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rfxfrd/guys/",
      "url": "https://www.reddit.com/r/singularity/comments/1rfxfrd/guys/",
      "author": "/u/Funkahontas",
      "created_utc": 1772168266,
      "selftext": "&#32; submitted by &#32; /u/Funkahontas [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "LocalLLaMA",
      "title": "GPU starved too?",
      "permalink": "https://www.reddit.com/r/LocalLLaMA/comments/1rfx25b/gpu_starved_too/",
      "url": "https://www.reddit.com/r/LocalLLaMA/comments/1rfx25b/gpu_starved_too/",
      "author": "/u/alrojo",
      "created_utc": 1772167103,
      "selftext": "Been having issues getting GPUs lately. Today it was completely unavailable on runpod. &#32; submitted by &#32; /u/alrojo [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "local-models",
      "post_category": "discussion",
      "is_relevant": false
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Usage somehow resetted",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rfw6t0/usage_somehow_resetted/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rfw6t0/usage_somehow_resetted/",
      "author": "/u/DeltaLaboratory",
      "created_utc": 1772164497,
      "selftext": "I don't know what exactly happened, but is this happen randomly? &#32; submitted by &#32; /u/DeltaLaboratory [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ClaudeAI",
      "title": "usage reset?",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rfw4dp/usage_reset/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rfw4dp/usage_reset/",
      "author": "/u/chrrisk",
      "created_utc": 1772164296,
      "selftext": "my usage just reset to 0% 0% for both of my accounts (and my friend too) but neither of them were restarting today. Why? &#32; submitted by &#32; /u/chrrisk [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "discussion",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "Large-scale online deanonymization with LLMs",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rfvxsy/largescale_online_deanonymization_with_llms/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rfvxsy/largescale_online_deanonymization_with_llms/",
      "author": "/u/Zenmodenabled",
      "created_utc": 1772163774,
      "selftext": "https://arxiv.org/html/2602.16800v1 ‚ÄúOur second dataset matches users across Reddit movie discussion communities; and the third splits a single user‚Äôs Reddit history in time to create two pseudonymous profiles to be matched. In each setting, LLM-based methods substantially outperform classical baselines, achieving up to 68% recall at 90% precision compared to near 0% for the best non-LLM method. Our results show that the practical obscurity protecting pseudonymous users online no longer holds...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "\"Nano Banana 2, create a comic of today's most interesting news story\"",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rfuybe/nano_banana_2_create_a_comic_of_todays_most/",
      "url": "https://www.reddit.com/r/singularity/comments/1rfuybe/nano_banana_2_create_a_comic_of_todays_most/",
      "author": "/u/Cagnazzo82",
      "created_utc": 1772161034,
      "selftext": "Accessing real-time data &#32; submitted by &#32; /u/Cagnazzo82 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "MachineLearning",
      "title": "[D] Waiting for PhD thesis examination results is affecting my mental health",
      "permalink": "https://www.reddit.com/r/MachineLearning/comments/1rfua88/d_waiting_for_phd_thesis_examination_results_is/",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1rfua88/d_waiting_for_phd_thesis_examination_results_is/",
      "author": "/u/EducationalTwo7262",
      "created_utc": 1772159217,
      "selftext": "Hi everyone, I honestly feel like my mental health is not in a good place right now, and I just want to share this to see if anyone else has gone through something similar. If you‚Äôve noticed, I‚Äôve been posting quite a lot recently about my PhD thesis situation. I submitted my thesis a little over two months ago. Since that day, I‚Äôve been in a constant state of anxiety waiting for the result. Every morning, the very first thing I do after waking up is log into the university system to check wh...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "academic",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "It‚Äôs starting",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rftspf/its_starting/",
      "url": "https://www.reddit.com/r/singularity/comments/1rftspf/its_starting/",
      "author": "/u/Vegetable_Ad_192",
      "created_utc": 1772157887,
      "selftext": "Almoat half the staff gone, in an instant‚Ä¶ &#32; submitted by &#32; /u/Vegetable_Ad_192 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Well‚Ä¶ guess I‚Äôm not getting it today",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rftrih/well_guess_im_not_getting_it_today/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rftrih/well_guess_im_not_getting_it_today/",
      "author": "/u/XenuIsWatching",
      "created_utc": 1772157798,
      "selftext": "&#32; submitted by &#32; /u/XenuIsWatching [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "Large Language Model",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rfsnr8/large_language_model/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rfsnr8/large_language_model/",
      "author": "/u/Ok_Relationship_1703",
      "created_utc": 1772154837,
      "selftext": "&#32; submitted by &#32; /u/Ok_Relationship_1703 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "The fact that humans can't read wingdings as easily as Calibri is proof that humans are not AGI",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rfsltc/the_fact_that_humans_cant_read_wingdings_as/",
      "url": "https://www.reddit.com/r/singularity/comments/1rfsltc/the_fact_that_humans_cant_read_wingdings_as/",
      "author": "/u/CallMePyro",
      "created_utc": 1772154691,
      "selftext": "If humans were AGI, they could simply map each wingdings symbol to the same underlying representation stored in their neurons. And yet you give a human a math test where all you do is change the font and their score drops to 0%! Talk about over fitting. Are all humans benchmaxxed on Times New Roman? &#32; submitted by &#32; /u/CallMePyro [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "MachineLearning",
      "title": "[D] ASURA: Recursive LMs done right",
      "permalink": "https://www.reddit.com/r/MachineLearning/comments/1rfskth/d_asura_recursive_lms_done_right/",
      "url": "https://www.reddit.com/r/MachineLearning/comments/1rfskth/d_asura_recursive_lms_done_right/",
      "author": "/u/Competitive-Rub-1958",
      "created_utc": 1772154616,
      "selftext": "Recursive models like TRM/CTM/UT have create a lot of buzz lately. But they're rarely used outside of static, toy domains - especially language. In 2018, we saw \"Universal Transformers\" try this. However, follow-up works reveal that simple RLMs (recursive LMs) don't yield substantial performance gains w.r.t FLOPs spent In this work, I argue that using some rather simple tricks, one can unlock huge performance gains and make RLMs outperform iso-param and iso-FLOP baselines Blogpost/Worklog: ht...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "academic",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ChatGPT",
      "title": "You're not crazy. You're not broken.",
      "permalink": "https://www.reddit.com/r/ChatGPT/comments/1rfsgbg/youre_not_crazy_youre_not_broken/",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1rfsgbg/youre_not_crazy_youre_not_broken/",
      "author": "/u/oldenough2hobetter",
      "created_utc": 1772154286,
      "selftext": "I trauma dump mundane daily life traumas to my chat. Why is it always responding \"You're not crazy. You're not behind. You're not broken.\" Well...I didn't think I was before, and now you're putting these ideas in my head! When I used to work with it on writing content for my brand (which is not unhinged, but it is visually creative), it would always use words like \"unhinged\" \"unwell\" and of course FERAL. Chat is such a judgy Victorian child gremlin ghost. &#32; submitted by &#32; /u/oldenough...",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "chatgpt",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "It's happening",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rfr5o4/its_happening/",
      "url": "https://www.reddit.com/r/singularity/comments/1rfr5o4/its_happening/",
      "author": "/u/Outside-Iron-8242",
      "created_utc": 1772150978,
      "selftext": "&#32; submitted by &#32; /u/Outside-Iron-8242 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "singularity",
      "title": "How are the old r/singularity posters doing?",
      "permalink": "https://www.reddit.com/r/singularity/comments/1rfr0q2/how_are_the_old_rsingularity_posters_doing/",
      "url": "https://www.reddit.com/r/singularity/comments/1rfr0q2/how_are_the_old_rsingularity_posters_doing/",
      "author": "/u/4e_65_6f",
      "created_utc": 1772150633,
      "selftext": "I remember posting here seven years ago. All of the \"crazy\" things discussed back then are now mainstream. I just came back to ask how is everybody doing? Do you still feel like you're yelling at the clouds? Are you (like me) bored of the AI topic now while everyone else can't get enough of it while they catch up? &#32; submitted by &#32; /u/4e_65_6f [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "general",
      "post_category": "discussion",
      "is_relevant": false
    },
    {
      "subreddit": "ClaudeAI",
      "title": "My experience using Haiku vs Sonnet vs Opus models",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rfqsjn/my_experience_using_haiku_vs_sonnet_vs_opus_models/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rfqsjn/my_experience_using_haiku_vs_sonnet_vs_opus_models/",
      "author": "/u/ryry1237",
      "created_utc": 1772150089,
      "selftext": "&#32; submitted by &#32; /u/ryry1237 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "benchmark",
      "is_relevant": false
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Dario after not not folding to the Pentagon's pressure",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rfq8pw/dario_after_not_not_folding_to_the_pentagons/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rfq8pw/dario_after_not_not_folding_to_the_pentagons/",
      "author": "/u/MrAgent_FT7",
      "created_utc": 1772148734,
      "selftext": "Statement from Dario Amodei on our discussions with the Department of War &#32; submitted by &#32; /u/MrAgent_FT7 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Statement from Dario Amodei on our discussions with the Department of War",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rfq7ij/statement_from_dario_amodei_on_our_discussions/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rfq7ij/statement_from_dario_amodei_on_our_discussions/",
      "author": "/u/Odd_Anything_8652",
      "created_utc": 1772148648,
      "selftext": "&#32; submitted by &#32; /u/Odd_Anything_8652 [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": false
    },
    {
      "subreddit": "ClaudeAI",
      "title": "Statement from Dario Amodei on our discussions with the Department of War",
      "permalink": "https://www.reddit.com/r/ClaudeAI/comments/1rfp7u4/statement_from_dario_amodei_on_our_discussions/",
      "url": "https://www.reddit.com/r/ClaudeAI/comments/1rfp7u4/statement_from_dario_amodei_on_our_discussions/",
      "author": "/u/SteinOS",
      "created_utc": 1772146313,
      "selftext": "TL;DR no mass surveillance and autonomous weapons. &#32; submitted by &#32; /u/SteinOS [link] &#32; [comments]",
      "score": null,
      "num_comments": null,
      "is_self": true,
      "flair": null,
      "source_category": "claude",
      "post_category": "news",
      "is_relevant": false
    }
  ]
}