{
  "scraped_at": "2026-02-28T05:12:34.539Z",
  "categories_searched": [
    "cs.AI",
    "cs.CL",
    "cs.LG"
  ],
  "stats": {
    "total_fetched": 200,
    "relevant_count": 50,
    "recent_count": 20,
    "by_category": {
      "agents": 22,
      "benchmarks": 16,
      "code-generation": 9,
      "reasoning": 3
    }
  },
  "relevant_papers": [
    {
      "id": "2602.22683v1",
      "title": "SUPERGLASSES: Benchmarking Vision Language Models as Intelligent Agents for AI Smart Glasses",
      "summary": "The rapid advancement of AI-powered smart glasses, one of the hottest wearable devices, has unlocked new frontiers for multimodal interaction, with Visual Question Answering (VQA) over external knowledge sources emerging as a core application. Existing Vision Language Models (VLMs) adapted to smart glasses are typically trained and evaluated on traditional multimodal datasets; however, these datasets lack the variety and realism needed to reflect smart glasses usage scenarios and diverge from their specific challenges, where accurately identifying the object of interest must precede any external knowledge retrieval. To bridge this gap, we introduce SUPERGLASSES, the first comprehensive VQA benchmark built on real-world data entirely collected by smart glasses devices. SUPERGLASSES comprise",
      "authors": [
        "Zhuohang Jiang",
        "Xu Yuan",
        "Haohao Qu",
        "Shanru Lin",
        "Kanglong Liu",
        "Wenqi Fan",
        "Qing Li"
      ],
      "published": "2026-02-26T06:55:48Z",
      "updated": "2026-02-26T06:55:48Z",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22683v1",
      "abs_url": "https://arxiv.org/abs/2602.22683v1",
      "relevance_score": 16,
      "matched_keywords": [
        "language model",
        "gpt",
        "agent",
        "benchmark",
        "reasoning",
        "reasoning",
        "multimodal",
        "vision language"
      ],
      "category": "agents"
    },
    {
      "id": "2602.22828v1",
      "title": "TCM-DiffRAG: Personalized Syndrome Differentiation Reasoning Method for Traditional Chinese Medicine based on Knowledge Graph and Chain of Thought",
      "summary": "Background: Retrieval augmented generation (RAG) technology can empower large language models (LLMs) to generate more accurate, professional, and timely responses without fine tuning. However, due to the complex reasoning processes and substantial individual differences involved in traditional Chinese medicine (TCM) clinical diagnosis and treatment, traditional RAG methods often exhibit poor performance in this domain. Objective: To address the limitations of conventional RAG approaches in TCM applications, this study aims to develop an improved RAG framework tailored to the characteristics of TCM reasoning. Methods: We developed TCM-DiffRAG, an innovative RAG framework that integrates knowledge graphs (KG) with chains of thought (CoT). TCM-DiffRAG was evaluated on three distinctive TCM te",
      "authors": [
        "Jianmin Li",
        "Ying Chang",
        "Su-Kit Tang",
        "Yujia Liu",
        "Yanwen Wang",
        "Shuyuan Lin",
        "Binkai Ou"
      ],
      "published": "2026-02-26T10:11:15Z",
      "updated": "2026-02-26T10:11:15Z",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22828v1",
      "abs_url": "https://arxiv.org/abs/2602.22828v1",
      "relevance_score": 15,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "benchmark",
        "reasoning",
        "chain of thought",
        "cot",
        "reasoning",
        "retrieval augmented",
        "rag",
        "alignment"
      ],
      "category": "benchmarks"
    },
    {
      "id": "2602.23276v1",
      "title": "CXReasonAgent: Evidence-Grounded Diagnostic Reasoning Agent for Chest X-rays",
      "summary": "Chest X-ray plays a central role in thoracic diagnosis, and its interpretation inherently requires multi-step, evidence-grounded reasoning. However, large vision-language models (LVLMs) often generate plausible responses that are not faithfully grounded in diagnostic evidence and provide limited visual evidence for verification, while also requiring costly retraining to support new diagnostic tasks, limiting their reliability and adaptability in clinical settings. To address these limitations, we present CXReasonAgent, a diagnostic agent that integrates a large language model (LLM) with clinically grounded diagnostic tools to perform evidence-grounded diagnostic reasoning using image-derived diagnostic and visual evidence. To evaluate these capabilities, we introduce CXReasonDial, a multi-",
      "authors": [
        "Hyungyung Lee",
        "Hangyul Yoon",
        "Edward Choi"
      ],
      "published": "2026-02-26T17:51:21Z",
      "updated": "2026-02-26T17:51:21Z",
      "categories": [
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23276v1",
      "abs_url": "https://arxiv.org/abs/2602.23276v1",
      "relevance_score": 14,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "agent",
        "benchmark",
        "reasoning",
        "reasoning",
        "safety"
      ],
      "category": "agents"
    },
    {
      "id": "2602.23193v1",
      "title": "ESAA: Event Sourcing for Autonomous Agents in LLM-Based Software Engineering",
      "summary": "Autonomous agents based on Large Language Models (LLMs) have evolved from reactive assistants to systems capable of planning, executing actions via tools, and iterating over environment observations. However, they remain vulnerable to structural limitations: lack of native state, context degradation over long horizons, and the gap between probabilistic generation and deterministic execution requirements. This paper presents the ESAA (Event Sourcing for Autonomous Agents) architecture, which separates the agent's cognitive intention from the project's state mutation, inspired by the Event Sourcing pattern. In ESAA, agents emit only structured intentions in validated JSON (agent.result or issue.report); a deterministic orchestrator validates, persists events in an append-only log (activity.j",
      "authors": [
        "Elzo Brito dos Santos Filho"
      ],
      "published": "2026-02-26T16:45:59Z",
      "updated": "2026-02-26T16:45:59Z",
      "categories": [
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23193v1",
      "abs_url": "https://arxiv.org/abs/2602.23193v1",
      "relevance_score": 14,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "gpt",
        "claude",
        "gemini",
        "agent",
        "prompt"
      ],
      "category": "agents"
    },
    {
      "id": "2602.22963v1",
      "title": "FactGuard: Agentic Video Misinformation Detection via Reinforcement Learning",
      "summary": "Multimodal large language models (MLLMs) have substantially advanced video misinformation detection through unified multimodal reasoning, but they often rely on fixed-depth inference and place excessive trust in internally generated assumptions, particularly in scenarios where critical evidence is sparse, fragmented, or requires external verification. To address these limitations, we propose FactGuard, an agentic framework for video misinformation detection that formulates verification as an iterative reasoning process built upon MLLMs. FactGuard explicitly assesses task ambiguity and selectively invokes external tools to acquire critical evidence, enabling progressive refinement of reasoning trajectories. To further strengthen this capability, we introduce a two-stage training strategy th",
      "authors": [
        "Zehao Li",
        "Hongwei Yu",
        "Hao Jiang",
        "Qiang Sheng",
        "Yilong Xu",
        "Baolong Bi",
        "Yang Li",
        "Zhenlong Yuan",
        "Yujun Cai",
        "Zhaoqi Wang"
      ],
      "published": "2026-02-26T13:00:31Z",
      "updated": "2026-02-26T13:00:31Z",
      "categories": [
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22963v1",
      "abs_url": "https://arxiv.org/abs/2602.22963v1",
      "relevance_score": 14,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "agent",
        "agentic",
        "fine-tuning",
        "reasoning",
        "reasoning",
        "rag",
        "multimodal"
      ],
      "category": "agents"
    },
    {
      "id": "2602.22675v1",
      "title": "Search More, Think Less: Rethinking Long-Horizon Agentic Search for Efficiency and Generalization",
      "summary": "Recent deep research agents primarily improve performance by scaling reasoning depth, but this leads to high inference cost and latency in search-intensive scenarios. Moreover, generalization across heterogeneous research settings remains challenging. In this work, we propose \\emph{Search More, Think Less} (SMTL), a framework for long-horizon agentic search that targets both efficiency and generalization. SMTL replaces sequential reasoning with parallel evidence acquisition, enabling efficient context management under constrained context budgets. To support generalization across task types, we further introduce a unified data synthesis pipeline that constructs search tasks spanning both deterministic question answering and open-ended research scenarios with task appropriate evaluation metr",
      "authors": [
        "Qianben Chen",
        "Tianrui Qin",
        "King Zhu",
        "Qiexiang Wang",
        "Chengjun Yu",
        "Shu Xu",
        "Jiaqi Wu",
        "Jiayu Zhang",
        "Xinpeng Liu",
        "Xin Gui",
        "Jingyi Cao",
        "Piaohong Wang",
        "Dingfeng Shi",
        "He Zhu",
        "Tiannan Wang",
        "Yuqing Wang",
        "Maojia Song",
        "Tianyu Zheng",
        "Ge Zhang",
        "Jian Yang",
        "Jiaheng Liu",
        "Minghao Liu",
        "Yuchen Eleanor Jiang",
        "Wangchunshu Zhou"
      ],
      "published": "2026-02-26T06:46:41Z",
      "updated": "2026-02-26T06:46:41Z",
      "categories": [
        "cs.CL"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22675v1",
      "abs_url": "https://arxiv.org/abs/2602.22675v1",
      "relevance_score": 14,
      "matched_keywords": [
        "agent",
        "agentic",
        "fine-tuning",
        "benchmark",
        "evaluation",
        "reasoning",
        "reasoning",
        "rag"
      ],
      "category": "agents"
    },
    {
      "id": "2602.22955v1",
      "title": "MM-NeuroOnco: A Multimodal Benchmark and Instruction Dataset for MRI-Based Brain Tumor Diagnosis",
      "summary": "Accurate brain tumor diagnosis requires models to not only detect lesions but also generate clinically interpretable reasoning grounded in imaging manifestations, yet existing public datasets remain limited in annotation richness and diagnostic semantics. To bridge this gap, we introduce MM-NeuroOnco, a large-scale multimodal benchmark and instruction-tuning dataset for brain tumor MRI understanding, consisting of 24,726 MRI slices from 20 data sources paired with approximately 200,000 semantically enriched multimodal instructions spanning diverse tumor subtypes and imaging modalities. To mitigate the scarcity and high cost of diagnostic semantic annotations, we develop a multi-model collaborative pipeline for automated medical information completion and quality control, enabling the gener",
      "authors": [
        "Feng Guo",
        "Jiaxiang Liu",
        "Yang Li",
        "Qianqian Shi",
        "Mingkun Xu"
      ],
      "published": "2026-02-26T12:50:32Z",
      "updated": "2026-02-26T12:50:32Z",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22955v1",
      "abs_url": "https://arxiv.org/abs/2602.22955v1",
      "relevance_score": 13,
      "matched_keywords": [
        "gpt",
        "gemini",
        "fine-tuning",
        "benchmark",
        "evaluation",
        "reasoning",
        "reasoning",
        "rag",
        "multimodal"
      ],
      "category": "code-generation"
    },
    {
      "id": "2602.22953v1",
      "title": "General Agent Evaluation",
      "summary": "The promise of general-purpose agents - systems that perform tasks in unfamiliar environments without domain-specific engineering - remains largely unrealized. Existing agents are predominantly specialized, and while emerging implementations like OpenAI SDK Agent and Claude Code hint at broader capabilities, no systematic evaluation of their general performance has been pursued. Current agentic benchmarks assume domain-specific integration, encoding task information in ways that preclude fair evaluation of general agents. This paper frames general-agent evaluation as a first-class research objective. We propose conceptual principles for such evaluation, a Unified Protocol enabling agent-benchmark integration, and Exgentic - a practical framework for general agent evaluation. We benchmark f",
      "authors": [
        "Elron Bandel",
        "Asaf Yehudai",
        "Lilach Eden",
        "Yehoshua Sagron",
        "Yotam Perlitz",
        "Elad Venezian",
        "Natalia Razinkov",
        "Natan Ergas",
        "Shlomit Shachor Ifergan",
        "Segev Shlomov",
        "Michal Jacovi",
        "Leshem Choshen",
        "Liat Ein-Dor",
        "Yoav Katz",
        "Michal Shmueli-Scheuer"
      ],
      "published": "2026-02-26T12:48:02Z",
      "updated": "2026-02-26T12:48:02Z",
      "categories": [
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22953v1",
      "abs_url": "https://arxiv.org/abs/2602.22953v1",
      "relevance_score": 13,
      "matched_keywords": [
        "claude",
        "agent",
        "agentic",
        "benchmark",
        "evaluation"
      ],
      "category": "agents"
    },
    {
      "id": "2602.22871v1",
      "title": "Test-Time Scaling with Diffusion Language Models via Reward-Guided Stitching",
      "summary": "Reasoning with large language models often benefits from generating multiple chains-of-thought, but existing aggregation strategies are typically trajectory-level (e.g., selecting the best trace or voting on the final answer), discarding useful intermediate work from partial or \"nearly correct\" attempts. We propose Stitching Noisy Diffusion Thoughts, a self-consistency framework that turns cheap diffusion-sampled reasoning into a reusable pool of step-level candidates. Given a problem, we (i) sample many diverse, low-cost reasoning trajectories using a masked diffusion language model, (ii) score every intermediate step with an off-the-shelf process reward model (PRM), and (iii) stitch these highest-quality steps across trajectories into a composite rationale. This rationale then conditions",
      "authors": [
        "Roy Miles",
        "Aysim Toker",
        "Andreea-Maria Oncescu",
        "Songcen Xu",
        "Jiankang Deng",
        "Ismail Elezi"
      ],
      "published": "2026-02-26T11:08:39Z",
      "updated": "2026-02-26T11:08:39Z",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22871v1",
      "abs_url": "https://arxiv.org/abs/2602.22871v1",
      "relevance_score": 13,
      "matched_keywords": [
        "large language model",
        "language model",
        "benchmark",
        "evaluation",
        "reasoning",
        "reasoning",
        "rag"
      ],
      "category": "code-generation"
    },
    {
      "id": "2602.22808v1",
      "title": "MiroFlow: Towards High-Performance and Robust Open-Source Agent Framework for General Deep Research Tasks",
      "summary": "Despite the remarkable progress of large language models (LLMs), the capabilities of standalone LLMs have begun to plateau when tackling real-world, complex tasks that require interaction with external tools and dynamic environments. Although recent agent frameworks aim to enhance model autonomy through tool integration and external interaction, they still suffer from naive workflows, unstable performance, limited support across diverse benchmarks and tasks, and heavy reliance on costly commercial APIs. In this work, we propose a high-performance and robust open-source agent framework, termed MiroFlow, which incorporates an agent graph for flexible orchestration, an optional deep reasoning mode to enhance performance, and a robust workflow execution to ensure stable and reproducible perfor",
      "authors": [
        "Shiqian Su",
        "Sen Xing",
        "Xuan Dong",
        "Muyan Zhong",
        "Bin Wang",
        "Xizhou Zhu",
        "Yuntao Chen",
        "Wenhai Wang",
        "Yue Deng",
        "Pengxiang Zhu",
        "Ziyuan Liu",
        "Tiantong Li",
        "Jiaheng Yu",
        "Zhe Chen",
        "Lidong Bing",
        "Jifeng Dai"
      ],
      "published": "2026-02-26T09:45:04Z",
      "updated": "2026-02-26T09:45:04Z",
      "categories": [
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22808v1",
      "abs_url": "https://arxiv.org/abs/2602.22808v1",
      "relevance_score": 13,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "agent",
        "benchmark",
        "reasoning",
        "reasoning"
      ],
      "category": "agents"
    },
    {
      "id": "2602.22638v1",
      "title": "MobilityBench: A Benchmark for Evaluating Route-Planning Agents in Real-World Mobility Scenarios",
      "summary": "Route-planning agents powered by large language models (LLMs) have emerged as a promising paradigm for supporting everyday human mobility through natural language interaction and tool-mediated decision making. However, systematic evaluation in real-world mobility settings is hindered by diverse routing demands, non-deterministic mapping services, and limited reproducibility. In this study, we introduce MobilityBench, a scalable benchmark for evaluating LLM-based route-planning agents in real-world mobility scenarios. MobilityBench is constructed from large-scale, anonymized real user queries collected from Amap and covers a broad spectrum of route-planning intents across multiple cities worldwide. To enable reproducible, end-to-end evaluation, we design a deterministic API-replay sandbox t",
      "authors": [
        "Zhiheng Song",
        "Jingshuai Zhang",
        "Chuan Qin",
        "Chao Wang",
        "Chao Chen",
        "Longfei Xu",
        "Kaikui Liu",
        "Xiangxiang Chu",
        "Hengshu Zhu"
      ],
      "published": "2026-02-26T05:39:38Z",
      "updated": "2026-02-26T05:39:38Z",
      "categories": [
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22638v1",
      "abs_url": "https://arxiv.org/abs/2602.22638v1",
      "relevance_score": 13,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "agent",
        "tool use",
        "benchmark",
        "evaluation"
      ],
      "category": "agents"
    },
    {
      "id": "2602.23258v1",
      "title": "AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning",
      "summary": "While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability and adaptability. We propose AgentDropoutV2, a test-time rectify-or-reject pruning framework designed to dynamically optimize MAS information flow without retraining. Our approach acts as an active firewall, intercepting agent outputs and employing a retrieval-augmented rectifier to iteratively correct errors based on a failure-driven indicator pool. This mechanism allows for the precise identification of potential errors using distilled failure patterns as prior knowledge. Irreparable outputs are subsequently prune",
      "authors": [
        "Yutong Wang",
        "Siyuan Xiong",
        "Xuebo Liu",
        "Wenkang Zhou",
        "Liang Ding",
        "Miao Zhang",
        "Min Zhang"
      ],
      "published": "2026-02-26T17:31:43Z",
      "updated": "2026-02-26T17:31:43Z",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23258v1",
      "abs_url": "https://arxiv.org/abs/2602.23258v1",
      "relevance_score": 12,
      "matched_keywords": [
        "agent",
        "fine-tuning",
        "benchmark",
        "reasoning",
        "reasoning",
        "rag"
      ],
      "category": "agents"
    },
    {
      "id": "2602.23225v1",
      "title": "Why Diffusion Language Models Struggle with Truly Parallel (Non-Autoregressive) Decoding?",
      "summary": "Diffusion Language Models (DLMs) are often advertised as enabling parallel token generation, yet practical fast DLMs frequently converge to left-to-right, autoregressive (AR)-like decoding dynamics. In contrast, genuinely non-AR generation is promising because it removes AR's sequential bottleneck, better exploiting parallel hardware to reduce synchronization/communication overhead and improve latency scaling with output length. We argue that a primary driver of AR-like decoding is a mismatch between DLM objectives and the highly sequential structure of widely used training data, including standard pretraining corpora and long chain-of-thought (CoT) supervision. Motivated by this diagnosis, we propose NAP (Non-Autoregressive Parallel DLMs), a proof-of-concept, data-centric approach that be",
      "authors": [
        "Pengxiang Li",
        "Dilxat Muhtar",
        "Lu Yin",
        "Tianlong Chen",
        "Shiwei Liu"
      ],
      "published": "2026-02-26T17:04:57Z",
      "updated": "2026-02-26T17:04:57Z",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23225v1",
      "abs_url": "https://arxiv.org/abs/2602.23225v1",
      "relevance_score": 12,
      "matched_keywords": [
        "language model",
        "benchmark",
        "reasoning",
        "cot",
        "reasoning",
        "rag"
      ],
      "category": "code-generation"
    },
    {
      "id": "2602.23199v1",
      "title": "SC-Arena: A Natural Language Benchmark for Single-Cell Reasoning with Knowledge-Augmented Evaluation",
      "summary": "Large language models (LLMs) are increasingly applied in scientific research, offering new capabilities for knowledge discovery and reasoning. In single-cell biology, however, evaluation practices for both general and specialized LLMs remain inadequate: existing benchmarks are fragmented across tasks, adopt formats such as multiple-choice classification that diverge from real-world usage, and rely on metrics lacking interpretability and biological grounding. We present SC-ARENA, a natural language evaluation framework tailored to single-cell foundation models. SC-ARENA formalizes a virtual cell abstraction that unifies evaluation targets by representing both intrinsic attributes and gene-level interactions. Within this paradigm, we define five natural language tasks (cell type annotation, ",
      "authors": [
        "Jiahao Zhao",
        "Feng Jiang",
        "Shaowei Qin",
        "Zhonghui Zhang",
        "Junhao Liu",
        "Guibing Guo",
        "Hamid Alinejad-Rokny",
        "Min Yang"
      ],
      "published": "2026-02-26T16:50:28Z",
      "updated": "2026-02-26T16:50:28Z",
      "categories": [
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23199v1",
      "abs_url": "https://arxiv.org/abs/2602.23199v1",
      "relevance_score": 12,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "benchmark",
        "evaluation",
        "reasoning",
        "reasoning",
        "rag"
      ],
      "category": "benchmarks"
    },
    {
      "id": "2602.23079v1",
      "title": "Assessing Deanonymization Risks with Stylometry-Assisted LLM Agent",
      "summary": "The rapid advancement of large language models (LLMs) has enabled powerful authorship inference capabilities, raising growing concerns about unintended deanonymization risks in textual data such as news articles. In this work, we introduce an LLM agent designed to evaluate and mitigate such risks through a structured, interpretable pipeline. Central to our framework is the proposed $\\textit{SALA}$ (Stylometry-Assisted LLM Analysis) method, which integrates quantitative stylometric features with LLM reasoning for robust and transparent authorship attribution. Experiments on large-scale news datasets demonstrate that $\\textit{SALA}$, particularly when augmented with a database module, achieves high inference accuracy in various scenarios. Finally, we propose a guided recomposition strategy t",
      "authors": [
        "Boyang Zhang",
        "Yang Zhang"
      ],
      "published": "2026-02-26T15:05:13Z",
      "updated": "2026-02-26T15:05:13Z",
      "categories": [
        "cs.CL",
        "cs.CR",
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23079v1",
      "abs_url": "https://arxiv.org/abs/2602.23079v1",
      "relevance_score": 12,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "agent",
        "prompt",
        "reasoning",
        "reasoning",
        "rag"
      ],
      "category": "agents"
    },
    {
      "id": "2602.22897v1",
      "title": "OmniGAIA: Towards Native Omni-Modal AI Agents",
      "summary": "Human intelligence naturally intertwines omni-modal perception -- spanning vision, audio, and language -- with complex reasoning and tool usage to interact with the world. However, current multi-modal LLMs are primarily confined to bi-modal interactions (e.g., vision-language), lacking the unified cognitive capabilities required for general AI assistants. To bridge this gap, we introduce OmniGAIA, a comprehensive benchmark designed to evaluate omni-modal agents on tasks necessitating deep reasoning and multi-turn tool execution across video, audio, and image modalities. Constructed via a novel omni-modal event graph approach, OmniGAIA synthesizes complex, multi-hop queries derived from real-world data that require cross-modal reasoning and external tool integration. Furthermore, we propose",
      "authors": [
        "Xiaoxi Li",
        "Wenxiang Jiao",
        "Jiarui Jin",
        "Shijian Wang",
        "Guanting Dong",
        "Jiajie Jin",
        "Hao Wang",
        "Yinuo Wang",
        "Ji-Rong Wen",
        "Yuan Lu",
        "Zhicheng Dou"
      ],
      "published": "2026-02-26T11:35:04Z",
      "updated": "2026-02-26T11:35:04Z",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22897v1",
      "abs_url": "https://arxiv.org/abs/2602.22897v1",
      "relevance_score": 12,
      "matched_keywords": [
        "llm",
        "agent",
        "dpo",
        "benchmark",
        "reasoning",
        "reasoning"
      ],
      "category": "agents"
    },
    {
      "id": "2602.22865v1",
      "title": "Effective QA-driven Annotation of Predicate-Argument Relations Across Languages",
      "summary": "Explicit representations of predicate-argument relations form the basis of interpretable semantic analysis, supporting reasoning, generation, and evaluation. However, attaining such semantic structures requires costly annotation efforts and has remained largely confined to English. We leverage the Question-Answer driven Semantic Role Labeling (QA-SRL) framework -- a natural-language formulation of predicate-argument relations -- as the foundation for extending semantic annotation to new languages. To this end, we introduce a cross-linguistic projection approach that reuses an English QA-SRL parser within a constrained translation and word-alignment pipeline to automatically generate question-answer annotations aligned with target-language predicates. Applied to Hebrew, Russian, and French ",
      "authors": [
        "Jonathan Davidov",
        "Aviv Slobodkin",
        "Shmuel Tomi Klein",
        "Reut Tsarfaty",
        "Ido Dagan",
        "Ayal Klein"
      ],
      "published": "2026-02-26T11:01:38Z",
      "updated": "2026-02-26T11:01:38Z",
      "categories": [
        "cs.CL"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22865v1",
      "abs_url": "https://arxiv.org/abs/2602.22865v1",
      "relevance_score": 12,
      "matched_keywords": [
        "llm",
        "gpt",
        "llama",
        "evaluation",
        "reasoning",
        "reasoning",
        "rag",
        "alignment"
      ],
      "category": "benchmarks"
    },
    {
      "id": "2602.22831v1",
      "title": "Moral Preferences of LLMs Under Directed Contextual Influence",
      "summary": "Moral benchmarks for LLMs typically use context-free prompts, implicitly assuming stable preferences. In deployment, however, prompts routinely include contextual signals such as user requests, cues on social norms, etc. that may steer decisions. We study how directed contextual influences reshape decisions in trolley-problem-style moral triage settings. We introduce a pilot evaluation harness for directed contextual influence in trolley-problem-style moral triage: for each demographic factor, we apply matched, direction-flipped contextual influences that differ only in which group they favor, enabling systematic measurement of directional response. We find that: (i) contextual influences often significantly shift decisions, even when only superficially relevant; (ii) baseline preferences ",
      "authors": [
        "Phil Blandfort",
        "Tushar Karayil",
        "Urja Pawar",
        "Robert Graham",
        "Alex McKenzie",
        "Dmitrii Krasheninnikov"
      ],
      "published": "2026-02-26T10:17:57Z",
      "updated": "2026-02-26T10:17:57Z",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.CY"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22831v1",
      "abs_url": "https://arxiv.org/abs/2602.22831v1",
      "relevance_score": 12,
      "matched_keywords": [
        "llm",
        "prompt",
        "few-shot",
        "benchmark",
        "evaluation",
        "reasoning",
        "reasoning",
        "rag"
      ],
      "category": "benchmarks"
    },
    {
      "id": "2602.22769v1",
      "title": "AMA-Bench: Evaluating Long-Horizon Memory for Agentic Applications",
      "summary": "Large Language Models (LLMs) are deployed as autonomous agents in increasingly complex applications, where enabling long-horizon memory is critical for achieving strong performance. However, a significant gap exists between practical applications and current evaluation standards for agent memory: existing benchmarks primarily focus on dialogue-centric, human-agent interactions. In reality, agent memory consists of a continuous stream of agent-environment interactions that are primarily composed of machine-generated representations. To bridge this gap, we introduce AMA-Bench (Agent Memory with Any length), which evaluates long-horizon memory for LLMs in real agentic applications. It features two key components: (1) a set of real-world agentic trajectories across representative agentic appli",
      "authors": [
        "Yujie Zhao",
        "Boqin Yuan",
        "Junbo Huang",
        "Haocheng Yuan",
        "Zhongming Yu",
        "Haozhou Xu",
        "Lanxiang Hu",
        "Abhilash Shankarampeta",
        "Zimeng Huang",
        "Wentao Ni",
        "Yuandong Tian",
        "Jishen Zhao"
      ],
      "published": "2026-02-26T08:59:31Z",
      "updated": "2026-02-26T08:59:31Z",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22769v1",
      "abs_url": "https://arxiv.org/abs/2602.22769v1",
      "relevance_score": 12,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "agent",
        "agentic",
        "benchmark",
        "evaluation",
        "rag"
      ],
      "category": "agents"
    },
    {
      "id": "2602.23239v1",
      "title": "Agency and Architectural Limits: Why Optimization-Based Systems Cannot Be Norm-Responsive",
      "summary": "AI systems are increasingly deployed in high-stakes contexts -- medical diagnosis, legal research, financial analysis -- under the assumption they can be governed by norms. This paper demonstrates that assumption is formally invalid for optimization-based systems, specifically Large Language Models trained via Reinforcement Learning from Human Feedback (RLHF). We establish that genuine agency requires two necessary and jointly sufficient architectural conditions: the capacity to maintain certain boundaries as non-negotiable constraints rather than tradeable weights (Incommensurability), and a non-inferential mechanism capable of suspending processing when those boundaries are threatened (Apophatic Responsiveness). These conditions apply across all normative domains. RLHF-based systems are ",
      "authors": [
        "Radha Sarma"
      ],
      "published": "2026-02-26T17:16:17Z",
      "updated": "2026-02-26T17:16:17Z",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23239v1",
      "abs_url": "https://arxiv.org/abs/2602.23239v1",
      "relevance_score": 11,
      "matched_keywords": [
        "large language model",
        "language model",
        "agent",
        "rlhf",
        "reasoning",
        "reasoning",
        "hallucination"
      ],
      "category": "agents"
    },
    {
      "id": "2602.23235v1",
      "title": "Spatio-Temporal Token Pruning for Efficient High-Resolution GUI Agents",
      "summary": "Pure-vision GUI agents provide universal interaction capabilities but suffer from severe efficiency bottlenecks due to the massive spatiotemporal redundancy inherent in high-resolution screenshots and historical trajectories. We identify two critical misalignments in existing compression paradigms: the temporal mismatch, where uniform history encoding diverges from the agent's \"fading memory\" attention pattern, and the spatial topology conflict, where unstructured pruning compromises the grid integrity required for precise coordinate grounding, inducing spatial hallucinations. To address these challenges, we introduce GUIPruner, a training-free framework tailored for high-resolution GUI navigation. It synergizes Temporal-Adaptive Resolution (TAR), which eliminates historical redundancy via",
      "authors": [
        "Zhou Xu",
        "Bowen Zhou",
        "Qi Wang",
        "Shuwen Feng",
        "Jingyu Xiao"
      ],
      "published": "2026-02-26T17:12:40Z",
      "updated": "2026-02-26T17:12:40Z",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23235v1",
      "abs_url": "https://arxiv.org/abs/2602.23235v1",
      "relevance_score": 11,
      "matched_keywords": [
        "agent",
        "benchmark",
        "evaluation",
        "alignment",
        "hallucination"
      ],
      "category": "agents"
    },
    {
      "id": "2602.22971v1",
      "title": "SPM-Bench: Benchmarking Large Language Models for Scanning Probe Microscopy",
      "summary": "As LLMs achieved breakthroughs in general reasoning, their proficiency in specialized scientific domains reveals pronounced gaps in existing benchmarks due to data contamination, insufficient complexity, and prohibitive human labor costs. Here we present SPM-Bench, an original, PhD-level multimodal benchmark specifically designed for scanning probe microscopy (SPM). We propose a fully automated data synthesis pipeline that ensures both high authority and low-cost. By employing Anchor-Gated Sieve (AGS) technology, we efficiently extract high-value image-text pairs from arXiv and journal papers published between 2023 and 2025. Through a hybrid cloud-local architecture where VLMs return only spatial coordinates \"llbox\" for local high-fidelity cropping, our pipeline achieves extreme token savi",
      "authors": [
        "Peiyao Xiao",
        "Xiaogang Li",
        "Chengliang Xu",
        "Jiayi Wang",
        "Ben Wang",
        "Zichao Chen",
        "Zeyu Wang",
        "Kejun Yu",
        "Yueqian Chen",
        "Xulin Liu",
        "Wende Xiao",
        "Bing Zhao",
        "Hu Wei"
      ],
      "published": "2026-02-26T13:08:56Z",
      "updated": "2026-02-26T13:08:56Z",
      "categories": [
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22971v1",
      "abs_url": "https://arxiv.org/abs/2602.22971v1",
      "relevance_score": 11,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "benchmark",
        "reasoning",
        "reasoning",
        "multimodal"
      ],
      "category": "benchmarks"
    },
    {
      "id": "2602.22755v1",
      "title": "AuditBench: Evaluating Alignment Auditing Techniques on Models with Hidden Behaviors",
      "summary": "We introduce AuditBench, an alignment auditing benchmark. AuditBench consists of 56 language models with implanted hidden behaviors. Each model has one of 14 concerning behaviors--such as sycophantic deference, opposition to AI regulation, or secret geopolitical loyalties--which it does not confess to when directly asked. AuditBench models are highly diverse--some are subtle, while others are overt, and we use varying training techniques both for implanting behaviors and training models not to confess. To demonstrate AuditBench's utility, we develop an investigator agent that autonomously employs a configurable set of auditing tools. By measuring investigator agent success using different tools, we can evaluate their efficacy. Notably, we observe a tool-to-agent gap, where tools that perfo",
      "authors": [
        "Abhay Sheshadri",
        "Aidan Ewart",
        "Kai Fronsdal",
        "Isha Gupta",
        "Samuel R. Bowman",
        "Sara Price",
        "Samuel Marks",
        "Rowan Wang"
      ],
      "published": "2026-02-26T08:43:07Z",
      "updated": "2026-02-26T08:43:07Z",
      "categories": [
        "cs.CL"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22755v1",
      "abs_url": "https://arxiv.org/abs/2602.22755v1",
      "relevance_score": 11,
      "matched_keywords": [
        "language model",
        "agent",
        "agentic",
        "prompt",
        "benchmark",
        "evaluation",
        "alignment"
      ],
      "category": "agents"
    },
    {
      "id": "2602.22724v1",
      "title": "AgentSentry: Mitigating Indirect Prompt Injection in LLM Agents via Temporal Causal Diagnostics and Context Purification",
      "summary": "Large language model (LLM) agents increasingly rely on external tools and retrieval systems to autonomously complete complex tasks. However, this design exposes agents to indirect prompt injection (IPI), where attacker-controlled context embedded in tool outputs or retrieved content silently steers agent actions away from user intent. Unlike prompt-based attacks, IPI unfolds over multi-turn trajectories, making malicious control difficult to disentangle from legitimate task execution. Existing inference-time defenses primarily rely on heuristic detection and conservative blocking of high-risk actions, which can prematurely terminate workflows or broadly suppress tool usage under ambiguous multi-turn scenarios. We propose AgentSentry, a novel inference-time detection and mitigation framewor",
      "authors": [
        "Tian Zhang",
        "Yiwei Xu",
        "Juan Wang",
        "Keyan Guo",
        "Xiaoyang Xu",
        "Bowen Xiao",
        "Quanlong Guan",
        "Jinlin Fan",
        "Jiawei Liu",
        "Zhiquan Liu",
        "Hongxin Hu"
      ],
      "published": "2026-02-26T07:59:10Z",
      "updated": "2026-02-26T07:59:10Z",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22724v1",
      "abs_url": "https://arxiv.org/abs/2602.22724v1",
      "relevance_score": 11,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "agent",
        "prompt",
        "benchmark",
        "rag"
      ],
      "category": "agents"
    },
    {
      "id": "2602.22703v1",
      "title": "Enhancing Geometric Perception in VLMs via Translator-Guided Reinforcement Learning",
      "summary": "Vision-language models (VLMs) often struggle with geometric reasoning due to their limited perception of fundamental diagram elements. To tackle this challenge, we introduce GeoPerceive, a benchmark comprising diagram instances paired with domain-specific language (DSL) representations, along with an efficient automatic data generation pipeline. This design enables the isolated evaluation of geometric perception independently from reasoning. To exploit the data provided by GeoPerceive for enhancing the geometric perception capabilities of VLMs, we propose GeoDPO, a translator-guided reinforcement learning (RL) framework. GeoDPO employs an NL-to-DSL translator, which is trained on synthetic pairs generated by the data engine of GeoPerceive, to bridge natural language and DSL. This translato",
      "authors": [
        "Hao Yu",
        "Shuning Jia",
        "Guanghao Li",
        "Wenhao Jiang",
        "Chun Yuan"
      ],
      "published": "2026-02-26T07:28:04Z",
      "updated": "2026-02-26T07:28:04Z",
      "categories": [
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22703v1",
      "abs_url": "https://arxiv.org/abs/2602.22703v1",
      "relevance_score": 11,
      "matched_keywords": [
        "language model",
        "fine-tuning",
        "dpo",
        "benchmark",
        "evaluation",
        "reasoning",
        "reasoning"
      ],
      "category": "code-generation"
    },
    {
      "id": "2602.22698v1",
      "title": "Tokenization, Fusion and Decoupling: Bridging the Granularity Mismatch Between Large Language Models and Knowledge Graphs",
      "summary": "Leveraging Large Language Models (LLMs) for Knowledge Graph Completion (KGC) is promising but hindered by a fundamental granularity mismatch. LLMs operate on fragmented token sequences, whereas entities are the fundamental units in knowledge graphs (KGs) scenarios. Existing approaches typically constrain predictions to limited candidate sets or align entities with the LLM's vocabulary by pooling multiple tokens or decomposing entities into fixed-length token sequences, which fail to capture both the semantic meaning of the text and the structural integrity of the graph. To address this, we propose KGT, a novel framework that uses dedicated entity tokens to enable efficient, full-space prediction. Specifically, we first introduce specialized tokenization to construct feature representations",
      "authors": [
        "Siyue Su",
        "Jian Yang",
        "Bo Li",
        "Guanglin Niu"
      ],
      "published": "2026-02-26T07:20:40Z",
      "updated": "2026-02-26T07:20:40Z",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22698v1",
      "abs_url": "https://arxiv.org/abs/2602.22698v1",
      "relevance_score": 11,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "benchmark",
        "reasoning",
        "reasoning",
        "rag"
      ],
      "category": "benchmarks"
    },
    {
      "id": "2602.22680v1",
      "title": "Toward Personalized LLM-Powered Agents: Foundations, Evaluation, and Future Directions",
      "summary": "Large language models have enabled agents that reason, plan, and interact with tools and environments to accomplish complex tasks. As these agents operate over extended interaction horizons, their effectiveness increasingly depends on adapting behavior to individual users and maintaining continuity across time, giving rise to personalized LLM-powered agents. In such long-term, user-dependent settings, personalization permeates the entire decision pipeline rather than remaining confined to surface-level generation. This survey provides a capability-oriented review of personalized LLM-powered agents. We organize the literature around four interdependent components: profile modeling, memory, planning, and action execution. Using this taxonomy, we synthesize representative methods and analyze ",
      "authors": [
        "Yue Xu",
        "Qian Chen",
        "Zizhan Ma",
        "Dongrui Liu",
        "Wenxuan Wang",
        "Xiting Wang",
        "Li Xiong",
        "Wenjie Wang"
      ],
      "published": "2026-02-26T06:52:47Z",
      "updated": "2026-02-26T06:52:47Z",
      "categories": [
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22680v1",
      "abs_url": "https://arxiv.org/abs/2602.22680v1",
      "relevance_score": 11,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "agent",
        "agentic",
        "benchmark",
        "evaluation"
      ],
      "category": "agents"
    },
    {
      "id": "2602.22642v1",
      "title": "Compress the Easy, Explore the Hard: Difficulty-Aware Entropy Regularization for Efficient LLM Reasoning",
      "summary": "Chain-of-Thought (CoT) has substantially empowered Large Language Models (LLMs) to tackle complex reasoning tasks, yet the verbose nature of explicit reasoning steps incurs prohibitive inference latency and computational costs, limiting real-world deployment. While existing compression methods - ranging from self-training to Reinforcement Learning (RL) with length constraints - attempt to mitigate this, they often sacrifice reasoning capability for brevity. We identify a critical failure mode in these approaches: explicitly optimizing for shorter trajectories triggers rapid entropy collapse, which prematurely shrinks the exploration space and stifles the discovery of valid reasoning paths, particularly for challenging questions requiring extensive deduction. To address this issue, we propo",
      "authors": [
        "Qin-Wen Luo",
        "Sheng Ren",
        "Xiang Chen",
        "Rui Liu",
        "Jun Fang",
        "Naiqiang Tan",
        "Sheng-Jun Huang"
      ],
      "published": "2026-02-26T05:47:30Z",
      "updated": "2026-02-26T05:47:30Z",
      "categories": [
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22642v1",
      "abs_url": "https://arxiv.org/abs/2602.22642v1",
      "relevance_score": 11,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "benchmark",
        "reasoning",
        "cot",
        "reasoning"
      ],
      "category": "benchmarks"
    },
    {
      "id": "2602.23320v1",
      "title": "ParamMem: Augmenting Language Agents with Parametric Reflective Memory",
      "summary": "Self-reflection enables language agents to iteratively refine solutions, yet often produces repetitive outputs that limit reasoning performance. Recent studies have attempted to address this limitation through various approaches, among which increasing reflective diversity has shown promise. Our empirical analysis reveals a strong positive correlation between reflective diversity and task success, further motivating the need for diverse reflection signals. We introduce ParamMem, a parametric memory module that encodes cross-sample reflection patterns into model parameters, enabling diverse reflection generation through temperature-controlled sampling. Building on this module, we propose ParamAgent, a reflection-based agent framework that integrates parametric memory with episodic and cross",
      "authors": [
        "Tianjun Yao",
        "Yongqiang Chen",
        "Yujia Zheng",
        "Pan Li",
        "Zhiqiang Shen",
        "Kun Zhang"
      ],
      "published": "2026-02-26T18:28:04Z",
      "updated": "2026-02-26T18:28:04Z",
      "categories": [
        "cs.LG",
        "cs.MA"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23320v1",
      "abs_url": "https://arxiv.org/abs/2602.23320v1",
      "relevance_score": 10,
      "matched_keywords": [
        "agent",
        "code generation",
        "reasoning",
        "reasoning"
      ],
      "category": "agents"
    },
    {
      "id": "2602.23163v1",
      "title": "A Decision-Theoretic Formalisation of Steganography With Applications to LLM Monitoring",
      "summary": "Large language models are beginning to show steganographic capabilities. Such capabilities could allow misaligned models to evade oversight mechanisms. Yet principled methods to detect and quantify such behaviours are lacking. Classical definitions of steganography, and detection methods based on them, require a known reference distribution of non-steganographic signals. For the case of steganographic reasoning in LLMs, knowing such a reference distribution is not feasible; this renders these approaches inapplicable. We propose an alternative, \\textbf{decision-theoretic view of steganography}. Our central insight is that steganography creates an asymmetry in usable information between agents who can and cannot decode the hidden content (present within a steganographic signal), and this oth",
      "authors": [
        "Usman Anwar",
        "Julianna Piskorz",
        "David D. Baek",
        "David Africa",
        "Jim Weatherall",
        "Max Tegmark",
        "Christian Schroeder de Witt",
        "Mihaela van der Schaar",
        "David Krueger"
      ],
      "published": "2026-02-26T16:27:24Z",
      "updated": "2026-02-26T16:27:24Z",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.IT",
        "cs.MA"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23163v1",
      "abs_url": "https://arxiv.org/abs/2602.23163v1",
      "relevance_score": 10,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "agent",
        "reasoning",
        "reasoning"
      ],
      "category": "agents"
    },
    {
      "id": "2602.23075v1",
      "title": "CiteLLM: An Agentic Platform for Trustworthy Scientific Reference Discovery",
      "summary": "Large language models (LLMs) have created new opportunities to enhance the efficiency of scholarly activities; however, challenges persist in the ethical deployment of AI assistance, including (1) the trustworthiness of AI-generated content, (2) preservation of academic integrity and intellectual property, and (3) protection of information privacy. In this work, we present CiteLLM, a specialized agentic platform designed to enable trustworthy reference discovery for grounding author-drafted claims and statements. The system introduces a novel interaction paradigm by embedding LLM utilities directly within the LaTeX editor environment, ensuring a seamless user experience and no data transmission outside the local system. To guarantee hallucination-free references, we employ dynamic discipli",
      "authors": [
        "Mengze Hong",
        "Di Jiang",
        "Chen Jason Zhang",
        "Zichang Guo",
        "Yawen Li",
        "Jun Chen",
        "Shaobo Cui",
        "Zhiyang Su"
      ],
      "published": "2026-02-26T15:02:22Z",
      "updated": "2026-02-26T15:02:22Z",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23075v1",
      "abs_url": "https://arxiv.org/abs/2602.23075v1",
      "relevance_score": 10,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "agent",
        "agentic",
        "evaluation",
        "rag",
        "hallucination"
      ],
      "category": "agents"
    },
    {
      "id": "2602.22787v1",
      "title": "Probing for Knowledge Attribution in Large Language Models",
      "summary": "Large language models (LLMs) often generate fluent but unfounded claims, or hallucinations, which fall into two types: (i) faithfulness violations - misusing user context - and (ii) factuality violations - errors from internal knowledge. Proper mitigation depends on knowing whether a model's answer is based on the prompt or its internal weights. This work focuses on the problem of contributive attribution: identifying the dominant knowledge source behind each output. We show that a probe, a simple linear classifier trained on model hidden representations, can reliably predict contributive attribution. For its training, we introduce AttriWiki, a self-supervised data pipeline that prompts models to recall withheld entities from memory or read them from context, generating labelled examples a",
      "authors": [
        "Ivo Brink",
        "Alexander Boer",
        "Dennis Ulmer"
      ],
      "published": "2026-02-26T09:21:12Z",
      "updated": "2026-02-26T09:21:12Z",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22787v1",
      "abs_url": "https://arxiv.org/abs/2602.22787v1",
      "relevance_score": 10,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "llama",
        "mistral",
        "prompt",
        "benchmark",
        "hallucination"
      ],
      "category": "benchmarks"
    },
    {
      "id": "2602.22766v1",
      "title": "Imagination Helps Visual Reasoning, But Not Yet in Latent Space",
      "summary": "Latent visual reasoning aims to mimic human's imagination process by meditating through hidden states of Multimodal Large Language Models. While recognized as a promising paradigm for visual reasoning, the underlying mechanisms driving its effectiveness remain unclear. Motivated to demystify the true source of its efficacy, we investigate the validity of latent reasoning using Causal Mediation Analysis. We model the process as a causal chain: the input as the treatment, the latent tokens as the mediator, and the final answer as the outcome. Our findings uncover two critical disconnections: (a) Input-Latent Disconnect: dramatic perturbations on the input result in negligible changes to the latent tokens, suggesting that latent tokens do not effectively attend to the input sequence. (b) Late",
      "authors": [
        "You Li",
        "Chi Chen",
        "Yanghao Li",
        "Fanhu Zeng",
        "Kaiyu Huang",
        "Jinan Xu",
        "Maosong Sun"
      ],
      "published": "2026-02-26T08:56:23Z",
      "updated": "2026-02-26T08:56:23Z",
      "categories": [
        "cs.CL"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22766v1",
      "abs_url": "https://arxiv.org/abs/2602.22766v1",
      "relevance_score": 10,
      "matched_keywords": [
        "large language model",
        "language model",
        "benchmark",
        "reasoning",
        "reasoning",
        "multimodal"
      ],
      "category": "code-generation"
    },
    {
      "id": "2602.22697v1",
      "title": "Reinforcing Real-world Service Agents: Balancing Utility and Cost in Task-oriented Dialogue",
      "summary": "The rapid evolution of Large Language Models (LLMs) has accelerated the transition from conversational chatbots to general agents. However, effectively balancing empathetic communication with budget-aware decision-making remains an open challenge. Since existing methods fail to capture these complex strategic trade-offs, we propose InteractCS-RL, a framework that reframes task-oriented dialogue as a multi-granularity reinforcement learning process. Specifically, we first establish a User-centric Interaction Framework to provide a high-fidelity training gym, enabling agents to dynamically explore diverse strategies with persona-driven users. Then, we introduce Cost-aware Multi-turn Policy Optimization (CMPO) with a hybrid advantage estimation strategy. By integrating generative process cred",
      "authors": [
        "Ning Gao",
        "Wei Zhang",
        "Yuqin Dai",
        "Ling Shi",
        "Ziyin Wang",
        "Yujie Wang",
        "Wei He",
        "Jinpeng Wang",
        "Chaozheng Wang"
      ],
      "published": "2026-02-26T07:19:57Z",
      "updated": "2026-02-26T07:19:57Z",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22697v1",
      "abs_url": "https://arxiv.org/abs/2602.22697v1",
      "relevance_score": 10,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "agent",
        "benchmark",
        "evaluation"
      ],
      "category": "agents"
    },
    {
      "id": "2602.23351v1",
      "title": "Scale Can't Overcome Pragmatics: The Impact of Reporting Bias on Vision-Language Reasoning",
      "summary": "The lack of reasoning capabilities in Vision-Language Models (VLMs) has remained at the forefront of research discourse. We posit that this behavior stems from a reporting bias in their training data. That is, how people communicate about visual content by default omits tacit information needed to supervise some types of reasoning; e.g., \"at the game today!\" is a more likely caption than \"a photo of 37 people standing behind a field\". We investigate the data underlying the popular VLMs OpenCLIP, LLaVA-1.5 and Molmo through the lens of theories from pragmatics, and find that reporting bias results in insufficient representation of four reasoning skills (spatial, temporal, negation, and counting), despite the corpora being of web-scale, and/or synthetically generated. With a set of curated b",
      "authors": [
        "Amita Kamath",
        "Jack Hessel",
        "Khyathi Chandu",
        "Jena D. Hwang",
        "Kai-Wei Chang",
        "Ranjay Krishna"
      ],
      "published": "2026-02-26T18:54:06Z",
      "updated": "2026-02-26T18:54:06Z",
      "categories": [
        "cs.CL",
        "cs.CV"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23351v1",
      "abs_url": "https://arxiv.org/abs/2602.23351v1",
      "relevance_score": 9,
      "matched_keywords": [
        "language model",
        "benchmark",
        "reasoning",
        "reasoning",
        "rag"
      ],
      "category": "benchmarks"
    },
    {
      "id": "2602.23300v1",
      "title": "A Mixture-of-Experts Model for Multimodal Emotion Recognition in Conversations",
      "summary": "Emotion Recognition in Conversations (ERC) presents unique challenges, requiring models to capture the temporal flow of multi-turn dialogues and to effectively integrate cues from multiple modalities. We propose Mixture of Speech-Text Experts for Recognition of Emotions (MiSTER-E), a modular Mixture-of-Experts (MoE) framework designed to decouple two core challenges in ERC: modality-specific context modeling and multimodal information fusion. MiSTER-E leverages large language models (LLMs) fine-tuned for both speech and text to provide rich utterance-level embeddings, which are then enhanced through a convolutional-recurrent context modeling layer. The system integrates predictions from three experts-speech-only, text-only, and cross-modal-using a learned gating mechanism that dynamically ",
      "authors": [
        "Soumya Dutta",
        "Smruthi Balaji",
        "Sriram Ganapathy"
      ],
      "published": "2026-02-26T18:08:40Z",
      "updated": "2026-02-26T18:08:40Z",
      "categories": [
        "cs.CL",
        "eess.AS"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23300v1",
      "abs_url": "https://arxiv.org/abs/2602.23300v1",
      "relevance_score": 9,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "benchmark",
        "rag",
        "multimodal",
        "alignment"
      ],
      "category": "benchmarks"
    },
    {
      "id": "2602.23152v1",
      "title": "The Trinity of Consistency as a Defining Principle for General World Models",
      "summary": "The construction of World Models capable of learning, simulating, and reasoning about objective physical laws constitutes a foundational challenge in the pursuit of Artificial General Intelligence. Recent advancements represented by video generation models like Sora have demonstrated the potential of data-driven scaling laws to approximate physical dynamics, while the emerging Unified Multimodal Model (UMM) offers a promising architectural paradigm for integrating perception, language, and reasoning. Despite these advances, the field still lacks a principled theoretical framework that defines the essential properties requisite for a General World Model. In this paper, we propose that a World Model must be grounded in the Trinity of Consistency: Modal Consistency as the semantic interface, ",
      "authors": [
        "Jingxuan Wei",
        "Siyuan Li",
        "Yuhang Xu",
        "Zheng Sun",
        "Junjie Jiang",
        "Hexuan Jin",
        "Caijun Jia",
        "Honghao He",
        "Xinglong Xu",
        "Xi bai",
        "Chang Yu",
        "Yumou Liu",
        "Junnan Zhu",
        "Xuanhe Zhou",
        "Jintao Chen",
        "Xiaobin Hu",
        "Shancheng Pang",
        "Bihui Yu",
        "Ran He",
        "Zhen Lei",
        "Stan Z. Li",
        "Conghui He",
        "Shuicheng Yan",
        "Cheng Tan"
      ],
      "published": "2026-02-26T16:15:55Z",
      "updated": "2026-02-26T16:15:55Z",
      "categories": [
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23152v1",
      "abs_url": "https://arxiv.org/abs/2602.23152v1",
      "relevance_score": 9,
      "matched_keywords": [
        "benchmark",
        "evaluation",
        "reasoning",
        "reasoning",
        "multimodal"
      ],
      "category": "benchmarks"
    },
    {
      "id": "2602.22839v1",
      "title": "DeepPresenter: Environment-Grounded Reflection for Agentic Presentation Generation",
      "summary": "Presentation generation requires deep content research, coherent visual design, and iterative refinement based on observation. However, existing presentation agents often rely on predefined workflows and fixed templates. To address this, we present DeepPresenter, an agentic framework that adapts to diverse user intents, enables effective feedback-driven refinement, and generalizes beyond a scripted pipeline. Specifically, DeepPresenter autonomously plans, renders, and revises intermediate slide artifacts to support long-horizon refinement with environmental observations. Furthermore, rather than relying on self-reflection over internal signals (e.g., reasoning traces), our environment-grounded reflection conditions the generation process on perceptual artifact states (e.g., rendered slides",
      "authors": [
        "Hao Zheng",
        "Guozhao Mo",
        "Xinru Yan",
        "Qianhao Yuan",
        "Wenkai Zhang",
        "Xuanang Chen",
        "Yaojie Lu",
        "Hongyu Lin",
        "Xianpei Han",
        "Le Sun"
      ],
      "published": "2026-02-26T10:26:48Z",
      "updated": "2026-02-26T10:26:48Z",
      "categories": [
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22839v1",
      "abs_url": "https://arxiv.org/abs/2602.22839v1",
      "relevance_score": 9,
      "matched_keywords": [
        "agent",
        "agentic",
        "evaluation",
        "reasoning",
        "reasoning"
      ],
      "category": "agents"
    },
    {
      "id": "2602.22790v1",
      "title": "Natural Language Declarative Prompting (NLD-P): A Modular Governance Method for Prompt Design Under Model Drift",
      "summary": "The rapid evolution of large language models (LLMs) has transformed prompt engineering from a localized craft into a systems-level governance challenge. As models scale and update across generations, prompt behavior becomes sensitive to shifts in instruction-following policies, alignment regimes, and decoding strategies, a phenomenon we characterize as GPT-scale model drift. Under such conditions, surface-level formatting conventions and ad hoc refinement are insufficient to ensure stable, interpretable control. This paper reconceptualizes Natural Language Declarative Prompting (NLD-P) as a declarative governance method rather than a rigid field template. NLD-P is formalized as a modular control abstraction that separates provenance, constraint logic, task content, and post-generation eval",
      "authors": [
        "Hyunwoo Kim",
        "Hanau Yi",
        "Jaehee Bae",
        "Yumin Kim"
      ],
      "published": "2026-02-26T09:23:09Z",
      "updated": "2026-02-26T09:23:09Z",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22790v1",
      "abs_url": "https://arxiv.org/abs/2602.22790v1",
      "relevance_score": 9,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "gpt",
        "prompt",
        "evaluation",
        "alignment"
      ],
      "category": "code-generation"
    },
    {
      "id": "2602.22730v1",
      "title": "Extending Czech Aspect-Based Sentiment Analysis with Opinion Terms: Dataset and LLM Benchmarks",
      "summary": "This paper introduces a novel Czech dataset in the restaurant domain for aspect-based sentiment analysis (ABSA), enriched with annotations of opinion terms. The dataset supports three distinct ABSA tasks involving opinion terms, accommodating varying levels of complexity. Leveraging this dataset, we conduct extensive experiments using modern Transformer-based models, including large language models (LLMs), in monolingual, cross-lingual, and multilingual settings. To address cross-lingual challenges, we propose a translation and label alignment methodology leveraging LLMs, which yields consistent improvements. Our results highlight the strengths and limitations of state-of-the-art models, especially when handling the linguistic intricacies of low-resource languages like Czech. A detailed er",
      "authors": [
        "Jakub md",
        "Pavel Pib",
        "Pavel Krl"
      ],
      "published": "2026-02-26T08:13:42Z",
      "updated": "2026-02-26T08:13:42Z",
      "categories": [
        "cs.CL"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22730v1",
      "abs_url": "https://arxiv.org/abs/2602.22730v1",
      "relevance_score": 9,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "transformer",
        "benchmark",
        "rag",
        "alignment"
      ],
      "category": "benchmarks"
    },
    {
      "id": "2602.22716v1",
      "title": "SoPE: Spherical Coordinate-Based Positional Embedding for Enhancing Spatial Perception of 3D LVLMs",
      "summary": "3D Large Vision-Language Models (3D LVLMs) built upon Large Language Models (LLMs) have achieved remarkable progress across various multimodal tasks. However, their inherited position-dependent modeling mechanism, Rotary Position Embedding (RoPE), remains suboptimal for 3D multimodal understanding. The vanilla RoPE formulation fails to preserve essential three-dimensional spatial structures when encoding 3D tokens, and its relative distance computation overlooks angular dependencies, hindering the model's ability to capture directional variations in visual representations. To overcome these limitations, we introduce Spherical Coordinate-based Positional Embedding (SoPE). Our method maps point-cloud token indices into a 3D spherical coordinate space, enabling unified modeling of spatial loc",
      "authors": [
        "Guanting Ye",
        "Qiyan Zhao",
        "Wenhao Yu",
        "Liangyu Yuan",
        "Mingkai Li",
        "Xiaofeng Zhang",
        "Jianmin Ji",
        "Yanyong Zhang",
        "Qing Jiang",
        "Ka-Veng Yuen"
      ],
      "published": "2026-02-26T07:42:15Z",
      "updated": "2026-02-26T07:42:15Z",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22716v1",
      "abs_url": "https://arxiv.org/abs/2602.22716v1",
      "relevance_score": 9,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "benchmark",
        "multimodal"
      ],
      "category": "code-generation"
    },
    {
      "id": "2602.22624v1",
      "title": "Instruction-based Image Editing with Planning, Reasoning, and Generation",
      "summary": "Editing images via instruction provides a natural way to generate interactive content, but it is a big challenge due to the higher requirement of scene understanding and generation. Prior work utilizes a chain of large language models, object segmentation models, and editing models for this task. However, the understanding models provide only a single modality ability, restricting the editing quality. We aim to bridge understanding and generation via a new multi-modality model that provides the intelligent abilities to instruction-based image editing models for more complex cases. To achieve this goal, we individually separate the instruction editing task with the multi-modality chain of thought prompts, i.e., Chain-of-Thought (CoT) planning, editing region reasoning, and editing. For Chai",
      "authors": [
        "Liya Ji",
        "Chenyang Qi",
        "Qifeng Chen"
      ],
      "published": "2026-02-26T04:56:02Z",
      "updated": "2026-02-26T04:56:02Z",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22624v1",
      "abs_url": "https://arxiv.org/abs/2602.22624v1",
      "relevance_score": 9,
      "matched_keywords": [
        "large language model",
        "language model",
        "prompt",
        "reasoning",
        "chain of thought",
        "cot",
        "reasoning"
      ],
      "category": "reasoning"
    },
    {
      "id": "2602.23312v1",
      "title": "Evaluating Zero-Shot and One-Shot Adaptation of Small Language Models in Leader-Follower Interaction",
      "summary": "Leader-follower interaction is an important paradigm in human-robot interaction (HRI). Yet, assigning roles in real time remains challenging for resource-constrained mobile and assistive robots. While large language models (LLMs) have shown promise for natural communication, their size and latency limit on-device deployment. Small language models (SLMs) offer a potential alternative, but their effectiveness for role classification in HRI has not been systematically evaluated. In this paper, we present a benchmark of SLMs for leader-follower communication, introducing a novel dataset derived from a published database and augmented with synthetic samples to capture interaction-specific dynamics. We investigate two adaptation strategies: prompt engineering and fine-tuning, studied under zero-",
      "authors": [
        "Rafael R. Baptista",
        "Andr de Lima Salgado",
        "Ricardo V. Godoy",
        "Marcelo Becker",
        "Thiago Boaventura",
        "Gustavo J. G. Lahr"
      ],
      "published": "2026-02-26T18:20:26Z",
      "updated": "2026-02-26T18:20:26Z",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "eess.SY"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23312v1",
      "abs_url": "https://arxiv.org/abs/2602.23312v1",
      "relevance_score": 8,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "fine-tuning",
        "prompt",
        "benchmark"
      ],
      "category": "benchmarks"
    },
    {
      "id": "2602.23266v1",
      "title": "Discourse-Aware Dual-Track Streaming Response for Low-Latency Spoken Dialogue Systems",
      "summary": "Achieving human-like responsiveness is a critical yet challenging goal for cascaded spoken dialogue systems. Conventional ASR-LLM-TTS pipelines follow a strictly sequential paradigm, requiring complete transcription and full reasoning before speech synthesis can begin, which results in high response latency. We propose the Discourse-Aware Dual-Track Streaming Response (DDTSR) framework, a low-latency architecture that enables listen-while-thinking and speak-while-thinking. DDTSR is built upon three key mechanisms: (1) connective-guided small-large model synergy, where an auxiliary small model generates minimal-committal discourse connectives while a large model performs knowledge-intensive reasoning in parallel; (2) streaming-based cross-modal collaboration, which dynamically overlaps ASR,",
      "authors": [
        "Siyuan Liu",
        "Jiahui Xu",
        "Feng Jiang",
        "Kuang Wang",
        "Zefeng Zhao",
        "Chu-Ren Huang",
        "Jinghang Gu",
        "Changqing Yin",
        "Haizhou Li"
      ],
      "published": "2026-02-26T17:39:56Z",
      "updated": "2026-02-26T17:39:56Z",
      "categories": [
        "cs.CL"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23266v1",
      "abs_url": "https://arxiv.org/abs/2602.23266v1",
      "relevance_score": 8,
      "matched_keywords": [
        "llm",
        "benchmark",
        "reasoning",
        "reasoning"
      ],
      "category": "benchmarks"
    },
    {
      "id": "2602.23228v1",
      "title": "MovieTeller: Tool-augmented Movie Synopsis with ID Consistent Progressive Abstraction",
      "summary": "With the explosive growth of digital entertainment, automated video summarization has become indispensable for applications such as content indexing, personalized recommendation, and efficient media archiving. Automatic synopsis generation for long-form videos, such as movies and TV series, presents a significant challenge for existing Vision-Language Models (VLMs). While proficient at single-image captioning, these general-purpose models often exhibit critical failures in long-duration contexts, primarily a lack of ID-consistent character identification and a fractured narrative coherence. To overcome these limitations, we propose MovieTeller, a novel framework for generating movie synopses via tool-augmented progressive abstraction. Our core contribution is a training-free, tool-augmente",
      "authors": [
        "Yizhi Li",
        "Xiaohan Chen",
        "Miao Jiang",
        "Wentao Tang",
        "Gaoang Wang"
      ],
      "published": "2026-02-26T17:08:08Z",
      "updated": "2026-02-26T17:08:08Z",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23228v1",
      "abs_url": "https://arxiv.org/abs/2602.23228v1",
      "relevance_score": 8,
      "matched_keywords": [
        "language model",
        "fine-tuning",
        "prompt",
        "reasoning",
        "reasoning",
        "rag"
      ],
      "category": "reasoning"
    },
    {
      "id": "2602.23200v1",
      "title": "InnerQ: Hardware-aware Tuning-free Quantization of KV Cache for Large Language Models",
      "summary": "Reducing the hardware footprint of large language models (LLMs) during decoding is critical for efficient long-sequence generation. A key bottleneck is the key-value (KV) cache, whose size scales with sequence length and easily dominates the memory footprint of the model. Previous work proposed quantization methods that are focused on compressing the KV cache while maintaining its information. We introduce InnerQ, a hardware-aware KV-cache quantization scheme that lowers decode latency without sacrificing accuracy. InnerQ applies group-wise quantization while grouping the cache matrices over their inner dimension. Unlike previous work that group over the outer dimension, InnerQ aligns dequantization with the vector-matrix multiplication and enables scale factor reuse across GPU compute uni",
      "authors": [
        "Sayed Mohammadreza Tayaranian Hosseini",
        "Amir Ardakani",
        "Warren J. Gross"
      ],
      "published": "2026-02-26T16:50:36Z",
      "updated": "2026-02-26T16:50:36Z",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23200v1",
      "abs_url": "https://arxiv.org/abs/2602.23200v1",
      "relevance_score": 8,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "llama",
        "few-shot",
        "evaluation"
      ],
      "category": "code-generation"
    },
    {
      "id": "2602.23148v1",
      "title": "On Sample-Efficient Generalized Planning via Learned Transition Models",
      "summary": "Generalized planning studies the construction of solution strategies that generalize across families of planning problems sharing a common domain model, formally defined by a transition function $: S \\times A \\rightarrow S$. Classical approaches achieve such generalization through symbolic abstractions and explicit reasoning over $$. In contrast, recent Transformer-based planners, such as PlanGPT and Plansformer, largely cast generalized planning as direct action-sequence prediction, bypassing explicit transition modeling. While effective on in-distribution instances, these approaches typically require large datasets and model sizes, and often suffer from state drift in long-horizon settings due to the absence of explicit world-state evolution. In this work, we formulate generalized plan",
      "authors": [
        "Nitin Gupta",
        "Vishal Pallagani",
        "John A. Aydin",
        "Biplav Srivastava"
      ],
      "published": "2026-02-26T16:13:46Z",
      "updated": "2026-02-26T16:13:46Z",
      "categories": [
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23148v1",
      "abs_url": "https://arxiv.org/abs/2602.23148v1",
      "relevance_score": 8,
      "matched_keywords": [
        "gpt",
        "transformer",
        "reasoning",
        "reasoning"
      ],
      "category": "code-generation"
    },
    {
      "id": "2602.23092v1",
      "title": "Enhancing CVRP Solver through LLM-driven Automatic Heuristic Design",
      "summary": "The Capacitated Vehicle Routing Problem (CVRP), a fundamental combinatorial optimization challenge, focuses on optimizing fleet operations under vehicle capacity constraints. While extensively studied in operational research, the NP-hard nature of CVRP continues to pose significant computational challenges, particularly for large-scale instances. This study presents AILS-AHD (Adaptive Iterated Local Search with Automatic Heuristic Design), a novel approach that leverages Large Language Models (LLMs) to revolutionize CVRP solving. Our methodology integrates an evolutionary search framework with LLMs to dynamically generate and optimize ruin heuristics within the AILS method. Additionally, we introduce an LLM-based acceleration mechanism to enhance computational efficiency. Comprehensive exp",
      "authors": [
        "Zhuoliang Xie",
        "Fei Liu",
        "Zhenkun Wang",
        "Qingfu Zhang"
      ],
      "published": "2026-02-26T15:12:23Z",
      "updated": "2026-02-26T15:12:23Z",
      "categories": [
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23092v1",
      "abs_url": "https://arxiv.org/abs/2602.23092v1",
      "relevance_score": 8,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "benchmark",
        "evaluation",
        "rag"
      ],
      "category": "benchmarks"
    },
    {
      "id": "2602.22911v1",
      "title": "NoRA: Breaking the Linear Ceiling of Low-Rank Adaptation via Manifold Expansion",
      "summary": "Low-Rank Adaptation (LoRA) dominates parameter-efficient fine-tuning (PEFT). However, it faces a critical ``linear ceiling'' in complex reasoning tasks: simply increasing the rank yields diminishing returns due to intrinsic linear constraints. We introduce NoRA (Non-linear Rank Adaptation), a weight-level parallel adapter that injects SiLU gating and structural dropout to induce manifold expansion. On the SlimOrca benchmark, NoRA breaks this linear barrier: NoRA remarkably at rank 64 (PPL 3.89) outperforms LoRA at rank 512 (PPL 3.90), demonstrating superior spectral efficiency. This advantage generalizes to mathematical reasoning, where NoRA achieves a perplexity of 1.97 on MathInstruct, significantly surpassing LoRA's saturation point of 2.07. Mechanism analysis via Singular Value Decompo",
      "authors": [
        "Hung-Hsuan Chen"
      ],
      "published": "2026-02-26T11:55:25Z",
      "updated": "2026-02-26T11:55:25Z",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22911v1",
      "abs_url": "https://arxiv.org/abs/2602.22911v1",
      "relevance_score": 8,
      "matched_keywords": [
        "fine-tuning",
        "benchmark",
        "reasoning",
        "reasoning"
      ],
      "category": "benchmarks"
    },
    {
      "id": "2602.22718v1",
      "title": "RLHFless: Serverless Computing for Efficient RLHF",
      "summary": "Reinforcement Learning from Human Feedback (RLHF) has been widely applied to Large Language Model (LLM) post-training to align model outputs with human preferences. Recent models, such as DeepSeek-R1, have also shown RLHF's potential to improve LLM reasoning on complex tasks. In RL, inference and training co-exist, creating dynamic resource demands throughout the workflow. Compared to traditional RL, RLHF further challenges training efficiency due to expanding model sizes and resource consumption. Several RLHF frameworks aim to balance flexible abstraction and efficient execution. However, they rely on serverful infrastructures, which struggle with fine-grained resource variability. As a result, during synchronous RLHF training, idle time between or within RL components often causes overhe",
      "authors": [
        "Rui Wei",
        "Hanfei Yu",
        "Shubham Jain",
        "Yogarajan Sivakumar",
        "Devesh Tiwari",
        "Jian Li",
        "Seung-Jong Park",
        "Hao Wang"
      ],
      "published": "2026-02-26T07:45:37Z",
      "updated": "2026-02-26T07:45:37Z",
      "categories": [
        "cs.AI",
        "cs.DC"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22718v1",
      "abs_url": "https://arxiv.org/abs/2602.22718v1",
      "relevance_score": 8,
      "matched_keywords": [
        "large language model",
        "llm",
        "language model",
        "rlhf",
        "reasoning",
        "reasoning"
      ],
      "category": "reasoning"
    }
  ],
  "recent_papers": [
    {
      "id": "2602.23341v1",
      "title": "Mean Estimation from Coarse Data: Characterizations and Efficient Algorithms",
      "summary": "Coarse data arise when learners observe only partial information about samples; namely, a set containing the sample rather than its exact value. This occurs naturally through measurement rounding, sensor limitations, and lag in economic systems. We study Gaussian mean estimation from coarse data, where each true sample $x$ is drawn from a $d$-dimensional Gaussian distribution with identity covariance, but is revealed only through the set of a partition containing $x$. When the coarse samples, roughly speaking, have ``low'' information, the mean cannot be uniquely recovered from observed samples (i.e., the problem is not identifiable). Recent work by Fotakis, Kalavasis, Kontonis, and Tzamos [FKKT21] established that sample-efficient mean estimation is possible when the unknown mean is ident",
      "authors": [
        "Alkis Kalavasis",
        "Anay Mehrotra",
        "Manolis Zampetakis",
        "Felix Zhou",
        "Ziyu Zhu"
      ],
      "published": "2026-02-26T18:47:06Z",
      "updated": "2026-02-26T18:47:06Z",
      "categories": [
        "cs.LG",
        "cs.DS",
        "math.ST",
        "stat.ML"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23341v1",
      "abs_url": "https://arxiv.org/abs/2602.23341v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "general"
    },
    {
      "id": "2602.23334v1",
      "title": "Bitwise Systolic Array Architecture for Runtime-Reconfigurable Multi-precision Quantized Multiplication on Hardware Accelerators",
      "summary": "Neural network accelerators have been widely applied to edge devices for complex tasks like object tracking, image recognition, etc. Previous works have explored the quantization technologies in related lightweight accelerator designs to reduce hardware resource consumption. However, low precision leads to high accuracy loss in inference. Therefore, mixed-precision quantization becomes an alternative solution by applying different precision in different layers to trade off resource consumption and accuracy. Because regular designs for multiplication on hardware cannot support the precision reconfiguration for a multi-precision Quantized Neural Network (QNN) model in runtime, we propose a runtime reconfigurable multi-precision multi-channel bitwise systolic array design for QNN accelerators",
      "authors": [
        "Yuhao Liu",
        "Salim Ullah",
        "Akash Kumar"
      ],
      "published": "2026-02-26T18:40:02Z",
      "updated": "2026-02-26T18:40:02Z",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23334v1",
      "abs_url": "https://arxiv.org/abs/2602.23334v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "general"
    },
    {
      "id": "2602.23321v1",
      "title": "Deep ensemble graph neural networks for probabilistic cosmic-ray direction and energy reconstruction in autonomous radio arrays",
      "summary": "Using advanced machine learning techniques, we developed a method for reconstructing precisely the arrival direction and energy of ultra-high-energy cosmic rays from the voltage traces they induced on ground-based radio detector arrays. In our approach, triggered antennas are represented as a graph structure, which serves as input for a graph neural network (GNN). By incorporating physical knowledge into both the GNN architecture and the input data, we improve the precision and reduce the required size of the training set with respect to a fully data-driven approach. This method achieves an angular resolution of 0.092 and an electromagnetic energy reconstruction resolution of 16.4% on simulated data with realistic noise conditions. We also employ uncertainty estimation methods to enhance ",
      "authors": [
        "Arsne Ferrire",
        "Aurlien Benoit-Lvy",
        "Olivier Martineau-Huynh",
        "Matas Tueros"
      ],
      "published": "2026-02-26T18:29:48Z",
      "updated": "2026-02-26T18:29:48Z",
      "categories": [
        "astro-ph.IM",
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23321v1",
      "abs_url": "https://arxiv.org/abs/2602.23321v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "general"
    },
    {
      "id": "2602.23318v1",
      "title": "Generalized Rapid Action Value Estimation in Memory-Constrained Environments",
      "summary": "Generalized Rapid Action Value Estimation (GRAVE) has been shown to be a strong variant within the Monte-Carlo Tree Search (MCTS) family of algorithms for General Game Playing (GGP). However, its reliance on storing additional win/visit statistics at each node makes its use impractical in memory-constrained environments, thereby limiting its applicability in practice. In this paper, we introduce the GRAVE2, GRAVER and GRAVER2 algorithms, which extend GRAVE through two-level search, node recycling, and a combination of both techniques, respectively. We show that these enhancements enable a drastic reduction in the number of stored nodes while matching the playing strength of GRAVE.",
      "authors": [
        "Alos Rautureau",
        "Tristan Cazenave",
        "ric Piette"
      ],
      "published": "2026-02-26T18:25:59Z",
      "updated": "2026-02-26T18:25:59Z",
      "categories": [
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23318v1",
      "abs_url": "https://arxiv.org/abs/2602.23318v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "general"
    },
    {
      "id": "2602.23303v1",
      "title": "Inferential Mechanics Part 1: Causal Mechanistic Theories of Machine Learning in Chemical Biology with Implications",
      "summary": "Machine learning techniques are now routinely encountered in research laboratories across the globe. Impressive progress has been made through ML and AI techniques with regards to large data set processing. This progress has increased the ability of the experimenter to digest data and make novel predictions regarding phenomena of interest. However, machine learning predictors generated from data sets taken from the natural sciences are often treated as black boxes which are used broadly and generally without detailed consideration of the causal structure of the data set of interest. Work has been attempted to bring causality into discussions of machine learning models of natural phenomena; however, a firm and unified theoretical treatment is lacking. This series of three papers explores th",
      "authors": [
        "Ilya Balabin",
        "Thomas M. Kaiser"
      ],
      "published": "2026-02-26T18:09:16Z",
      "updated": "2026-02-26T18:09:16Z",
      "categories": [
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23303v1",
      "abs_url": "https://arxiv.org/abs/2602.23303v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "general"
    },
    {
      "id": "2602.23302v1",
      "title": "The logic of KM belief update is contained in the logic of AGM belief revision",
      "summary": "For each axiom of KM belief update we provide a corresponding axiom in a modal logic containing three modal operators: a unimodal belief operator $B$, a bimodal conditional operator $&gt;$ and the unimodal necessity operator $\\square$. We then compare the resulting logic to the similar logic obtained from converting the AGM axioms of belief revision into modal axioms and show that the latter contains the former. Denoting the latter by $\\mathcal L_{AGM}$ and the former by $\\mathcal L_{KM}$ we show that every axiom of $\\mathcal L_{KM}$ is a theorem of $\\mathcal L_{AGM}$. Thus AGM belief revision can be seen as a special case of KM belief update. For the strong version of KM belief update we show that the difference between $\\mathcal L_{KM}$ and $\\mathcal L_{AGM}$ can be narrowed down to a si",
      "authors": [
        "Giacomo Bonanno"
      ],
      "published": "2026-02-26T18:09:02Z",
      "updated": "2026-02-26T18:09:02Z",
      "categories": [
        "cs.AI",
        "cs.LO",
        "math.LO"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23302v1",
      "abs_url": "https://arxiv.org/abs/2602.23302v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "general"
    },
    {
      "id": "2602.23285v1",
      "title": "ODEBrain: Continuous-Time EEG Graph for Modeling Dynamic Brain Networks",
      "summary": "Modeling neural population dynamics is crucial for foundational neuroscientific research and various clinical applications. Conventional latent variable methods typically model continuous brain dynamics through discretizing time with recurrent architecture, which necessarily results in compounded cumulative prediction errors and failure of capturing instantaneous, nonlinear characteristics of EEGs. We propose ODEBRAIN, a Neural ODE latent dynamic forecasting framework to overcome these challenges by integrating spatio-temporal-frequency features into spectral graph nodes, followed by a Neural ODE modeling the continuous latent dynamics. Our design ensures that latent representations can capture stochastic variations of complex brain states at any given time point. Extensive experiments ver",
      "authors": [
        "Haohui Jia",
        "Zheng Chen",
        "Lingwei Zhu",
        "Rikuto Kotoge",
        "Jathurshan Pradeepkumar",
        "Yasuko Matsubara",
        "Jimeng Sun",
        "Yasushi Sakurai",
        "Takashi Matsubara"
      ],
      "published": "2026-02-26T17:59:10Z",
      "updated": "2026-02-26T17:59:10Z",
      "categories": [
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23285v1",
      "abs_url": "https://arxiv.org/abs/2602.23285v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "general"
    },
    {
      "id": "2602.23277v1",
      "title": "Zeroth-Order Stackelberg Control in Combinatorial Congestion Games",
      "summary": "We study Stackelberg (leader--follower) tuning of network parameters (tolls, capacities, incentives) in combinatorial congestion games, where selfish users choose discrete routes (or other combinatorial strategies) and settle at a congestion equilibrium. The leader minimizes a system-level objective (e.g., total travel time) evaluated at equilibrium, but this objective is typically nonsmooth because the set of used strategies can change abruptly. We propose ZO-Stackelberg, which couples a projection-free Frank--Wolfe equilibrium solver with a zeroth-order outer update, avoiding differentiation through equilibria. We prove convergence to generalized Goldstein stationary points of the true equilibrium objective, with explicit dependence on the equilibrium approximation error, and analyze sub",
      "authors": [
        "Saeed Masiha",
        "Sepehr Elahi",
        "Negar Kiyavash",
        "Patrick Thiran"
      ],
      "published": "2026-02-26T17:52:08Z",
      "updated": "2026-02-26T17:52:08Z",
      "categories": [
        "cs.GT",
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23277v1",
      "abs_url": "https://arxiv.org/abs/2602.23277v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "general"
    },
    {
      "id": "2602.23219v1",
      "title": "Takeuchi's Information Criteria as Generalization Measures for DNNs Close to NTK Regime",
      "summary": "Generalization measures have been studied extensively in the machine learning community to better characterize generalization gaps. However, establishing a reliable generalization measure for statistically singular models such as deep neural networks (DNNs) is difficult due to their complex nature. This study focuses on Takeuchi's information criterion (TIC) to investigate the conditions under which this classical measure can effectively explain the generalization gaps of DNNs. Importantly, the developed theory indicates the applicability of TIC near the neural tangent kernel (NTK) regime. In a series of experiments, we trained more than 5,000 DNN models with 12 architectures, including large models (e.g., VGG-16), on four datasets, and estimated the corresponding TIC values to examine the",
      "authors": [
        "Hiroki Naganuma",
        "Taiji Suzuki",
        "Rio Yokota",
        "Masahiro Nomura",
        "Kohta Ishikawa",
        "Ikuro Sato"
      ],
      "published": "2026-02-26T17:01:14Z",
      "updated": "2026-02-26T17:01:14Z",
      "categories": [
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23219v1",
      "abs_url": "https://arxiv.org/abs/2602.23219v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "benchmarks"
    },
    {
      "id": "2602.23203v1",
      "title": "ColoDiff: Integrating Dynamic Consistency With Content Awareness for Colonoscopy Video Generation",
      "summary": "Colonoscopy video generation delivers dynamic, information-rich data critical for diagnosing intestinal diseases, particularly in data-scarce scenarios. High-quality video generation demands temporal consistency and precise control over clinical attributes, but faces challenges from irregular intestinal structures, diverse disease representations, and various imaging modalities. To this end, we propose ColoDiff, a diffusion-based framework that generates dynamic-consistent and content-aware colonoscopy videos, aiming to alleviate data shortage and assist clinical analysis. At the inter-frame level, our TimeStream module decouples temporal dependency from video sequences through a cross-frame tokenization mechanism, enabling intricate dynamic modeling despite irregular intestinal structures",
      "authors": [
        "Junhu Fu",
        "Shuyu Liang",
        "Wutong Li",
        "Chen Ma",
        "Peng Huang",
        "Kehao Wang",
        "Ke Chen",
        "Shengli Lin",
        "Pinghong Zhou",
        "Zeju Li",
        "Yuanyuan Wang",
        "Yi Guo"
      ],
      "published": "2026-02-26T16:51:24Z",
      "updated": "2026-02-26T16:51:24Z",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23203v1",
      "abs_url": "https://arxiv.org/abs/2602.23203v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "benchmarks"
    },
    {
      "id": "2602.23172v1",
      "title": "Latent Gaussian Splatting for 4D Panoptic Occupancy Tracking",
      "summary": "Capturing 4D spatiotemporal surroundings is crucial for the safe and reliable operation of robots in dynamic environments. However, most existing methods address only one side of the problem: they either provide coarse geometric tracking via bounding boxes, or detailed 3D structures like voxel-based occupancy that lack explicit temporal association. In this work, we present Latent Gaussian Splatting for 4D Panoptic Occupancy Tracking (LaGS) that advances spatiotemporal scene understanding in a holistic direction. Our approach incorporates camera-based end-to-end tracking with mask-based multi-view panoptic occupancy prediction, and addresses the key challenge of efficiently aggregating multi-view information into 3D voxel grids via a novel latent Gaussian splatting approach. Specifically, ",
      "authors": [
        "Maximilian Luz",
        "Rohit Mohan",
        "Thomas Nrnberg",
        "Yakov Miron",
        "Daniele Cattaneo",
        "Abhinav Valada"
      ],
      "published": "2026-02-26T16:34:49Z",
      "updated": "2026-02-26T16:34:49Z",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23172v1",
      "abs_url": "https://arxiv.org/abs/2602.23172v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "code-generation"
    },
    {
      "id": "2602.23146v1",
      "title": "Partial recovery of meter-scale surface weather",
      "summary": "Near-surface atmospheric conditions can differ sharply over tens to hundreds of meters due to land cover and topography, yet this variability is absent from current weather analyses and forecasts. It is unclear whether such meter-scale variability reflects irreducibly chaotic dynamics or contains a component predictable from surface characteristics and large-scale atmospheric forcing. Here we show that a substantial, physically coherent component of meter-scale near-surface weather is statistically recoverable from existing observations. By conditioning coarse atmospheric state on sparse surface station measurements and high-resolution Earth observation data, we infer spatially continuous fields of near-surface wind, temperature, and humidity at 10 m resolution across the contiguous United",
      "authors": [
        "Jonathan Giezendanner",
        "Qidong Yang",
        "Eric Schmitt",
        "Anirban Chandra",
        "Daniel Salles Civitarese",
        "Johannes Jakubik",
        "Jeremy Vila",
        "Detlef Hohl",
        "Campbell Watson",
        "Sherrie Wang"
      ],
      "published": "2026-02-26T16:11:53Z",
      "updated": "2026-02-26T16:11:53Z",
      "categories": [
        "cs.LG",
        "cs.CV",
        "physics.ao-ph"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23146v1",
      "abs_url": "https://arxiv.org/abs/2602.23146v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "general"
    },
    {
      "id": "2602.23142v1",
      "title": "Prediction of Diffusion Coefficients in Mixtures with Tensor Completion",
      "summary": "Predicting diffusion coefficients in mixtures is crucial for many applications, as experimental data remain scarce, and machine learning (ML) offers promising alternatives to established semi-empirical models. Among ML models, matrix completion methods (MCMs) have proven effective in predicting thermophysical properties, including diffusion coefficients in binary mixtures. However, MCMs are restricted to single-temperature predictions, and their accuracy depends strongly on the availability of high-quality experimental data for each temperature of interest. In this work, we address this challenge by presenting a hybrid tensor completion method (TCM) for predicting temperature-dependent diffusion coefficients at infinite dilution in binary mixtures. The TCM employs a Tucker decomposition an",
      "authors": [
        "Zeno Romero",
        "Kerstin Mnnemann",
        "Hans Hasse",
        "Fabian Jirasek"
      ],
      "published": "2026-02-26T16:08:50Z",
      "updated": "2026-02-26T16:08:50Z",
      "categories": [
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23142v1",
      "abs_url": "https://arxiv.org/abs/2602.23142v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "general"
    },
    {
      "id": "2602.23132v1",
      "title": "From Agnostic to Specific: Latent Preference Diffusion for Multi-Behavior Sequential Recommendation",
      "summary": "Multi-behavior sequential recommendation (MBSR) aims to learn the dynamic and heterogeneous interactions of users' multi-behavior sequences, so as to capture user preferences under target behavior for the next interacted item prediction. Unlike previous methods that adopt unidirectional modeling by mapping auxiliary behaviors to target behavior, recent concerns are shifting from behavior-fixed to behavior-specific recommendation. However, these methods still ignore the user's latent preference that underlying decision-making, leading to suboptimal solutions. Meanwhile, due to the asymmetric deterministic between items and behaviors, discriminative paradigm based on preference scoring is unsuitable to capture the uncertainty from low-entropy behaviors to high-entropy items, failing to provi",
      "authors": [
        "Ruochen Yang",
        "Xiaodong Li",
        "Jiawei Sheng",
        "Jiangxia Cao",
        "Xinkui Lin",
        "Shen Wang",
        "Shuang Yang",
        "Zhaojie Liu",
        "Tingwen Liu"
      ],
      "published": "2026-02-26T15:48:09Z",
      "updated": "2026-02-26T15:48:09Z",
      "categories": [
        "cs.IR",
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23132v1",
      "abs_url": "https://arxiv.org/abs/2602.23132v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "code-generation"
    },
    {
      "id": "2602.23071v1",
      "title": "Quantity Convergence, Quality Divergence: Disentangling Fluency and Accuracy in L2 Mandarin Prosody",
      "summary": "While second language (L2) learners may acquire target syntactic word order, mapping this syntax onto appropriate prosodic structures remains a persistent challenge. This study investigates the fossilization and stability of the L2 syntax-prosody interface by comparing 67 native Mandarin speakers with 67 Vietnamese learners using the BLCU-SAIT corpus. By integrating C-ToBI boundary annotation with Dependency Grammar analysis, we examined both the quantity of prosodic boundaries and their mapping to syntactic relations. Results reveal a non-linear acquisition: although high-proficiency learners (VNH) converge to the native baseline in boundary quantity at the Major Phrase level (B3), their structural mapping significantly diverges. Specifically, VNH demote the prosodic boundary at the Subje",
      "authors": [
        "Yuqi Shi",
        "Hao Yang",
        "Xiyao Lu",
        "Jinsong Zhang"
      ],
      "published": "2026-02-26T15:00:59Z",
      "updated": "2026-02-26T15:00:59Z",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23071v1",
      "abs_url": "https://arxiv.org/abs/2602.23071v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "general"
    },
    {
      "id": "2602.23050v1",
      "title": "Latent Matters: Learning Deep State-Space Models",
      "summary": "Deep state-space models (DSSMs) enable temporal predictions by learning the underlying dynamics of observed sequence data. They are often trained by maximising the evidence lower bound. However, as we show, this does not ensure the model actually learns the underlying dynamics. We therefore propose a constrained optimisation framework as a general approach for training DSSMs. Building upon this, we introduce the extended Kalman VAE (EKVAE), which combines amortised variational inference with classic Bayesian filtering/smoothing to model dynamics more accurately than RNN-based DSSMs. Our results show that the constrained optimisation framework significantly improves system identification and prediction accuracy on the example of established state-of-the-art DSSMs. The EKVAE outperforms prev",
      "authors": [
        "Alexej Klushyn",
        "Richard Kurle",
        "Maximilian Soelch",
        "Botond Cseke",
        "Patrick van der Smagt"
      ],
      "published": "2026-02-26T14:35:45Z",
      "updated": "2026-02-26T14:35:45Z",
      "categories": [
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23050v1",
      "abs_url": "https://arxiv.org/abs/2602.23050v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "general"
    },
    {
      "id": "2602.23035v1",
      "title": "Learning Disease-Sensitive Latent Interaction Graphs From Noisy Cardiac Flow Measurements",
      "summary": "Cardiac blood flow patterns contain rich information about disease severity and clinical interventions, yet current imaging and computational methods fail to capture underlying relational structures of coherent flow features. We propose a physics-informed, latent relational framework to model cardiac vortices as interacting nodes in a graph. Our model combines a neural relational inference architecture with physics-inspired interaction energy and birth-death dynamics, yielding a latent graph sensitive to disease severity and intervention level. We first apply this to computational fluid dynamics simulations of aortic coarctation. Learned latent graphs reveal that as the aortic radius narrows, vortex interactions become stronger and more frequent. This leads to a higher graph entropy, corre",
      "authors": [
        "Viraj Patel",
        "Marko Grujic",
        "Philipp Aigner",
        "Theodor Abart",
        "Marcus Granegger",
        "Deblina Bhattacharjee",
        "Katharine Fraser"
      ],
      "published": "2026-02-26T14:17:49Z",
      "updated": "2026-02-26T14:17:49Z",
      "categories": [
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23035v1",
      "abs_url": "https://arxiv.org/abs/2602.23035v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "benchmarks"
    },
    {
      "id": "2602.23023v1",
      "title": "Low-degree Lower bounds for clustering in moderate dimension",
      "summary": "We study the fundamental problem of clustering $n$ points into $K$ groups drawn from a mixture of isotropic Gaussians in $\\mathbb{R}^d$. Specifically, we investigate the requisite minimal distance $$ between mean vectors to partially recover the underlying partition. While the minimax-optimal threshold for $$ is well-established, a significant gap exists between this information-theoretic limit and the performance of known polynomial-time procedures. Although this gap was recently characterized in the high-dimensional regime ($n \\leq dK$), it remains largely unexplored in the moderate-dimensional regime ($n \\geq dK$). In this manuscript, we address this regime by establishing a new low-degree polynomial lower bound for the moderate-dimensional case when $d \\geq K$. We show that while the",
      "authors": [
        "Alexandra Carpentier",
        "Nicolas Verzelen"
      ],
      "published": "2026-02-26T14:03:55Z",
      "updated": "2026-02-26T14:03:55Z",
      "categories": [
        "math.ST",
        "cs.LG",
        "math.PR",
        "stat.ML"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23023v1",
      "abs_url": "https://arxiv.org/abs/2602.23023v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "general"
    },
    {
      "id": "2602.23006v1",
      "title": "Regular Fourier Features for Nonstationary Gaussian Processes",
      "summary": "Simulating a Gaussian process requires sampling from a high-dimensional Gaussian distribution, which scales cubically with the number of sample locations. Spectral methods address this challenge by exploiting the Fourier representation, treating the spectral density as a probability distribution for Monte Carlo approximation. Although this probabilistic interpretation works for stationary processes, it is overly restrictive for the nonstationary case, where spectral densities are generally not probability measures. We propose regular Fourier features for harmonizable processes that avoid this limitation. Our method discretizes the spectral representation directly, preserving the correlation structure among spectral weights without requiring probability assumptions. Under a finite spectral ",
      "authors": [
        "Arsalan Jawaid",
        "Abdullah Karatas",
        "Jrg Seewig"
      ],
      "published": "2026-02-26T13:50:28Z",
      "updated": "2026-02-26T13:50:28Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.23006v1",
      "abs_url": "https://arxiv.org/abs/2602.23006v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "general"
    },
    {
      "id": "2602.22985v1",
      "title": "Kernel Integrated $R^2$: A Measure of Dependence",
      "summary": "We introduce kernel integrated $R^2$, a new measure of statistical dependence that combines the local normalization principle of the recently introduced integrated $R^2$ with the flexibility of reproducing kernel Hilbert spaces (RKHSs). The proposed measure extends integrated $R^2$ from scalar responses to responses taking values on general spaces equipped with a characteristic kernel, allowing to measure dependence of multivariate, functional, and structured data, while remaining sensitive to tail behaviour and oscillatory dependence structures. We establish that (i) this new measure takes values in $[0,1]$, (ii) equals zero if and only if independence holds, and (iii) equals one if and only if the response is almost surely a measurable function of the covariates. Two estimators are propo",
      "authors": [
        "Pouya Roudaki",
        "Shakeel Gavioli-Akilagun",
        "Florian Kalinke",
        "Mona Azadkia",
        "Zoltn Szab"
      ],
      "published": "2026-02-26T13:29:12Z",
      "updated": "2026-02-26T13:29:12Z",
      "categories": [
        "stat.ML",
        "cs.IT",
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.22985v1",
      "abs_url": "https://arxiv.org/abs/2602.22985v1",
      "relevance_score": 0,
      "matched_keywords": [],
      "category": "general"
    }
  ]
}